{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVOLUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convolution(data, filters, stride, padding='valid'):\n",
    "    \"\"\"\n",
    "    Optimized batch convolution operation with 4D input support\n",
    "    \"\"\"\n",
    "    # Input validation code remains unchanged\n",
    "        # Input validation\n",
    "    if not isinstance(data, np.ndarray) or data.ndim != 4:\n",
    "        raise ValueError(\"Input data must be 4D numpy array [B, C, H, W]\")\n",
    "    \n",
    "    if not isinstance(filters, np.ndarray) or filters.ndim != 4:\n",
    "        raise ValueError(\"Filters must be 4D numpy array [N, C, FH, FW]\")\n",
    "    \n",
    "    if filters.shape[1] != data.shape[1]:\n",
    "        raise ValueError(f\"Filter channels ({filters.shape[1]}) must match data channels ({data.shape[1]})\")\n",
    "    \n",
    "    batch_size, in_channels, in_h, in_w = data.shape\n",
    "    num_filters, _, fh, fw = filters.shape\n",
    "    sh, sw = stride\n",
    "    batch_size, in_channels, in_h, in_w = data.shape\n",
    "    num_filters, _, fh, fw = filters.shape\n",
    "    sh, sw = stride\n",
    "    \n",
    "    # Calculate output dimensions remains unchanged\n",
    "    if padding == 'same':\n",
    "        i=0\n",
    "        # Same padding calculation code\n",
    "        # ...\n",
    "    elif padding == 'valid':\n",
    "        out_h = (in_h - fh) // sh + 1\n",
    "        out_w = (in_w - fw) // sw + 1\n",
    "    else:\n",
    "        raise ValueError(\"Padding must be 'valid' or 'same'\")\n",
    "\n",
    "    # Create sliding windows for each sample in the batch\n",
    "    windows = sliding_window_view(data, (1, 1, fh, fw), axis=(0, 1, 2, 3))\n",
    "    \n",
    "    # Apply stride\n",
    "    windows = windows[:, :, ::sh, ::sw, 0, :, :, :]\n",
    "    \n",
    "    # FIXED: Get actual window shape rather than trying to unpack\n",
    "    window_shape = windows.shape\n",
    "    \n",
    "    # FIXED: Reshape using actual dimensions\n",
    "    # Flatten batch, channels, and spatial dimensions\n",
    "    windows_reshaped = windows.reshape(-1, in_channels * fh * fw)\n",
    "    \n",
    "    # Reshape filters to match inner dimension\n",
    "    filters_reshaped = filters.reshape(num_filters, in_channels * fh * fw)\n",
    "    \n",
    "    # Matrix multiplication with matching dimensions\n",
    "    output = np.matmul(windows_reshaped, filters_reshaped.T)\n",
    "    \n",
    "    # Reshape output to proper dimensions\n",
    "    output = output.reshape(batch_size, out_h, out_w, num_filters)\n",
    "    output = output.transpose(0, 3, 1, 2)  # NHWC -> NCHW\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECONVOLUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def batch_deconvolution(data, filters, stride, padding='valid', output_padding=(0, 0)):\n",
    "    \"\"\"\n",
    "    Vectorized transposed convolution (deconvolution) with batch support\n",
    "\n",
    "    Parameters:\n",
    "    data : np.ndarray [batch_size, in_channels, in_height, in_width]\n",
    "    filters : np.ndarray [out_channels, in_channels, fh, fw]\n",
    "    stride : tuple (sh, sw)\n",
    "    padding : 'valid' or 'same'\n",
    "    output_padding : tuple (oph, opw)\n",
    "\n",
    "    Returns:\n",
    "    output : np.ndarray [batch_size, out_channels, out_height, out_width]\n",
    "    \"\"\"\n",
    "    if data.ndim != 4 or filters.ndim != 4:\n",
    "        raise ValueError(\"Inputs must be 4D arrays\")\n",
    "\n",
    "    batch_size, in_chan, in_h, in_w = data.shape\n",
    "    out_chan, _, fh, fw = filters.shape\n",
    "    sh, sw = stride\n",
    "    oph, opw = output_padding\n",
    "\n",
    "    # Calculate expected output shape\n",
    "    if padding == 'same':\n",
    "        out_h = in_h * sh + oph\n",
    "        out_w = in_w * sw + opw\n",
    "        pad_h = (in_h - 1) * sh + fh - out_h + oph\n",
    "        pad_w = (in_w - 1) * sw + fw - out_w + opw\n",
    "        pad_h = max(pad_h, 0)\n",
    "        pad_w = max(pad_w, 0)\n",
    "    elif padding == 'valid':\n",
    "        out_h = (in_h - 1) * sh + fh + oph\n",
    "        out_w = (in_w - 1) * sw + fw + opw\n",
    "        pad_h = pad_w = 0\n",
    "    else:\n",
    "        raise ValueError(\"Padding must be 'valid' or 'same'\")\n",
    "\n",
    "    # Step 1: Upsample\n",
    "    up_h = (in_h - 1) * sh + 1\n",
    "    up_w = (in_w - 1) * sw + 1\n",
    "    upsampled = np.zeros((batch_size, in_chan, up_h, up_w), dtype=data.dtype)\n",
    "    upsampled[:, :, ::sh, ::sw] = data\n",
    "\n",
    "    # Step 2: Pad\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "    padded = np.pad(\n",
    "        upsampled,\n",
    "        [(0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)],\n",
    "        mode='constant'\n",
    "    )\n",
    "\n",
    "    # Step 3: Adjust padding if needed to match output shape\n",
    "    needed_h = out_h + fh - 1\n",
    "    needed_w = out_w + fw - 1\n",
    "    cur_h, cur_w = padded.shape[2], padded.shape[3]\n",
    "    extra_pad_h = max(0, needed_h - cur_h)\n",
    "    extra_pad_w = max(0, needed_w - cur_w)\n",
    "\n",
    "    if extra_pad_h > 0 or extra_pad_w > 0:\n",
    "        padded = np.pad(\n",
    "            padded,\n",
    "            [(0, 0), (0, 0), (0, extra_pad_h), (0, extra_pad_w)],\n",
    "            mode='constant'\n",
    "        )\n",
    "\n",
    "    # Step 4: Sliding window view\n",
    "    windows = sliding_window_view(padded, (fh, fw), axis=(2, 3))  # shape: [B, C, H_out, W_out, fh, fw]\n",
    "\n",
    "    # Step 5: Apply filters with einsum\n",
    "    output = np.einsum('bcijxy,ocxy->boij', windows, filters)\n",
    "\n",
    "    # Final sanity check\n",
    "    assert output.shape[2] == out_h and output.shape[3] == out_w, \\\n",
    "        f\"Deconv output shape mismatch: got {output.shape[2:]}, expected ({out_h}, {out_w})\"\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RELU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(data):\n",
    "    return np.maximum(0.0,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BATCH NORMALIZATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(data, bn, eps=1e-5):\n",
    "\n",
    "    gamma=bn[0,:]\n",
    "    beta=bn[1,:]\n",
    "    \"\"\"  \n",
    "    data : np.ndarray [N, C, H, W]  \n",
    "    gamma: np.ndarray [C,]  \n",
    "    beta : np.ndarray [C,]  \n",
    "    \"\"\"  \n",
    "    # Per-channel statistics  \n",
    "    mu = np.mean(data, axis=(0, 2, 3), keepdims=True)  \n",
    "    var = np.var(data, axis=(0, 2, 3), keepdims=True)  \n",
    "\n",
    "    # Normalization  \n",
    "    x_hat = (data - mu) / np.sqrt(var + eps)  \n",
    "\n",
    "    # Scale and shift  \n",
    "    return gamma[None,:,None,None] * x_hat + beta[None,:,None,None]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVATIVE FOR BATCH NORMALIZATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_backward(dout, x, gamma, eps=1e-5):  \n",
    "    mu = np.mean(x, axis=(0,2,3), keepdims=True)  \n",
    "    var = np.var(x, axis=(0,2,3), keepdims=True)  \n",
    "    x_hat = (x - mu)/np.sqrt(var + eps)  \n",
    "\n",
    "    N, C, H, W = x.shape  \n",
    "    dgamma = np.sum(dout * x_hat, axis=(0,2,3))  \n",
    "    dbeta = np.sum(dout, axis=(0,2,3))  \n",
    "\n",
    "    dx_hat = dout * gamma[None,:,None,None]  \n",
    "    dvar = np.sum(dx_hat * (x - mu) * (-0.5) * (var + eps)**(-1.5), axis=(0,2,3))  \n",
    "    dmu = np.sum(dx_hat * (-1)/np.sqrt(var + eps), axis=(0,2,3)) + dvar * np.mean(-2*(x - mu), axis=(0,2,3))  \n",
    "\n",
    "    dx = dx_hat / np.sqrt(var + eps) + dvar[None,:,None,None]*2*(x - mu)/N/H/W + dmu[None,:,None,None]/N/H/W  \n",
    "    dbn=np.zeros((2,gamma.shape[0]))\n",
    "    dbn[0,:]=dgamma\n",
    "    dbn[1,:]=dbeta\n",
    "    return dx, dbn  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVATIVE FOR RELU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(data):\n",
    "    return (data>0).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVATIVE FOR CONVOLUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def conv_backward(dout, x, W, stride, padding='valid'):\n",
    "    \"\"\"\n",
    "    Vectorized backward pass for batch convolution.\n",
    "    \"\"\"\n",
    "    batch_size, in_chan, h_in, w_in = x.shape\n",
    "    num_filters, _, fh, fw = W.shape\n",
    "    sh, sw = stride\n",
    "\n",
    "    # === Padding for x (input) ===\n",
    "    if padding == 'same':\n",
    "        out_h = int(np.ceil(h_in / sh))\n",
    "        out_w = int(np.ceil(w_in / sw))\n",
    "        pad_h = max((out_h - 1) * sh + fh - h_in, 0)\n",
    "        pad_w = max((out_w - 1) * sw + fw - w_in, 0)\n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "        x_padded = np.pad(x, [(0,0), (0,0), (pad_top, pad_bottom), (pad_left, pad_right)])\n",
    "    else:\n",
    "        x_padded = x\n",
    "        out_h = (h_in - fh) // sh + 1\n",
    "        out_w = (w_in - fw) // sw + 1\n",
    "\n",
    "    # === dW: Vectorized filter gradient ===\n",
    "    # Extract input patches as in the forward pass\n",
    "    x_windows = sliding_window_view(x_padded, (fh, fw), axis=(2, 3))\n",
    "    x_windows = x_windows[:, :, ::sh, ::sw, :, :]  # Apply stride\n",
    "    # x_windows shape: (B, in_chan, out_h, out_w, fh, fw)\n",
    "    # dout shape: (B, num_filters, out_h, out_w)\n",
    "    # We want: (num_filters, in_chan, fh, fw)\n",
    "    dW = np.einsum('b o h w, b c h w f g -> o c f g', dout, x_windows)\n",
    "\n",
    "    # === dx: Vectorized input gradient ===\n",
    "    # For dx, we need to convolve dout with flipped filters\n",
    "    W_flip = np.flip(W, axis=(2, 3)).swapaxes(0,1)  # (in_chan, num_filters, fh, fw)\n",
    "    # Upsample dout to account for stride\n",
    "    H_out, W_out = dout.shape[2], dout.shape[3]\n",
    "    H_upsampled = (H_out - 1) * sh + 1\n",
    "    W_upsampled = (W_out - 1) * sw + 1\n",
    "    dout_upsampled = np.zeros((batch_size, num_filters, H_upsampled, W_upsampled), dtype=dout.dtype)\n",
    "    dout_upsampled[:, :, ::sh, ::sw] = dout\n",
    "\n",
    "    # Pad dout_upsampled for full convolution\n",
    "    pad_h = fh - 1\n",
    "    pad_w = fw - 1\n",
    "    dout_padded = np.pad(dout_upsampled, [(0,0), (0,0), (pad_h, pad_h), (pad_w, pad_w)])\n",
    "\n",
    "    # Extract sliding windows from padded dout\n",
    "    dout_windows = sliding_window_view(dout_padded, (fh, fw), axis=(2,3))\n",
    "    # dout_windows shape: (B, num_filters, h_in, w_in, fh, fw)\n",
    "    # W_flip shape: (in_chan, num_filters, fh, fw)\n",
    "    # We want: (B, in_chan, h_in, w_in)\n",
    "    dx = np.einsum('b o h w f g, c o f g -> b c h w', dout_windows, W_flip)\n",
    "\n",
    "    # Remove padding from dx if 'same'\n",
    "    if padding == 'same':\n",
    "        dx = dx[:, :, :h_in, :w_in]\n",
    "\n",
    "    return dx, dW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERIVATIVE FOR DECONVOLUTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "def deconv_backward(dout, x, W, stride, padding='valid', output_padding=(0,0)):\n",
    "    B, in_C, H_in, W_in = x.shape\n",
    "    out_C, _, fh, fw = W.shape\n",
    "    sh, sw = stride\n",
    "    oph, opw = output_padding\n",
    "\n",
    "    # Gradient w.r.t. input (dx)\n",
    "    W_flipped = np.flip(W, axis=(2,3)).transpose(1, 0, 2, 3)  # [in_C, out_C, fh, fw]\n",
    "\n",
    "    if padding == 'same':\n",
    "        pad_h = fh - 1\n",
    "        pad_w = fw - 1\n",
    "    elif padding == 'valid':\n",
    "        pad_h = fh - 1 + oph\n",
    "        pad_w = fw - 1 + opw\n",
    "    else:\n",
    "        raise ValueError(\"Padding must be 'valid' or 'same'\")\n",
    "\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "\n",
    "    dout_padded = np.pad(dout, [(0,0), (0,0), (pad_top, pad_bottom), (pad_left, pad_right)], mode='constant')\n",
    "\n",
    "    dx = np.zeros((B, in_C, H_in, W_in))\n",
    "    for b in range(B):\n",
    "        for i in range(in_C):\n",
    "            for o in range(out_C):\n",
    "                conv_result = correlate2d(dout[b, o], W_flipped[i, o], mode='valid')\n",
    "                dx[b, i] += conv_result[::sh, ::sw]\n",
    "\n",
    "    # Gradient w.r.t. weights (dW)\n",
    "    # Calculate required padded size\n",
    "    H_up = (H_in - 1) * sh + 1\n",
    "    W_up = (W_in - 1) * sw + 1\n",
    "    x_upsampled = np.zeros((B, in_C, H_up, W_up))\n",
    "    x_upsampled[:, :, ::sh, ::sw] = x    \n",
    "    required_h = dout.shape[2] + fh - 1\n",
    "    required_w = dout.shape[3] + fw - 1\n",
    "\n",
    "    cur_h, cur_w = x_upsampled.shape[2], x_upsampled.shape[3]\n",
    "    pad_h = required_h - cur_h\n",
    "    pad_w = required_w - cur_w\n",
    "\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "\n",
    "    if pad_h > 0 or pad_w > 0:\n",
    "        x_upsampled = np.pad(\n",
    "            x_upsampled,\n",
    "            [(0, 0), (0, 0), (pad_top, pad_bottom), (pad_left, pad_right)],\n",
    "            mode='constant'\n",
    "        )\n",
    "\n",
    "    x_windows = sliding_window_view(x_upsampled, (fh, fw), axis=(2, 3))  # [B, in_C, H_out, W_out, fh, fw]\n",
    "\n",
    "    H_out, W_out = dout.shape[2], dout.shape[3]\n",
    "    if x_windows.shape[2] != H_out or x_windows.shape[3] != W_out:\n",
    "        x_windows = x_windows[:, :, :H_out, :W_out, :, :]\n",
    "\n",
    "    dW = np.einsum('bohw,bchwxy->ocxy', dout, x_windows)\n",
    "\n",
    "    return dx, dW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ERROR METRICS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_loss(y_true, y_pred):\n",
    "    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)\n",
    "    vgg = tf.keras.applications.VGG16(include_top=False, weights='imagenet')\n",
    "    perceptual_model = tf.keras.Model(vgg.input, vgg.get_layer('block3_conv3').output)\n",
    "    pl = tf.reduce_mean(tf.square(perceptual_model(y_true) - perceptual_model(y_pred)))\n",
    "    return 0.7*pl + 0.3*mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_error(IP,OP):\n",
    "    error=(IP-OP)**2\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=\"D:\\REQS\\PROJECT\\dataset\\\\train\"\n",
    "\n",
    "#Hypreparameters\n",
    "epochs=10\n",
    "back_spin=5\n",
    "learning_rate=0.0001\n",
    "e=0.00001\n",
    "batch_size=32\n",
    "image_size=[3,32,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL:2 -- THE BASE\n",
    "\n",
    "s_all=[2,2]\n",
    "#3x32x32\n",
    "conv_f1=np.random.randn(8,3,4,4)* np.sqrt(2/(3*4*4))\n",
    "bn_f1=np.random.randn(2,8)* np.sqrt(2/(3*4*4))\n",
    "#8x15x15\n",
    "conv_f2=np.random.randn(12,8,3,3)* np.sqrt(2/(3*4*4))\n",
    "bn_f2=np.random.rand(2,12)* np.sqrt(2/(3*4*4))\n",
    "#12x7x7\n",
    "deconv_f3=np.random.randn(10,12,5,5)* np.sqrt(2/(3*4*4))\n",
    "bn_f3=np.random.rand(2,10)* np.sqrt(2/(3*4*4))\n",
    "#10x17x17\n",
    "deconv_f4=np.random.randn(6,10,4,4)* np.sqrt(2/(3*4*4))\n",
    "bn_f4=np.random.rand(2,6)* np.sqrt(2/(3*4*4))\n",
    "#6x36x36\n",
    "deconv_f5=np.random.randn(3,6,5,5)* np.sqrt(2/(3*4*4))\n",
    "bn_f5=np.random.rand(2,3)* np.sqrt(2/(3*4*4))\n",
    "#3x75x75\n",
    "conv_f6=np.random.randn(6,3,5,5)* np.sqrt(2/(3*4*4))\n",
    "bn_f6=np.random.rand(2,6)* np.sqrt(2/(3*4*4))\n",
    "#6x36x36\n",
    "conv_f7=np.random.randn(10,6,4,4)* np.sqrt(2/(3*4*4))\n",
    "bn_f7=np.random.rand(2,10)* np.sqrt(2/(3*4*4))\n",
    "#10x17x17\n",
    "conv_f8=np.random.randn(12,10,5,5)* np.sqrt(2/(3*4*4))\n",
    "bn_f8=np.random.rand(2,12)* np.sqrt(2/(3*4*4))\n",
    "#12x7x7\n",
    "deconv_f9=np.random.randn(8,12,3,3)* np.sqrt(2/(3*4*4))\n",
    "bn_f9=np.random.rand(2,8)* np.sqrt(2/(3*4*4))\n",
    "#8x15x15\n",
    "deconv_f10=np.random.randn(3,8,4,4)* np.sqrt(2/(3*4*4))\n",
    "bn_f10=np.random.rand(2,3)* np.sqrt(2/(3*4*4))\n",
    "#3x32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flow 1,2,3,4,5,6,7,8,9,10\n",
    "def forward(IP):\n",
    "    a1=batch_convolution(IP,conv_f1,(2,2),'valid')\n",
    "    bn_a1=batch_norm(a1, bn_f1,0.00001)\n",
    "    act_a1=relu(bn_a1)\n",
    "    #print(act_a1.shape)\n",
    "    a2=batch_convolution(act_a1,conv_f2,(2,2),'valid',)\n",
    "    bn_a2=batch_norm(a2, bn_f2,0.00001)\n",
    "    act_a2=relu(bn_a2)\n",
    "    #print(act_a2.shape)\n",
    "    a3=batch_deconvolution(act_a2,deconv_f3,(2,2),'valid',(0,0))\n",
    "    bn_a3=batch_norm(a3, bn_f3,0.00001)\n",
    "    act_a3=relu(bn_a3)\n",
    "    #print(act_a3.shape)\n",
    "    a4=batch_deconvolution(act_a3,deconv_f4,(2,2),'valid',(0,0))\n",
    "    bn_a4=batch_norm(a4, bn_f4,0.00001)\n",
    "    act_a4=relu(bn_a4)\n",
    "    #print(act_a4.shape)\n",
    "    a5=batch_deconvolution(act_a4,deconv_f5,(2,2),'valid',(0,0))\n",
    "    bn_a5=batch_norm(a5, bn_f5,0.00001)\n",
    "    act_a5=relu(bn_a5)\n",
    "    #print(act_a5.shape)\n",
    "    a6=batch_convolution(act_a5,conv_f6,(2,2),'valid')\n",
    "    bn_a6=batch_norm(a6, bn_f6,0.00001)\n",
    "    act_a6=relu(bn_a6)\n",
    "    #print(act_a6.shape)\n",
    "    a7=batch_convolution(act_a6,conv_f7,(2,2),'valid')\n",
    "    bn_a7=batch_norm(a7, bn_f7,0.00001)\n",
    "    act_a7=relu(bn_a7)\n",
    "    #print(act_a7.shape)\n",
    "    a8=batch_convolution(act_a7,conv_f8,(2,2),'valid')\n",
    "    bn_a8=batch_norm(a8, bn_f8,0.00001)\n",
    "    act_a8=relu(bn_a8)\n",
    "    a9=batch_deconvolution(act_a8,deconv_f9,(2,2),'valid',(0,0))\n",
    "    bn_a9=batch_norm(a9, bn_f9,0.00001)\n",
    "    act_a9=relu(bn_a9)\n",
    "    a10=batch_deconvolution(act_a9,deconv_f10,(2,2),'valid',(0,0))\n",
    "    bn_a10=batch_norm(a10, bn_f10,0.00001)\n",
    "    act_a10=relu(bn_a10)\n",
    "    \n",
    "    return act_a10, bn_a10, a10, act_a9, bn_a9, a9, act_a8, bn_a8, a8, act_a7, bn_a7, a7, act_a6, bn_a6, a6, act_a5, bn_a5, a5, act_a4, bn_a4, a4, act_a3, bn_a3, a3, act_a2, bn_a2, a2, act_a1, bn_a1, a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1_backward(IP, layers, losse, saver):\n",
    "    act_a10, bn_a10, a10, act_a9, bn_a9, a9, act_a8, bn_a8, a8, act_a7, bn_a7, a7, act_a6, bn_a6, a6, act_a5, bn_a5, a5, act_a4, bn_a4, a4, act_a3, bn_a3, a3, act_a2, bn_a2, a2, act_a1, bn_a1, a1=layers\n",
    "    d_act_a10=losse\n",
    "    d_bn_a10=relu_backward(d_act_a10)\n",
    "    d_a10, d_bn_f10=batch_norm_backward(d_bn_a10, a10, bn_f10[0,:])\n",
    "    d_act_a9, d_deconv_f10=deconv_backward(d_a10, act_a9, deconv_f10, (2,2))\n",
    "    #print(d_act_a9.shape)\n",
    "    d_bn_a9=relu_backward(d_act_a9)\n",
    "    d_a9, d_bn_f9=batch_norm_backward(d_bn_a9, a9, bn_f9[0,:])\n",
    "    d_act_a8, d_deconv_f9=deconv_backward(d_a9, act_a8, deconv_f9, (2,2))\n",
    "    #print(d_act_a8.shape)\n",
    "    d_bn_a8=relu_backward(d_act_a8)\n",
    "    d_a8, d_bn_f8=batch_norm_backward(d_bn_a8, a8, bn_f8[0,:])\n",
    "    d_act_a7, d_conv_f8=conv_backward(d_a8, act_a7, conv_f8, (2,2))\n",
    "    #print(d_act_a7.shape)\n",
    "    d_bn_a7=relu_backward(d_act_a7)\n",
    "    d_a7, d_bn_f7=batch_norm_backward(d_bn_a7, a7, bn_f7[0,:])\n",
    "    d_act_a6, d_conv_f7=conv_backward(d_a7, act_a6, conv_f7, (2,2))\n",
    "    #print(d_act_a6.shape)\n",
    "    d_bn_a6=relu_backward(d_act_a6)\n",
    "    d_a6, d_bn_f6=batch_norm_backward(d_bn_a6, a6, bn_f6[0,:])\n",
    "    d_act_a5, d_conv_f6=conv_backward(d_a6, act_a5, conv_f6, (2,2))\n",
    "    #print(d_act_a5.shape)\n",
    "    d_bn_a5=relu_backward(d_act_a5)\n",
    "    d_a5, d_bn_f5=batch_norm_backward(d_bn_a5, a5, bn_f5[0,:])\n",
    "    d_act_a4, d_deconv_f5=deconv_backward(d_a5, act_a4, deconv_f5, (2,2))\n",
    "    #print(d_act_a4.shape)\n",
    "    d_bn_a4=relu_backward(d_act_a4)\n",
    "    d_a4, d_bn_f4=batch_norm_backward(d_bn_a4, a4, bn_f4[0,:])\n",
    "    d_act_a3, d_deconv_f4=deconv_backward(d_a4, act_a3, deconv_f4, (2,2))\n",
    "    #print(d_act_a3.shape)\n",
    "    d_bn_a3=relu_backward(d_act_a3)\n",
    "    d_a3, d_bn_f3=batch_norm_backward(d_bn_a3, a3, bn_f3[0,:])\n",
    "    d_act_a2, d_deconv_f3=deconv_backward(d_a3, act_a2, deconv_f3, (2,2))\n",
    "    #print(d_act_a2.shape)\n",
    "    d_bn_a2=relu_backward(d_act_a2)\n",
    "    d_a2, d_bn_f2=batch_norm_backward(d_bn_a2, a2, bn_f2[0,:])\n",
    "    d_act_a1, d_conv_f2=conv_backward(d_a2, act_a1, conv_f2, (2,2))\n",
    "    #print(d_act_a1.shape)\n",
    "    d_bn_a1=relu_backward(d_act_a1)\n",
    "    d_a1, d_bn_f1=batch_norm_backward(d_bn_a1, a1, bn_f1[0,:])\n",
    "    d_IP, d_conv_f1=conv_backward(d_a1, IP, conv_f1, (2,2))\n",
    "    saver=d_IP\n",
    "    return d_conv_f1, d_bn_f1, d_conv_f2, d_bn_f2, d_deconv_f3, d_bn_f3, d_deconv_f4, d_bn_f4, d_deconv_f5, d_bn_f5, d_conv_f6, d_bn_f6, d_conv_f7, d_bn_f7, d_conv_f8, d_bn_f8, d_deconv_f9, d_bn_f9, d_deconv_f10, d_bn_f10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Parameters\n",
    "def update_params(diffs, lr, conv_f1, conv_f2, deconv_f3, deconv_f4, deconv_f5, conv_f6, conv_f7, conv_f8, deconv_f9, deconv_f10, bn_f1, bn_f2, bn_f3, bn_f4, bn_f5, bn_f6, bn_f7, bn_f8, bn_f9, bn_f10):\n",
    "    d_conv_f1, d_bn_f1, d_conv_f2, d_bn_f2, d_deconv_f3, d_bn_f3, d_deconv_f4, d_bn_f4, d_deconv_f5, d_bn_f5, d_conv_f6, d_bn_f6, d_conv_f7, d_bn_f7, d_conv_f8, d_bn_f8, d_deconv_f9, d_bn_f9, d_deconv_f10, d_bn_f10=diffs\n",
    "    conv_f1=conv_f1-lr*d_conv_f1\n",
    "    bn_f1-=lr*d_bn_f1\n",
    "    conv_f2-=lr*d_conv_f2\n",
    "    bn_f2-=lr*d_bn_f2\n",
    "    deconv_f3-=lr*d_deconv_f3\n",
    "    bn_f3-=lr*d_bn_f3\n",
    "    deconv_f4-=lr*d_deconv_f4\n",
    "    bn_f4-=lr*d_bn_f4\n",
    "    deconv_f5-=lr*d_deconv_f5\n",
    "    bn_f5-=lr*d_bn_f5\n",
    "    conv_f6-=lr*d_conv_f6\n",
    "    bn_f6-=lr*d_bn_f6\n",
    "    conv_f7-=lr*d_conv_f7\n",
    "    bn_f7-=lr*d_bn_f7\n",
    "    conv_f8-=lr*d_conv_f8\n",
    "    bn_f8-=lr*d_bn_f8\n",
    "    deconv_f9-=lr*d_deconv_f9\n",
    "    bn_f9-=lr*d_bn_f9\n",
    "    deconv_f10-=lr*d_deconv_f10\n",
    "    bn_f10-=lr*d_bn_f10\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_paths():\n",
    "    \"\"\"Loads all image file paths from the dataset directory.\"\"\"\n",
    "    supported_formats = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "    image_paths = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) \n",
    "                    if f.endswith(supported_formats)]\n",
    "    return image_paths\n",
    "    \n",
    "def load_image(image_path):\n",
    "    \"\"\"Loads an image, resizes it, and normalizes pixel values to the range [0, 1].\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    #Eimage = cv2.resize(image, image_size)\n",
    "    image = image.astype(np.float64) / 255.0  # Normalize to [0, 1]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [2/1562], Loss: 0.2850\n",
      "Epoch [1/10], Batch [4/1562], Loss: 0.2932\n",
      "Epoch [1/10], Batch [6/1562], Loss: 0.3113\n",
      "Epoch [1/10], Batch [8/1562], Loss: 0.2913\n",
      "Epoch [1/10], Batch [10/1562], Loss: 0.2892\n",
      "Epoch [1/10], Batch [12/1562], Loss: 0.2961\n",
      "Epoch [1/10], Batch [14/1562], Loss: 0.2737\n",
      "Epoch [1/10], Batch [16/1562], Loss: 0.2781\n",
      "Epoch [1/10], Batch [18/1562], Loss: 0.3085\n",
      "Epoch [1/10], Batch [20/1562], Loss: 0.2674\n",
      "Epoch [1/10], Batch [22/1562], Loss: 0.2592\n",
      "Epoch [1/10], Batch [24/1562], Loss: 0.3401\n",
      "Epoch [1/10], Batch [26/1562], Loss: 0.3010\n",
      "Epoch [1/10], Batch [28/1562], Loss: 0.2736\n",
      "Epoch [1/10], Batch [30/1562], Loss: 0.3049\n",
      "Epoch [1/10], Batch [32/1562], Loss: 0.3151\n",
      "Epoch [1/10], Batch [34/1562], Loss: 0.2831\n",
      "Epoch [1/10], Batch [36/1562], Loss: 0.3154\n",
      "Epoch [1/10], Batch [38/1562], Loss: 0.2710\n",
      "Epoch [1/10], Batch [40/1562], Loss: 0.3034\n",
      "Epoch [1/10], Batch [42/1562], Loss: 0.2881\n",
      "Epoch [1/10], Batch [44/1562], Loss: 0.3470\n",
      "Epoch [1/10], Batch [46/1562], Loss: 0.2950\n",
      "Epoch [1/10], Batch [48/1562], Loss: 0.2925\n",
      "Epoch [1/10], Batch [50/1562], Loss: 0.2930\n",
      "Epoch [1/10], Batch [52/1562], Loss: 0.3223\n",
      "Epoch [1/10], Batch [54/1562], Loss: 0.2969\n",
      "Epoch [1/10], Batch [56/1562], Loss: 0.2908\n",
      "Epoch [1/10], Batch [58/1562], Loss: 0.2501\n",
      "Epoch [1/10], Batch [60/1562], Loss: 0.2979\n",
      "Epoch [1/10], Batch [62/1562], Loss: 0.2821\n",
      "Epoch [1/10], Batch [64/1562], Loss: 0.2857\n",
      "Epoch [1/10], Batch [66/1562], Loss: 0.2801\n",
      "Epoch [1/10], Batch [68/1562], Loss: 0.3455\n",
      "Epoch [1/10], Batch [70/1562], Loss: 0.2916\n",
      "Epoch [1/10], Batch [72/1562], Loss: 0.2846\n",
      "Epoch [1/10], Batch [74/1562], Loss: 0.2880\n",
      "Epoch [1/10], Batch [76/1562], Loss: 0.2717\n",
      "Epoch [1/10], Batch [78/1562], Loss: 0.2822\n",
      "Epoch [1/10], Batch [80/1562], Loss: 0.2653\n",
      "Epoch [1/10], Batch [82/1562], Loss: 0.2593\n",
      "Epoch [1/10], Batch [84/1562], Loss: 0.2821\n",
      "Epoch [1/10], Batch [86/1562], Loss: 0.3319\n",
      "Epoch [1/10], Batch [88/1562], Loss: 0.2950\n",
      "Epoch [1/10], Batch [90/1562], Loss: 0.2581\n",
      "Epoch [1/10], Batch [92/1562], Loss: 0.2575\n",
      "Epoch [1/10], Batch [94/1562], Loss: 0.2917\n",
      "Epoch [1/10], Batch [96/1562], Loss: 0.2838\n",
      "Epoch [1/10], Batch [98/1562], Loss: 0.3050\n",
      "Epoch [1/10], Batch [100/1562], Loss: 0.2650\n",
      "Epoch [1/10], Batch [102/1562], Loss: 0.3103\n",
      "Epoch [1/10], Batch [104/1562], Loss: 0.2832\n",
      "Epoch [1/10], Batch [106/1562], Loss: 0.2882\n",
      "Epoch [1/10], Batch [108/1562], Loss: 0.2711\n",
      "Epoch [1/10], Batch [110/1562], Loss: 0.2827\n",
      "Epoch [1/10], Batch [112/1562], Loss: 0.2897\n",
      "Epoch [1/10], Batch [114/1562], Loss: 0.3086\n",
      "Epoch [1/10], Batch [116/1562], Loss: 0.3388\n",
      "Epoch [1/10], Batch [118/1562], Loss: 0.2588\n",
      "Epoch [1/10], Batch [120/1562], Loss: 0.2770\n",
      "Epoch [1/10], Batch [122/1562], Loss: 0.2886\n",
      "Epoch [1/10], Batch [124/1562], Loss: 0.3159\n",
      "Epoch [1/10], Batch [126/1562], Loss: 0.3186\n",
      "Epoch [1/10], Batch [128/1562], Loss: 0.2526\n",
      "Epoch [1/10], Batch [130/1562], Loss: 0.3223\n",
      "Epoch [1/10], Batch [132/1562], Loss: 0.3202\n",
      "Epoch [1/10], Batch [134/1562], Loss: 0.2322\n",
      "Epoch [1/10], Batch [136/1562], Loss: 0.2550\n",
      "Epoch [1/10], Batch [138/1562], Loss: 0.2757\n",
      "Epoch [1/10], Batch [140/1562], Loss: 0.2702\n",
      "Epoch [1/10], Batch [142/1562], Loss: 0.2282\n",
      "Epoch [1/10], Batch [144/1562], Loss: 0.2808\n",
      "Epoch [1/10], Batch [146/1562], Loss: 0.2726\n",
      "Epoch [1/10], Batch [148/1562], Loss: 0.2761\n",
      "Epoch [1/10], Batch [150/1562], Loss: 0.2900\n",
      "Epoch [1/10], Batch [152/1562], Loss: 0.2302\n",
      "Epoch [1/10], Batch [154/1562], Loss: 0.2794\n",
      "Epoch [1/10], Batch [156/1562], Loss: 0.2539\n",
      "Epoch [1/10], Batch [158/1562], Loss: 0.3117\n",
      "Epoch [1/10], Batch [160/1562], Loss: 0.2824\n",
      "Epoch [1/10], Batch [162/1562], Loss: 0.2690\n",
      "Epoch [1/10], Batch [164/1562], Loss: 0.2488\n",
      "Epoch [1/10], Batch [166/1562], Loss: 0.2830\n",
      "Epoch [1/10], Batch [168/1562], Loss: 0.2759\n",
      "Epoch [1/10], Batch [170/1562], Loss: 0.3071\n",
      "Epoch [1/10], Batch [172/1562], Loss: 0.3272\n",
      "Epoch [1/10], Batch [174/1562], Loss: 0.2996\n",
      "Epoch [1/10], Batch [176/1562], Loss: 0.2526\n",
      "Epoch [1/10], Batch [178/1562], Loss: 0.2895\n",
      "Epoch [1/10], Batch [180/1562], Loss: 0.2940\n",
      "Epoch [1/10], Batch [182/1562], Loss: 0.2930\n",
      "Epoch [1/10], Batch [184/1562], Loss: 0.3002\n",
      "Epoch [1/10], Batch [186/1562], Loss: 0.3297\n",
      "Epoch [1/10], Batch [188/1562], Loss: 0.2432\n",
      "Epoch [1/10], Batch [190/1562], Loss: 0.3030\n",
      "Epoch [1/10], Batch [192/1562], Loss: 0.3134\n",
      "Epoch [1/10], Batch [194/1562], Loss: 0.2756\n",
      "Epoch [1/10], Batch [196/1562], Loss: 0.2707\n",
      "Epoch [1/10], Batch [198/1562], Loss: 0.3086\n",
      "Epoch [1/10], Batch [200/1562], Loss: 0.2930\n",
      "Epoch [1/10], Batch [202/1562], Loss: 0.2897\n",
      "Epoch [1/10], Batch [204/1562], Loss: 0.2597\n",
      "Epoch [1/10], Batch [206/1562], Loss: 0.3011\n",
      "Epoch [1/10], Batch [208/1562], Loss: 0.2672\n",
      "Epoch [1/10], Batch [210/1562], Loss: 0.2943\n",
      "Epoch [1/10], Batch [212/1562], Loss: 0.3358\n",
      "Epoch [1/10], Batch [214/1562], Loss: 0.3134\n",
      "Epoch [1/10], Batch [216/1562], Loss: 0.2780\n",
      "Epoch [1/10], Batch [218/1562], Loss: 0.2979\n",
      "Epoch [1/10], Batch [220/1562], Loss: 0.2460\n",
      "Epoch [1/10], Batch [222/1562], Loss: 0.2456\n",
      "Epoch [1/10], Batch [224/1562], Loss: 0.2732\n",
      "Epoch [1/10], Batch [226/1562], Loss: 0.2616\n",
      "Epoch [1/10], Batch [228/1562], Loss: 0.3010\n",
      "Epoch [1/10], Batch [230/1562], Loss: 0.2491\n",
      "Epoch [1/10], Batch [232/1562], Loss: 0.3002\n",
      "Epoch [1/10], Batch [234/1562], Loss: 0.2825\n",
      "Epoch [1/10], Batch [236/1562], Loss: 0.2541\n",
      "Epoch [1/10], Batch [238/1562], Loss: 0.2800\n",
      "Epoch [1/10], Batch [240/1562], Loss: 0.2429\n",
      "Epoch [1/10], Batch [242/1562], Loss: 0.2277\n",
      "Epoch [1/10], Batch [244/1562], Loss: 0.2898\n",
      "Epoch [1/10], Batch [246/1562], Loss: 0.3310\n",
      "Epoch [1/10], Batch [248/1562], Loss: 0.2880\n",
      "Epoch [1/10], Batch [250/1562], Loss: 0.3064\n",
      "Epoch [1/10], Batch [252/1562], Loss: 0.3052\n",
      "Epoch [1/10], Batch [254/1562], Loss: 0.3034\n",
      "Epoch [1/10], Batch [256/1562], Loss: 0.2823\n",
      "Epoch [1/10], Batch [258/1562], Loss: 0.3034\n",
      "Epoch [1/10], Batch [260/1562], Loss: 0.2353\n",
      "Epoch [1/10], Batch [262/1562], Loss: 0.3162\n",
      "Epoch [1/10], Batch [264/1562], Loss: 0.2654\n",
      "Epoch [1/10], Batch [266/1562], Loss: 0.3169\n",
      "Epoch [1/10], Batch [268/1562], Loss: 0.3167\n",
      "Epoch [1/10], Batch [270/1562], Loss: 0.2832\n",
      "Epoch [1/10], Batch [272/1562], Loss: 0.2686\n",
      "Epoch [1/10], Batch [274/1562], Loss: 0.2772\n",
      "Epoch [1/10], Batch [276/1562], Loss: 0.2934\n",
      "Epoch [1/10], Batch [278/1562], Loss: 0.3336\n",
      "Epoch [1/10], Batch [280/1562], Loss: 0.3076\n",
      "Epoch [1/10], Batch [282/1562], Loss: 0.3194\n",
      "Epoch [1/10], Batch [284/1562], Loss: 0.2673\n",
      "Epoch [1/10], Batch [286/1562], Loss: 0.2825\n",
      "Epoch [1/10], Batch [288/1562], Loss: 0.2966\n",
      "Epoch [1/10], Batch [290/1562], Loss: 0.3207\n",
      "Epoch [1/10], Batch [292/1562], Loss: 0.3139\n",
      "Epoch [1/10], Batch [294/1562], Loss: 0.2476\n",
      "Epoch [1/10], Batch [296/1562], Loss: 0.3125\n",
      "Epoch [1/10], Batch [298/1562], Loss: 0.2792\n",
      "Epoch [1/10], Batch [300/1562], Loss: 0.2386\n",
      "Epoch [1/10], Batch [302/1562], Loss: 0.2722\n",
      "Epoch [1/10], Batch [304/1562], Loss: 0.3509\n",
      "Epoch [1/10], Batch [306/1562], Loss: 0.2419\n",
      "Epoch [1/10], Batch [308/1562], Loss: 0.3045\n",
      "Epoch [1/10], Batch [310/1562], Loss: 0.3010\n",
      "Epoch [1/10], Batch [312/1562], Loss: 0.2385\n",
      "Epoch [1/10], Batch [314/1562], Loss: 0.2928\n",
      "Epoch [1/10], Batch [316/1562], Loss: 0.3067\n",
      "Epoch [1/10], Batch [318/1562], Loss: 0.2968\n",
      "Epoch [1/10], Batch [320/1562], Loss: 0.3121\n",
      "Epoch [1/10], Batch [322/1562], Loss: 0.3023\n",
      "Epoch [1/10], Batch [324/1562], Loss: 0.3157\n",
      "Epoch [1/10], Batch [326/1562], Loss: 0.2776\n",
      "Epoch [1/10], Batch [328/1562], Loss: 0.2756\n",
      "Epoch [1/10], Batch [330/1562], Loss: 0.2902\n",
      "Epoch [1/10], Batch [332/1562], Loss: 0.2858\n",
      "Epoch [1/10], Batch [334/1562], Loss: 0.2917\n",
      "Epoch [1/10], Batch [336/1562], Loss: 0.2502\n",
      "Epoch [1/10], Batch [338/1562], Loss: 0.3182\n",
      "Epoch [1/10], Batch [340/1562], Loss: 0.3009\n",
      "Epoch [1/10], Batch [342/1562], Loss: 0.3100\n",
      "Epoch [1/10], Batch [344/1562], Loss: 0.2940\n",
      "Epoch [1/10], Batch [346/1562], Loss: 0.3185\n",
      "Epoch [1/10], Batch [348/1562], Loss: 0.2542\n",
      "Epoch [1/10], Batch [350/1562], Loss: 0.2573\n",
      "Epoch [1/10], Batch [352/1562], Loss: 0.2899\n",
      "Epoch [1/10], Batch [354/1562], Loss: 0.2976\n",
      "Epoch [1/10], Batch [356/1562], Loss: 0.3002\n",
      "Epoch [1/10], Batch [358/1562], Loss: 0.2819\n",
      "Epoch [1/10], Batch [360/1562], Loss: 0.2946\n",
      "Epoch [1/10], Batch [362/1562], Loss: 0.2645\n",
      "Epoch [1/10], Batch [364/1562], Loss: 0.2749\n",
      "Epoch [1/10], Batch [366/1562], Loss: 0.2891\n",
      "Epoch [1/10], Batch [368/1562], Loss: 0.2968\n",
      "Epoch [1/10], Batch [370/1562], Loss: 0.2652\n",
      "Epoch [1/10], Batch [372/1562], Loss: 0.2876\n",
      "Epoch [1/10], Batch [374/1562], Loss: 0.2615\n",
      "Epoch [1/10], Batch [376/1562], Loss: 0.3209\n",
      "Epoch [1/10], Batch [378/1562], Loss: 0.3152\n",
      "Epoch [1/10], Batch [380/1562], Loss: 0.2815\n",
      "Epoch [1/10], Batch [382/1562], Loss: 0.2829\n",
      "Epoch [1/10], Batch [384/1562], Loss: 0.2835\n",
      "Epoch [1/10], Batch [386/1562], Loss: 0.2842\n",
      "Epoch [1/10], Batch [388/1562], Loss: 0.3062\n",
      "Epoch [1/10], Batch [390/1562], Loss: 0.2694\n",
      "Epoch [1/10], Batch [392/1562], Loss: 0.2884\n",
      "Epoch [1/10], Batch [394/1562], Loss: 0.2793\n",
      "Epoch [1/10], Batch [396/1562], Loss: 0.2981\n",
      "Epoch [1/10], Batch [398/1562], Loss: 0.2547\n",
      "Epoch [1/10], Batch [400/1562], Loss: 0.3117\n",
      "Epoch [1/10], Batch [402/1562], Loss: 0.2549\n",
      "Epoch [1/10], Batch [404/1562], Loss: 0.2582\n",
      "Epoch [1/10], Batch [406/1562], Loss: 0.2912\n",
      "Epoch [1/10], Batch [408/1562], Loss: 0.2987\n",
      "Epoch [1/10], Batch [410/1562], Loss: 0.3069\n",
      "Epoch [1/10], Batch [412/1562], Loss: 0.3250\n",
      "Epoch [1/10], Batch [414/1562], Loss: 0.2950\n",
      "Epoch [1/10], Batch [416/1562], Loss: 0.2515\n",
      "Epoch [1/10], Batch [418/1562], Loss: 0.3080\n",
      "Epoch [1/10], Batch [420/1562], Loss: 0.2677\n",
      "Epoch [1/10], Batch [422/1562], Loss: 0.3297\n",
      "Epoch [1/10], Batch [424/1562], Loss: 0.2730\n",
      "Epoch [1/10], Batch [426/1562], Loss: 0.2697\n",
      "Epoch [1/10], Batch [428/1562], Loss: 0.2871\n",
      "Epoch [1/10], Batch [430/1562], Loss: 0.2410\n",
      "Epoch [1/10], Batch [432/1562], Loss: 0.2583\n",
      "Epoch [1/10], Batch [434/1562], Loss: 0.2769\n",
      "Epoch [1/10], Batch [436/1562], Loss: 0.2714\n",
      "Epoch [1/10], Batch [438/1562], Loss: 0.2700\n",
      "Epoch [1/10], Batch [440/1562], Loss: 0.2834\n",
      "Epoch [1/10], Batch [442/1562], Loss: 0.3164\n",
      "Epoch [1/10], Batch [444/1562], Loss: 0.2908\n",
      "Epoch [1/10], Batch [446/1562], Loss: 0.3137\n",
      "Epoch [1/10], Batch [448/1562], Loss: 0.3209\n",
      "Epoch [1/10], Batch [450/1562], Loss: 0.3114\n",
      "Epoch [1/10], Batch [452/1562], Loss: 0.2767\n",
      "Epoch [1/10], Batch [454/1562], Loss: 0.2771\n",
      "Epoch [1/10], Batch [456/1562], Loss: 0.2802\n",
      "Epoch [1/10], Batch [458/1562], Loss: 0.3071\n",
      "Epoch [1/10], Batch [460/1562], Loss: 0.2668\n",
      "Epoch [1/10], Batch [462/1562], Loss: 0.3314\n",
      "Epoch [1/10], Batch [464/1562], Loss: 0.3036\n",
      "Epoch [1/10], Batch [466/1562], Loss: 0.2991\n",
      "Epoch [1/10], Batch [468/1562], Loss: 0.2973\n",
      "Epoch [1/10], Batch [470/1562], Loss: 0.2787\n",
      "Epoch [1/10], Batch [472/1562], Loss: 0.2957\n",
      "Epoch [1/10], Batch [474/1562], Loss: 0.2733\n",
      "Epoch [1/10], Batch [476/1562], Loss: 0.2628\n",
      "Epoch [1/10], Batch [478/1562], Loss: 0.3123\n",
      "Epoch [1/10], Batch [480/1562], Loss: 0.2751\n",
      "Epoch [1/10], Batch [482/1562], Loss: 0.3052\n",
      "Epoch [1/10], Batch [484/1562], Loss: 0.2772\n",
      "Epoch [1/10], Batch [486/1562], Loss: 0.2213\n",
      "Epoch [1/10], Batch [488/1562], Loss: 0.2670\n",
      "Epoch [1/10], Batch [490/1562], Loss: 0.3176\n",
      "Epoch [1/10], Batch [492/1562], Loss: 0.2454\n",
      "Epoch [1/10], Batch [494/1562], Loss: 0.3001\n",
      "Epoch [1/10], Batch [496/1562], Loss: 0.3009\n",
      "Epoch [1/10], Batch [498/1562], Loss: 0.2478\n",
      "Epoch [1/10], Batch [500/1562], Loss: 0.2867\n",
      "Epoch [1/10], Batch [502/1562], Loss: 0.3148\n",
      "Epoch [1/10], Batch [504/1562], Loss: 0.2968\n",
      "Epoch [1/10], Batch [506/1562], Loss: 0.2969\n",
      "Epoch [1/10], Batch [508/1562], Loss: 0.3045\n",
      "Epoch [1/10], Batch [510/1562], Loss: 0.2758\n",
      "Epoch [1/10], Batch [512/1562], Loss: 0.2562\n",
      "Epoch [1/10], Batch [514/1562], Loss: 0.2761\n",
      "Epoch [1/10], Batch [516/1562], Loss: 0.2344\n",
      "Epoch [1/10], Batch [518/1562], Loss: 0.2527\n",
      "Epoch [1/10], Batch [520/1562], Loss: 0.2941\n",
      "Epoch [1/10], Batch [522/1562], Loss: 0.2851\n",
      "Epoch [1/10], Batch [524/1562], Loss: 0.2794\n",
      "Epoch [1/10], Batch [526/1562], Loss: 0.3020\n",
      "Epoch [1/10], Batch [528/1562], Loss: 0.2318\n",
      "Epoch [1/10], Batch [530/1562], Loss: 0.3330\n",
      "Epoch [1/10], Batch [532/1562], Loss: 0.2822\n",
      "Epoch [1/10], Batch [534/1562], Loss: 0.2685\n",
      "Epoch [1/10], Batch [536/1562], Loss: 0.3073\n",
      "Epoch [1/10], Batch [538/1562], Loss: 0.2768\n",
      "Epoch [1/10], Batch [540/1562], Loss: 0.2864\n",
      "Epoch [1/10], Batch [542/1562], Loss: 0.2885\n",
      "Epoch [1/10], Batch [544/1562], Loss: 0.2594\n",
      "Epoch [1/10], Batch [546/1562], Loss: 0.2763\n",
      "Epoch [1/10], Batch [548/1562], Loss: 0.2487\n",
      "Epoch [1/10], Batch [550/1562], Loss: 0.2872\n",
      "Epoch [1/10], Batch [552/1562], Loss: 0.2905\n",
      "Epoch [1/10], Batch [554/1562], Loss: 0.2622\n",
      "Epoch [1/10], Batch [556/1562], Loss: 0.3011\n",
      "Epoch [1/10], Batch [558/1562], Loss: 0.2815\n",
      "Epoch [1/10], Batch [560/1562], Loss: 0.2800\n",
      "Epoch [1/10], Batch [562/1562], Loss: 0.3194\n",
      "Epoch [1/10], Batch [564/1562], Loss: 0.2676\n",
      "Epoch [1/10], Batch [566/1562], Loss: 0.2740\n",
      "Epoch [1/10], Batch [568/1562], Loss: 0.3194\n",
      "Epoch [1/10], Batch [570/1562], Loss: 0.2544\n",
      "Epoch [1/10], Batch [572/1562], Loss: 0.3148\n",
      "Epoch [1/10], Batch [574/1562], Loss: 0.2409\n",
      "Epoch [1/10], Batch [576/1562], Loss: 0.2757\n",
      "Epoch [1/10], Batch [578/1562], Loss: 0.2439\n",
      "Epoch [1/10], Batch [580/1562], Loss: 0.2657\n",
      "Epoch [1/10], Batch [582/1562], Loss: 0.3238\n",
      "Epoch [1/10], Batch [584/1562], Loss: 0.3578\n",
      "Epoch [1/10], Batch [586/1562], Loss: 0.3081\n",
      "Epoch [1/10], Batch [588/1562], Loss: 0.2846\n",
      "Epoch [1/10], Batch [590/1562], Loss: 0.2823\n",
      "Epoch [1/10], Batch [592/1562], Loss: 0.2897\n",
      "Epoch [1/10], Batch [594/1562], Loss: 0.2929\n",
      "Epoch [1/10], Batch [596/1562], Loss: 0.2983\n",
      "Epoch [1/10], Batch [598/1562], Loss: 0.3061\n",
      "Epoch [1/10], Batch [600/1562], Loss: 0.3004\n",
      "Epoch [1/10], Batch [602/1562], Loss: 0.2847\n",
      "Epoch [1/10], Batch [604/1562], Loss: 0.2986\n",
      "Epoch [1/10], Batch [606/1562], Loss: 0.2814\n",
      "Epoch [1/10], Batch [608/1562], Loss: 0.2415\n",
      "Epoch [1/10], Batch [610/1562], Loss: 0.2758\n",
      "Epoch [1/10], Batch [612/1562], Loss: 0.2827\n",
      "Epoch [1/10], Batch [614/1562], Loss: 0.2677\n",
      "Epoch [1/10], Batch [616/1562], Loss: 0.3055\n",
      "Epoch [1/10], Batch [618/1562], Loss: 0.3156\n",
      "Epoch [1/10], Batch [620/1562], Loss: 0.2815\n",
      "Epoch [1/10], Batch [622/1562], Loss: 0.3224\n",
      "Epoch [1/10], Batch [624/1562], Loss: 0.3002\n",
      "Epoch [1/10], Batch [626/1562], Loss: 0.2832\n",
      "Epoch [1/10], Batch [628/1562], Loss: 0.2907\n",
      "Epoch [1/10], Batch [630/1562], Loss: 0.2928\n",
      "Epoch [1/10], Batch [632/1562], Loss: 0.2736\n",
      "Epoch [1/10], Batch [634/1562], Loss: 0.3035\n",
      "Epoch [1/10], Batch [636/1562], Loss: 0.2618\n",
      "Epoch [1/10], Batch [638/1562], Loss: 0.2779\n",
      "Epoch [1/10], Batch [640/1562], Loss: 0.2923\n",
      "Epoch [1/10], Batch [642/1562], Loss: 0.2775\n",
      "Epoch [1/10], Batch [644/1562], Loss: 0.3022\n",
      "Epoch [1/10], Batch [646/1562], Loss: 0.3206\n",
      "Epoch [1/10], Batch [648/1562], Loss: 0.2775\n",
      "Epoch [1/10], Batch [650/1562], Loss: 0.2854\n",
      "Epoch [1/10], Batch [652/1562], Loss: 0.3280\n",
      "Epoch [1/10], Batch [654/1562], Loss: 0.2739\n",
      "Epoch [1/10], Batch [656/1562], Loss: 0.2854\n",
      "Epoch [1/10], Batch [658/1562], Loss: 0.2454\n",
      "Epoch [1/10], Batch [660/1562], Loss: 0.2884\n",
      "Epoch [1/10], Batch [662/1562], Loss: 0.2910\n",
      "Epoch [1/10], Batch [664/1562], Loss: 0.2896\n",
      "Epoch [1/10], Batch [666/1562], Loss: 0.2535\n",
      "Epoch [1/10], Batch [668/1562], Loss: 0.2952\n",
      "Epoch [1/10], Batch [670/1562], Loss: 0.2855\n",
      "Epoch [1/10], Batch [672/1562], Loss: 0.2832\n",
      "Epoch [1/10], Batch [674/1562], Loss: 0.2731\n",
      "Epoch [1/10], Batch [676/1562], Loss: 0.3344\n",
      "Epoch [1/10], Batch [678/1562], Loss: 0.3086\n",
      "Epoch [1/10], Batch [680/1562], Loss: 0.2309\n",
      "Epoch [1/10], Batch [682/1562], Loss: 0.2960\n",
      "Epoch [1/10], Batch [684/1562], Loss: 0.2868\n",
      "Epoch [1/10], Batch [686/1562], Loss: 0.2641\n",
      "Epoch [1/10], Batch [688/1562], Loss: 0.2607\n",
      "Epoch [1/10], Batch [690/1562], Loss: 0.2551\n",
      "Epoch [1/10], Batch [692/1562], Loss: 0.2851\n",
      "Epoch [1/10], Batch [694/1562], Loss: 0.2734\n",
      "Epoch [1/10], Batch [696/1562], Loss: 0.2760\n",
      "Epoch [1/10], Batch [698/1562], Loss: 0.2986\n",
      "Epoch [1/10], Batch [700/1562], Loss: 0.3269\n",
      "Epoch [1/10], Batch [702/1562], Loss: 0.2528\n",
      "Epoch [1/10], Batch [704/1562], Loss: 0.3055\n",
      "Epoch [1/10], Batch [706/1562], Loss: 0.2800\n",
      "Epoch [1/10], Batch [708/1562], Loss: 0.3227\n",
      "Epoch [1/10], Batch [710/1562], Loss: 0.2762\n",
      "Epoch [1/10], Batch [712/1562], Loss: 0.2914\n",
      "Epoch [1/10], Batch [714/1562], Loss: 0.2666\n",
      "Epoch [1/10], Batch [716/1562], Loss: 0.3096\n",
      "Epoch [1/10], Batch [718/1562], Loss: 0.3101\n",
      "Epoch [1/10], Batch [720/1562], Loss: 0.2770\n",
      "Epoch [1/10], Batch [722/1562], Loss: 0.3022\n",
      "Epoch [1/10], Batch [724/1562], Loss: 0.2633\n",
      "Epoch [1/10], Batch [726/1562], Loss: 0.2795\n",
      "Epoch [1/10], Batch [728/1562], Loss: 0.2669\n",
      "Epoch [1/10], Batch [730/1562], Loss: 0.2695\n",
      "Epoch [1/10], Batch [732/1562], Loss: 0.2743\n",
      "Epoch [1/10], Batch [734/1562], Loss: 0.2460\n",
      "Epoch [1/10], Batch [736/1562], Loss: 0.2779\n",
      "Epoch [1/10], Batch [738/1562], Loss: 0.3235\n",
      "Epoch [1/10], Batch [740/1562], Loss: 0.2779\n",
      "Epoch [1/10], Batch [742/1562], Loss: 0.2486\n",
      "Epoch [1/10], Batch [744/1562], Loss: 0.2434\n",
      "Epoch [1/10], Batch [746/1562], Loss: 0.2731\n",
      "Epoch [1/10], Batch [748/1562], Loss: 0.2877\n",
      "Epoch [1/10], Batch [750/1562], Loss: 0.2606\n",
      "Epoch [1/10], Batch [752/1562], Loss: 0.2876\n",
      "Epoch [1/10], Batch [754/1562], Loss: 0.2640\n",
      "Epoch [1/10], Batch [756/1562], Loss: 0.2792\n",
      "Epoch [1/10], Batch [758/1562], Loss: 0.2955\n",
      "Epoch [1/10], Batch [760/1562], Loss: 0.2466\n",
      "Epoch [1/10], Batch [762/1562], Loss: 0.2614\n",
      "Epoch [1/10], Batch [764/1562], Loss: 0.2681\n",
      "Epoch [1/10], Batch [766/1562], Loss: 0.2753\n",
      "Epoch [1/10], Batch [768/1562], Loss: 0.3192\n",
      "Epoch [1/10], Batch [770/1562], Loss: 0.2789\n",
      "Epoch [1/10], Batch [772/1562], Loss: 0.2865\n",
      "Epoch [1/10], Batch [774/1562], Loss: 0.2445\n",
      "Epoch [1/10], Batch [776/1562], Loss: 0.2836\n",
      "Epoch [1/10], Batch [778/1562], Loss: 0.3025\n",
      "Epoch [1/10], Batch [780/1562], Loss: 0.2726\n",
      "Epoch [1/10], Batch [782/1562], Loss: 0.3037\n",
      "Epoch [1/10], Batch [784/1562], Loss: 0.2716\n",
      "Epoch [1/10], Batch [786/1562], Loss: 0.3286\n",
      "Epoch [1/10], Batch [788/1562], Loss: 0.2725\n",
      "Epoch [1/10], Batch [790/1562], Loss: 0.3150\n",
      "Epoch [1/10], Batch [792/1562], Loss: 0.2792\n",
      "Epoch [1/10], Batch [794/1562], Loss: 0.2843\n",
      "Epoch [1/10], Batch [796/1562], Loss: 0.2919\n",
      "Epoch [1/10], Batch [798/1562], Loss: 0.2741\n",
      "Epoch [1/10], Batch [800/1562], Loss: 0.3046\n",
      "Epoch [1/10], Batch [802/1562], Loss: 0.2445\n",
      "Epoch [1/10], Batch [804/1562], Loss: 0.3039\n",
      "Epoch [1/10], Batch [806/1562], Loss: 0.3032\n",
      "Epoch [1/10], Batch [808/1562], Loss: 0.2833\n",
      "Epoch [1/10], Batch [810/1562], Loss: 0.2835\n",
      "Epoch [1/10], Batch [812/1562], Loss: 0.2823\n",
      "Epoch [1/10], Batch [814/1562], Loss: 0.2883\n",
      "Epoch [1/10], Batch [816/1562], Loss: 0.2829\n",
      "Epoch [1/10], Batch [818/1562], Loss: 0.3072\n",
      "Epoch [1/10], Batch [820/1562], Loss: 0.2983\n",
      "Epoch [1/10], Batch [822/1562], Loss: 0.2948\n",
      "Epoch [1/10], Batch [824/1562], Loss: 0.2905\n",
      "Epoch [1/10], Batch [826/1562], Loss: 0.2487\n",
      "Epoch [1/10], Batch [828/1562], Loss: 0.2677\n",
      "Epoch [1/10], Batch [830/1562], Loss: 0.2917\n",
      "Epoch [1/10], Batch [832/1562], Loss: 0.2704\n",
      "Epoch [1/10], Batch [834/1562], Loss: 0.2583\n",
      "Epoch [1/10], Batch [836/1562], Loss: 0.2771\n",
      "Epoch [1/10], Batch [838/1562], Loss: 0.2839\n",
      "Epoch [1/10], Batch [840/1562], Loss: 0.2990\n",
      "Epoch [1/10], Batch [842/1562], Loss: 0.2980\n",
      "Epoch [1/10], Batch [844/1562], Loss: 0.3005\n",
      "Epoch [1/10], Batch [846/1562], Loss: 0.3271\n",
      "Epoch [1/10], Batch [848/1562], Loss: 0.3166\n",
      "Epoch [1/10], Batch [850/1562], Loss: 0.2920\n",
      "Epoch [1/10], Batch [852/1562], Loss: 0.3195\n",
      "Epoch [1/10], Batch [854/1562], Loss: 0.2586\n",
      "Epoch [1/10], Batch [856/1562], Loss: 0.2874\n",
      "Epoch [1/10], Batch [858/1562], Loss: 0.3240\n",
      "Epoch [1/10], Batch [860/1562], Loss: 0.3038\n",
      "Epoch [1/10], Batch [862/1562], Loss: 0.2774\n",
      "Epoch [1/10], Batch [864/1562], Loss: 0.2779\n",
      "Epoch [1/10], Batch [866/1562], Loss: 0.2540\n",
      "Epoch [1/10], Batch [868/1562], Loss: 0.2784\n",
      "Epoch [1/10], Batch [870/1562], Loss: 0.2671\n",
      "Epoch [1/10], Batch [872/1562], Loss: 0.3079\n",
      "Epoch [1/10], Batch [874/1562], Loss: 0.2920\n",
      "Epoch [1/10], Batch [876/1562], Loss: 0.2974\n",
      "Epoch [1/10], Batch [878/1562], Loss: 0.2793\n",
      "Epoch [1/10], Batch [880/1562], Loss: 0.2547\n",
      "Epoch [1/10], Batch [882/1562], Loss: 0.2794\n",
      "Epoch [1/10], Batch [884/1562], Loss: 0.2528\n",
      "Epoch [1/10], Batch [886/1562], Loss: 0.2252\n",
      "Epoch [1/10], Batch [888/1562], Loss: 0.2773\n",
      "Epoch [1/10], Batch [890/1562], Loss: 0.2661\n",
      "Epoch [1/10], Batch [892/1562], Loss: 0.3017\n",
      "Epoch [1/10], Batch [894/1562], Loss: 0.2411\n",
      "Epoch [1/10], Batch [896/1562], Loss: 0.3329\n",
      "Epoch [1/10], Batch [898/1562], Loss: 0.2952\n",
      "Epoch [1/10], Batch [900/1562], Loss: 0.3515\n",
      "Epoch [1/10], Batch [902/1562], Loss: 0.2888\n",
      "Epoch [1/10], Batch [904/1562], Loss: 0.2765\n",
      "Epoch [1/10], Batch [906/1562], Loss: 0.2569\n",
      "Epoch [1/10], Batch [908/1562], Loss: 0.2663\n",
      "Epoch [1/10], Batch [910/1562], Loss: 0.2877\n",
      "Epoch [1/10], Batch [912/1562], Loss: 0.2802\n",
      "Epoch [1/10], Batch [914/1562], Loss: 0.2733\n",
      "Epoch [1/10], Batch [916/1562], Loss: 0.2719\n",
      "Epoch [1/10], Batch [918/1562], Loss: 0.2734\n",
      "Epoch [1/10], Batch [920/1562], Loss: 0.3001\n",
      "Epoch [1/10], Batch [922/1562], Loss: 0.2818\n",
      "Epoch [1/10], Batch [924/1562], Loss: 0.2490\n",
      "Epoch [1/10], Batch [926/1562], Loss: 0.3005\n",
      "Epoch [1/10], Batch [928/1562], Loss: 0.3043\n",
      "Epoch [1/10], Batch [930/1562], Loss: 0.2437\n",
      "Epoch [1/10], Batch [932/1562], Loss: 0.3251\n",
      "Epoch [1/10], Batch [934/1562], Loss: 0.2569\n",
      "Epoch [1/10], Batch [936/1562], Loss: 0.2693\n",
      "Epoch [1/10], Batch [938/1562], Loss: 0.2825\n",
      "Epoch [1/10], Batch [940/1562], Loss: 0.3333\n",
      "Epoch [1/10], Batch [942/1562], Loss: 0.2848\n",
      "Epoch [1/10], Batch [944/1562], Loss: 0.3008\n",
      "Epoch [1/10], Batch [946/1562], Loss: 0.3140\n",
      "Epoch [1/10], Batch [948/1562], Loss: 0.3196\n",
      "Epoch [1/10], Batch [950/1562], Loss: 0.2856\n",
      "Epoch [1/10], Batch [952/1562], Loss: 0.2919\n",
      "Epoch [1/10], Batch [954/1562], Loss: 0.2934\n",
      "Epoch [1/10], Batch [956/1562], Loss: 0.3033\n",
      "Epoch [1/10], Batch [958/1562], Loss: 0.2846\n",
      "Epoch [1/10], Batch [960/1562], Loss: 0.3217\n",
      "Epoch [1/10], Batch [962/1562], Loss: 0.3013\n",
      "Epoch [1/10], Batch [964/1562], Loss: 0.2724\n",
      "Epoch [1/10], Batch [966/1562], Loss: 0.2852\n",
      "Epoch [1/10], Batch [968/1562], Loss: 0.2858\n",
      "Epoch [1/10], Batch [970/1562], Loss: 0.2754\n",
      "Epoch [1/10], Batch [972/1562], Loss: 0.2866\n",
      "Epoch [1/10], Batch [974/1562], Loss: 0.2956\n",
      "Epoch [1/10], Batch [976/1562], Loss: 0.3076\n",
      "Epoch [1/10], Batch [978/1562], Loss: 0.2898\n",
      "Epoch [1/10], Batch [980/1562], Loss: 0.2975\n",
      "Epoch [1/10], Batch [982/1562], Loss: 0.2930\n",
      "Epoch [1/10], Batch [984/1562], Loss: 0.3043\n",
      "Epoch [1/10], Batch [986/1562], Loss: 0.2842\n",
      "Epoch [1/10], Batch [988/1562], Loss: 0.3162\n",
      "Epoch [1/10], Batch [990/1562], Loss: 0.3023\n",
      "Epoch [1/10], Batch [992/1562], Loss: 0.2842\n",
      "Epoch [1/10], Batch [994/1562], Loss: 0.2415\n",
      "Epoch [1/10], Batch [996/1562], Loss: 0.2561\n",
      "Epoch [1/10], Batch [998/1562], Loss: 0.2990\n",
      "Epoch [1/10], Batch [1000/1562], Loss: 0.2505\n",
      "Epoch [1/10], Batch [1002/1562], Loss: 0.2522\n",
      "Epoch [1/10], Batch [1004/1562], Loss: 0.3031\n",
      "Epoch [1/10], Batch [1006/1562], Loss: 0.3169\n",
      "Epoch [1/10], Batch [1008/1562], Loss: 0.2972\n",
      "Epoch [1/10], Batch [1010/1562], Loss: 0.2804\n",
      "Epoch [1/10], Batch [1012/1562], Loss: 0.3129\n",
      "Epoch [1/10], Batch [1014/1562], Loss: 0.2561\n",
      "Epoch [1/10], Batch [1016/1562], Loss: 0.2819\n",
      "Epoch [1/10], Batch [1018/1562], Loss: 0.2745\n",
      "Epoch [1/10], Batch [1020/1562], Loss: 0.2715\n",
      "Epoch [1/10], Batch [1022/1562], Loss: 0.2921\n",
      "Epoch [1/10], Batch [1024/1562], Loss: 0.2600\n",
      "Epoch [1/10], Batch [1026/1562], Loss: 0.2985\n",
      "Epoch [1/10], Batch [1028/1562], Loss: 0.2636\n",
      "Epoch [1/10], Batch [1030/1562], Loss: 0.2862\n",
      "Epoch [1/10], Batch [1032/1562], Loss: 0.2945\n",
      "Epoch [1/10], Batch [1034/1562], Loss: 0.2905\n",
      "Epoch [1/10], Batch [1036/1562], Loss: 0.3140\n",
      "Epoch [1/10], Batch [1038/1562], Loss: 0.3065\n",
      "Epoch [1/10], Batch [1040/1562], Loss: 0.2637\n",
      "Epoch [1/10], Batch [1042/1562], Loss: 0.2729\n",
      "Epoch [1/10], Batch [1044/1562], Loss: 0.2843\n",
      "Epoch [1/10], Batch [1046/1562], Loss: 0.2625\n",
      "Epoch [1/10], Batch [1048/1562], Loss: 0.2888\n",
      "Epoch [1/10], Batch [1050/1562], Loss: 0.2669\n",
      "Epoch [1/10], Batch [1052/1562], Loss: 0.2795\n",
      "Epoch [1/10], Batch [1054/1562], Loss: 0.2792\n",
      "Epoch [1/10], Batch [1056/1562], Loss: 0.2909\n",
      "Epoch [1/10], Batch [1058/1562], Loss: 0.2686\n",
      "Epoch [1/10], Batch [1060/1562], Loss: 0.3187\n",
      "Epoch [1/10], Batch [1062/1562], Loss: 0.2861\n",
      "Epoch [1/10], Batch [1064/1562], Loss: 0.2615\n",
      "Epoch [1/10], Batch [1066/1562], Loss: 0.2899\n",
      "Epoch [1/10], Batch [1068/1562], Loss: 0.3005\n",
      "Epoch [1/10], Batch [1070/1562], Loss: 0.3158\n",
      "Epoch [1/10], Batch [1072/1562], Loss: 0.3265\n",
      "Epoch [1/10], Batch [1074/1562], Loss: 0.3281\n",
      "Epoch [1/10], Batch [1076/1562], Loss: 0.2871\n",
      "Epoch [1/10], Batch [1078/1562], Loss: 0.2949\n",
      "Epoch [1/10], Batch [1080/1562], Loss: 0.2992\n",
      "Epoch [1/10], Batch [1082/1562], Loss: 0.2787\n",
      "Epoch [1/10], Batch [1084/1562], Loss: 0.2769\n",
      "Epoch [1/10], Batch [1086/1562], Loss: 0.2834\n",
      "Epoch [1/10], Batch [1088/1562], Loss: 0.2553\n",
      "Epoch [1/10], Batch [1090/1562], Loss: 0.2714\n",
      "Epoch [1/10], Batch [1092/1562], Loss: 0.2898\n",
      "Epoch [1/10], Batch [1094/1562], Loss: 0.2703\n",
      "Epoch [1/10], Batch [1096/1562], Loss: 0.2847\n",
      "Epoch [1/10], Batch [1098/1562], Loss: 0.2926\n",
      "Epoch [1/10], Batch [1100/1562], Loss: 0.2315\n",
      "Epoch [1/10], Batch [1102/1562], Loss: 0.2619\n",
      "Epoch [1/10], Batch [1104/1562], Loss: 0.2747\n",
      "Epoch [1/10], Batch [1106/1562], Loss: 0.3012\n",
      "Epoch [1/10], Batch [1108/1562], Loss: 0.2753\n",
      "Epoch [1/10], Batch [1110/1562], Loss: 0.2861\n",
      "Epoch [1/10], Batch [1112/1562], Loss: 0.2907\n",
      "Epoch [1/10], Batch [1114/1562], Loss: 0.2841\n",
      "Epoch [1/10], Batch [1116/1562], Loss: 0.3121\n",
      "Epoch [1/10], Batch [1118/1562], Loss: 0.3133\n",
      "Epoch [1/10], Batch [1120/1562], Loss: 0.3032\n",
      "Epoch [1/10], Batch [1122/1562], Loss: 0.2828\n",
      "Epoch [1/10], Batch [1124/1562], Loss: 0.3200\n",
      "Epoch [1/10], Batch [1126/1562], Loss: 0.2542\n",
      "Epoch [1/10], Batch [1128/1562], Loss: 0.2623\n",
      "Epoch [1/10], Batch [1130/1562], Loss: 0.2854\n",
      "Epoch [1/10], Batch [1132/1562], Loss: 0.2835\n",
      "Epoch [1/10], Batch [1134/1562], Loss: 0.2858\n",
      "Epoch [1/10], Batch [1136/1562], Loss: 0.2985\n",
      "Epoch [1/10], Batch [1138/1562], Loss: 0.2899\n",
      "Epoch [1/10], Batch [1140/1562], Loss: 0.3269\n",
      "Epoch [1/10], Batch [1142/1562], Loss: 0.3042\n",
      "Epoch [1/10], Batch [1144/1562], Loss: 0.3119\n",
      "Epoch [1/10], Batch [1146/1562], Loss: 0.2845\n",
      "Epoch [1/10], Batch [1148/1562], Loss: 0.2540\n",
      "Epoch [1/10], Batch [1150/1562], Loss: 0.3249\n",
      "Epoch [1/10], Batch [1152/1562], Loss: 0.2936\n",
      "Epoch [1/10], Batch [1154/1562], Loss: 0.2812\n",
      "Epoch [1/10], Batch [1156/1562], Loss: 0.2554\n",
      "Epoch [1/10], Batch [1158/1562], Loss: 0.3085\n",
      "Epoch [1/10], Batch [1160/1562], Loss: 0.3089\n",
      "Epoch [1/10], Batch [1162/1562], Loss: 0.2937\n",
      "Epoch [1/10], Batch [1164/1562], Loss: 0.2743\n",
      "Epoch [1/10], Batch [1166/1562], Loss: 0.2805\n",
      "Epoch [1/10], Batch [1168/1562], Loss: 0.2763\n",
      "Epoch [1/10], Batch [1170/1562], Loss: 0.3254\n",
      "Epoch [1/10], Batch [1172/1562], Loss: 0.3039\n",
      "Epoch [1/10], Batch [1174/1562], Loss: 0.2828\n",
      "Epoch [1/10], Batch [1176/1562], Loss: 0.2869\n",
      "Epoch [1/10], Batch [1178/1562], Loss: 0.2561\n",
      "Epoch [1/10], Batch [1180/1562], Loss: 0.2745\n",
      "Epoch [1/10], Batch [1182/1562], Loss: 0.2855\n",
      "Epoch [1/10], Batch [1184/1562], Loss: 0.2804\n",
      "Epoch [1/10], Batch [1186/1562], Loss: 0.3040\n",
      "Epoch [1/10], Batch [1188/1562], Loss: 0.3040\n",
      "Epoch [1/10], Batch [1190/1562], Loss: 0.3006\n",
      "Epoch [1/10], Batch [1192/1562], Loss: 0.2778\n",
      "Epoch [1/10], Batch [1194/1562], Loss: 0.3028\n",
      "Epoch [1/10], Batch [1196/1562], Loss: 0.3146\n",
      "Epoch [1/10], Batch [1198/1562], Loss: 0.2714\n",
      "Epoch [1/10], Batch [1200/1562], Loss: 0.3277\n",
      "Epoch [1/10], Batch [1202/1562], Loss: 0.2886\n",
      "Epoch [1/10], Batch [1204/1562], Loss: 0.2570\n",
      "Epoch [1/10], Batch [1206/1562], Loss: 0.2754\n",
      "Epoch [1/10], Batch [1208/1562], Loss: 0.2901\n",
      "Epoch [1/10], Batch [1210/1562], Loss: 0.2576\n",
      "Epoch [1/10], Batch [1212/1562], Loss: 0.2606\n",
      "Epoch [1/10], Batch [1214/1562], Loss: 0.3367\n",
      "Epoch [1/10], Batch [1216/1562], Loss: 0.3232\n",
      "Epoch [1/10], Batch [1218/1562], Loss: 0.2977\n",
      "Epoch [1/10], Batch [1220/1562], Loss: 0.2909\n",
      "Epoch [1/10], Batch [1222/1562], Loss: 0.2522\n",
      "Epoch [1/10], Batch [1224/1562], Loss: 0.3025\n",
      "Epoch [1/10], Batch [1226/1562], Loss: 0.2994\n",
      "Epoch [1/10], Batch [1228/1562], Loss: 0.2607\n",
      "Epoch [1/10], Batch [1230/1562], Loss: 0.2957\n",
      "Epoch [1/10], Batch [1232/1562], Loss: 0.3170\n",
      "Epoch [1/10], Batch [1234/1562], Loss: 0.3028\n",
      "Epoch [1/10], Batch [1236/1562], Loss: 0.2985\n",
      "Epoch [1/10], Batch [1238/1562], Loss: 0.2622\n",
      "Epoch [1/10], Batch [1240/1562], Loss: 0.2954\n",
      "Epoch [1/10], Batch [1242/1562], Loss: 0.2983\n",
      "Epoch [1/10], Batch [1244/1562], Loss: 0.2633\n",
      "Epoch [1/10], Batch [1246/1562], Loss: 0.2373\n",
      "Epoch [1/10], Batch [1248/1562], Loss: 0.2858\n",
      "Epoch [1/10], Batch [1250/1562], Loss: 0.2638\n",
      "Epoch [1/10], Batch [1252/1562], Loss: 0.3340\n",
      "Epoch [1/10], Batch [1254/1562], Loss: 0.2861\n",
      "Epoch [1/10], Batch [1256/1562], Loss: 0.2763\n",
      "Epoch [1/10], Batch [1258/1562], Loss: 0.2403\n",
      "Epoch [1/10], Batch [1260/1562], Loss: 0.2731\n",
      "Epoch [1/10], Batch [1262/1562], Loss: 0.3059\n",
      "Epoch [1/10], Batch [1264/1562], Loss: 0.3040\n",
      "Epoch [1/10], Batch [1266/1562], Loss: 0.2646\n",
      "Epoch [1/10], Batch [1268/1562], Loss: 0.2649\n",
      "Epoch [1/10], Batch [1270/1562], Loss: 0.2613\n",
      "Epoch [1/10], Batch [1272/1562], Loss: 0.2641\n",
      "Epoch [1/10], Batch [1274/1562], Loss: 0.3180\n",
      "Epoch [1/10], Batch [1276/1562], Loss: 0.2629\n",
      "Epoch [1/10], Batch [1278/1562], Loss: 0.2886\n",
      "Epoch [1/10], Batch [1280/1562], Loss: 0.2825\n",
      "Epoch [1/10], Batch [1282/1562], Loss: 0.2790\n",
      "Epoch [1/10], Batch [1284/1562], Loss: 0.2874\n",
      "Epoch [1/10], Batch [1286/1562], Loss: 0.2909\n",
      "Epoch [1/10], Batch [1288/1562], Loss: 0.2998\n",
      "Epoch [1/10], Batch [1290/1562], Loss: 0.2814\n",
      "Epoch [1/10], Batch [1292/1562], Loss: 0.3079\n",
      "Epoch [1/10], Batch [1294/1562], Loss: 0.2807\n",
      "Epoch [1/10], Batch [1296/1562], Loss: 0.2444\n",
      "Epoch [1/10], Batch [1298/1562], Loss: 0.3456\n",
      "Epoch [1/10], Batch [1300/1562], Loss: 0.2719\n",
      "Epoch [1/10], Batch [1302/1562], Loss: 0.2885\n",
      "Epoch [1/10], Batch [1304/1562], Loss: 0.3011\n",
      "Epoch [1/10], Batch [1306/1562], Loss: 0.3057\n",
      "Epoch [1/10], Batch [1308/1562], Loss: 0.2821\n",
      "Epoch [1/10], Batch [1310/1562], Loss: 0.2866\n",
      "Epoch [1/10], Batch [1312/1562], Loss: 0.2480\n",
      "Epoch [1/10], Batch [1314/1562], Loss: 0.2560\n",
      "Epoch [1/10], Batch [1316/1562], Loss: 0.3130\n",
      "Epoch [1/10], Batch [1318/1562], Loss: 0.2983\n",
      "Epoch [1/10], Batch [1320/1562], Loss: 0.2887\n",
      "Epoch [1/10], Batch [1322/1562], Loss: 0.2596\n",
      "Epoch [1/10], Batch [1324/1562], Loss: 0.2524\n",
      "Epoch [1/10], Batch [1326/1562], Loss: 0.2641\n",
      "Epoch [1/10], Batch [1328/1562], Loss: 0.2786\n",
      "Epoch [1/10], Batch [1330/1562], Loss: 0.2768\n",
      "Epoch [1/10], Batch [1332/1562], Loss: 0.3161\n",
      "Epoch [1/10], Batch [1334/1562], Loss: 0.2742\n",
      "Epoch [1/10], Batch [1336/1562], Loss: 0.2960\n",
      "Epoch [1/10], Batch [1338/1562], Loss: 0.3165\n",
      "Epoch [1/10], Batch [1340/1562], Loss: 0.2820\n",
      "Epoch [1/10], Batch [1342/1562], Loss: 0.2806\n",
      "Epoch [1/10], Batch [1344/1562], Loss: 0.3161\n",
      "Epoch [1/10], Batch [1346/1562], Loss: 0.3113\n",
      "Epoch [1/10], Batch [1348/1562], Loss: 0.2826\n",
      "Epoch [1/10], Batch [1350/1562], Loss: 0.2995\n",
      "Epoch [1/10], Batch [1352/1562], Loss: 0.2838\n",
      "Epoch [1/10], Batch [1354/1562], Loss: 0.2953\n",
      "Epoch [1/10], Batch [1356/1562], Loss: 0.2810\n",
      "Epoch [1/10], Batch [1358/1562], Loss: 0.2948\n",
      "Epoch [1/10], Batch [1360/1562], Loss: 0.2764\n",
      "Epoch [1/10], Batch [1362/1562], Loss: 0.3363\n",
      "Epoch [1/10], Batch [1364/1562], Loss: 0.2842\n",
      "Epoch [1/10], Batch [1366/1562], Loss: 0.2830\n",
      "Epoch [1/10], Batch [1368/1562], Loss: 0.3002\n",
      "Epoch [1/10], Batch [1370/1562], Loss: 0.2578\n",
      "Epoch [1/10], Batch [1372/1562], Loss: 0.3351\n",
      "Epoch [1/10], Batch [1374/1562], Loss: 0.2869\n",
      "Epoch [1/10], Batch [1376/1562], Loss: 0.2478\n",
      "Epoch [1/10], Batch [1378/1562], Loss: 0.2845\n",
      "Epoch [1/10], Batch [1380/1562], Loss: 0.2761\n",
      "Epoch [1/10], Batch [1382/1562], Loss: 0.2460\n",
      "Epoch [1/10], Batch [1384/1562], Loss: 0.2798\n",
      "Epoch [1/10], Batch [1386/1562], Loss: 0.2671\n",
      "Epoch [1/10], Batch [1388/1562], Loss: 0.2887\n",
      "Epoch [1/10], Batch [1390/1562], Loss: 0.2712\n",
      "Epoch [1/10], Batch [1392/1562], Loss: 0.3162\n",
      "Epoch [1/10], Batch [1394/1562], Loss: 0.2715\n",
      "Epoch [1/10], Batch [1396/1562], Loss: 0.2646\n",
      "Epoch [1/10], Batch [1398/1562], Loss: 0.3073\n",
      "Epoch [1/10], Batch [1400/1562], Loss: 0.2739\n",
      "Epoch [1/10], Batch [1402/1562], Loss: 0.2854\n",
      "Epoch [1/10], Batch [1404/1562], Loss: 0.2752\n",
      "Epoch [1/10], Batch [1406/1562], Loss: 0.2815\n",
      "Epoch [1/10], Batch [1408/1562], Loss: 0.3091\n",
      "Epoch [1/10], Batch [1410/1562], Loss: 0.2866\n",
      "Epoch [1/10], Batch [1412/1562], Loss: 0.2991\n",
      "Epoch [1/10], Batch [1414/1562], Loss: 0.2474\n",
      "Epoch [1/10], Batch [1416/1562], Loss: 0.3172\n",
      "Epoch [1/10], Batch [1418/1562], Loss: 0.3209\n",
      "Epoch [1/10], Batch [1420/1562], Loss: 0.2628\n",
      "Epoch [1/10], Batch [1422/1562], Loss: 0.3138\n",
      "Epoch [1/10], Batch [1424/1562], Loss: 0.2833\n",
      "Epoch [1/10], Batch [1426/1562], Loss: 0.2882\n",
      "Epoch [1/10], Batch [1428/1562], Loss: 0.2758\n",
      "Epoch [1/10], Batch [1430/1562], Loss: 0.2480\n",
      "Epoch [1/10], Batch [1432/1562], Loss: 0.3077\n",
      "Epoch [1/10], Batch [1434/1562], Loss: 0.2861\n",
      "Epoch [1/10], Batch [1436/1562], Loss: 0.2678\n",
      "Epoch [1/10], Batch [1438/1562], Loss: 0.2765\n",
      "Epoch [1/10], Batch [1440/1562], Loss: 0.2691\n",
      "Epoch [1/10], Batch [1442/1562], Loss: 0.3032\n",
      "Epoch [1/10], Batch [1444/1562], Loss: 0.2720\n",
      "Epoch [1/10], Batch [1446/1562], Loss: 0.2840\n",
      "Epoch [1/10], Batch [1448/1562], Loss: 0.3037\n",
      "Epoch [1/10], Batch [1450/1562], Loss: 0.2765\n",
      "Epoch [1/10], Batch [1452/1562], Loss: 0.2837\n",
      "Epoch [1/10], Batch [1454/1562], Loss: 0.2607\n",
      "Epoch [1/10], Batch [1456/1562], Loss: 0.2494\n",
      "Epoch [1/10], Batch [1458/1562], Loss: 0.2778\n",
      "Epoch [1/10], Batch [1460/1562], Loss: 0.2976\n",
      "Epoch [1/10], Batch [1462/1562], Loss: 0.2652\n",
      "Epoch [1/10], Batch [1464/1562], Loss: 0.2865\n",
      "Epoch [1/10], Batch [1466/1562], Loss: 0.2480\n",
      "Epoch [1/10], Batch [1468/1562], Loss: 0.2951\n",
      "Epoch [1/10], Batch [1470/1562], Loss: 0.2861\n",
      "Epoch [1/10], Batch [1472/1562], Loss: 0.2580\n",
      "Epoch [1/10], Batch [1474/1562], Loss: 0.3067\n",
      "Epoch [1/10], Batch [1476/1562], Loss: 0.3345\n",
      "Epoch [1/10], Batch [1478/1562], Loss: 0.2643\n",
      "Epoch [1/10], Batch [1480/1562], Loss: 0.2785\n",
      "Epoch [1/10], Batch [1482/1562], Loss: 0.3276\n",
      "Epoch [1/10], Batch [1484/1562], Loss: 0.2968\n",
      "Epoch [1/10], Batch [1486/1562], Loss: 0.2488\n",
      "Epoch [1/10], Batch [1488/1562], Loss: 0.2763\n",
      "Epoch [1/10], Batch [1490/1562], Loss: 0.3430\n",
      "Epoch [1/10], Batch [1492/1562], Loss: 0.3112\n",
      "Epoch [1/10], Batch [1494/1562], Loss: 0.2437\n",
      "Epoch [1/10], Batch [1496/1562], Loss: 0.2852\n",
      "Epoch [1/10], Batch [1498/1562], Loss: 0.2937\n",
      "Epoch [1/10], Batch [1500/1562], Loss: 0.3296\n",
      "Epoch [1/10], Batch [1502/1562], Loss: 0.2482\n",
      "Epoch [1/10], Batch [1504/1562], Loss: 0.2966\n",
      "Epoch [1/10], Batch [1506/1562], Loss: 0.3057\n",
      "Epoch [1/10], Batch [1508/1562], Loss: 0.2903\n",
      "Epoch [1/10], Batch [1510/1562], Loss: 0.2622\n",
      "Epoch [1/10], Batch [1512/1562], Loss: 0.2594\n",
      "Epoch [1/10], Batch [1514/1562], Loss: 0.2675\n",
      "Epoch [1/10], Batch [1516/1562], Loss: 0.2637\n",
      "Epoch [1/10], Batch [1518/1562], Loss: 0.2655\n",
      "Epoch [1/10], Batch [1520/1562], Loss: 0.2995\n",
      "Epoch [1/10], Batch [1522/1562], Loss: 0.2893\n",
      "Epoch [1/10], Batch [1524/1562], Loss: 0.2654\n",
      "Epoch [1/10], Batch [1526/1562], Loss: 0.3225\n",
      "Epoch [1/10], Batch [1528/1562], Loss: 0.3215\n",
      "Epoch [1/10], Batch [1530/1562], Loss: 0.3176\n",
      "Epoch [1/10], Batch [1532/1562], Loss: 0.3058\n",
      "Epoch [1/10], Batch [1534/1562], Loss: 0.2782\n",
      "Epoch [1/10], Batch [1536/1562], Loss: 0.2959\n",
      "Epoch [1/10], Batch [1538/1562], Loss: 0.2925\n",
      "Epoch [1/10], Batch [1540/1562], Loss: 0.2794\n",
      "Epoch [1/10], Batch [1542/1562], Loss: 0.2911\n",
      "Epoch [1/10], Batch [1544/1562], Loss: 0.2971\n",
      "Epoch [1/10], Batch [1546/1562], Loss: 0.3037\n",
      "Epoch [1/10], Batch [1548/1562], Loss: 0.3024\n",
      "Epoch [1/10], Batch [1550/1562], Loss: 0.2739\n",
      "Epoch [1/10], Batch [1552/1562], Loss: 0.3292\n",
      "Epoch [1/10], Batch [1554/1562], Loss: 0.2941\n",
      "Epoch [1/10], Batch [1556/1562], Loss: 0.2882\n",
      "Epoch [1/10], Batch [1558/1562], Loss: 0.2963\n",
      "Epoch [1/10], Batch [1560/1562], Loss: 0.3336\n",
      "Epoch [1/10], Batch [1562/1562], Loss: 0.2769\n",
      "Epoch [1/10] completed. Average Loss: 0.2867\n",
      "Epoch [2/10], Batch [2/1562], Loss: 0.2621\n",
      "Epoch [2/10], Batch [4/1562], Loss: 0.3012\n",
      "Epoch [2/10], Batch [6/1562], Loss: 0.3079\n",
      "Epoch [2/10], Batch [8/1562], Loss: 0.2751\n",
      "Epoch [2/10], Batch [10/1562], Loss: 0.2849\n",
      "Epoch [2/10], Batch [12/1562], Loss: 0.2891\n",
      "Epoch [2/10], Batch [14/1562], Loss: 0.3258\n",
      "Epoch [2/10], Batch [16/1562], Loss: 0.2630\n",
      "Epoch [2/10], Batch [18/1562], Loss: 0.2531\n",
      "Epoch [2/10], Batch [20/1562], Loss: 0.3131\n",
      "Epoch [2/10], Batch [22/1562], Loss: 0.2752\n",
      "Epoch [2/10], Batch [24/1562], Loss: 0.2584\n",
      "Epoch [2/10], Batch [26/1562], Loss: 0.2795\n",
      "Epoch [2/10], Batch [28/1562], Loss: 0.2667\n",
      "Epoch [2/10], Batch [30/1562], Loss: 0.2925\n",
      "Epoch [2/10], Batch [32/1562], Loss: 0.2815\n",
      "Epoch [2/10], Batch [34/1562], Loss: 0.2751\n",
      "Epoch [2/10], Batch [36/1562], Loss: 0.2752\n",
      "Epoch [2/10], Batch [38/1562], Loss: 0.2710\n",
      "Epoch [2/10], Batch [40/1562], Loss: 0.3082\n",
      "Epoch [2/10], Batch [42/1562], Loss: 0.3090\n",
      "Epoch [2/10], Batch [44/1562], Loss: 0.2511\n",
      "Epoch [2/10], Batch [46/1562], Loss: 0.2524\n",
      "Epoch [2/10], Batch [48/1562], Loss: 0.2875\n",
      "Epoch [2/10], Batch [50/1562], Loss: 0.2932\n",
      "Epoch [2/10], Batch [52/1562], Loss: 0.2791\n",
      "Epoch [2/10], Batch [54/1562], Loss: 0.2759\n",
      "Epoch [2/10], Batch [56/1562], Loss: 0.2863\n",
      "Epoch [2/10], Batch [58/1562], Loss: 0.3077\n",
      "Epoch [2/10], Batch [60/1562], Loss: 0.3008\n",
      "Epoch [2/10], Batch [62/1562], Loss: 0.2590\n",
      "Epoch [2/10], Batch [64/1562], Loss: 0.2492\n",
      "Epoch [2/10], Batch [66/1562], Loss: 0.3218\n",
      "Epoch [2/10], Batch [68/1562], Loss: 0.2756\n",
      "Epoch [2/10], Batch [70/1562], Loss: 0.3013\n",
      "Epoch [2/10], Batch [72/1562], Loss: 0.3121\n",
      "Epoch [2/10], Batch [74/1562], Loss: 0.2597\n",
      "Epoch [2/10], Batch [76/1562], Loss: 0.2941\n",
      "Epoch [2/10], Batch [78/1562], Loss: 0.3101\n",
      "Epoch [2/10], Batch [80/1562], Loss: 0.3010\n",
      "Epoch [2/10], Batch [82/1562], Loss: 0.2731\n",
      "Epoch [2/10], Batch [84/1562], Loss: 0.3028\n",
      "Epoch [2/10], Batch [86/1562], Loss: 0.2930\n",
      "Epoch [2/10], Batch [88/1562], Loss: 0.2498\n",
      "Epoch [2/10], Batch [90/1562], Loss: 0.2939\n",
      "Epoch [2/10], Batch [92/1562], Loss: 0.2898\n",
      "Epoch [2/10], Batch [94/1562], Loss: 0.2573\n",
      "Epoch [2/10], Batch [96/1562], Loss: 0.3021\n",
      "Epoch [2/10], Batch [98/1562], Loss: 0.2690\n",
      "Epoch [2/10], Batch [100/1562], Loss: 0.2655\n",
      "Epoch [2/10], Batch [102/1562], Loss: 0.3058\n",
      "Epoch [2/10], Batch [104/1562], Loss: 0.2819\n",
      "Epoch [2/10], Batch [106/1562], Loss: 0.2836\n",
      "Epoch [2/10], Batch [108/1562], Loss: 0.3067\n",
      "Epoch [2/10], Batch [110/1562], Loss: 0.2436\n",
      "Epoch [2/10], Batch [112/1562], Loss: 0.3026\n",
      "Epoch [2/10], Batch [114/1562], Loss: 0.2566\n",
      "Epoch [2/10], Batch [116/1562], Loss: 0.2775\n",
      "Epoch [2/10], Batch [118/1562], Loss: 0.2704\n",
      "Epoch [2/10], Batch [120/1562], Loss: 0.2782\n",
      "Epoch [2/10], Batch [122/1562], Loss: 0.2876\n",
      "Epoch [2/10], Batch [124/1562], Loss: 0.2740\n",
      "Epoch [2/10], Batch [126/1562], Loss: 0.2597\n",
      "Epoch [2/10], Batch [128/1562], Loss: 0.2949\n",
      "Epoch [2/10], Batch [130/1562], Loss: 0.3172\n",
      "Epoch [2/10], Batch [132/1562], Loss: 0.2819\n",
      "Epoch [2/10], Batch [134/1562], Loss: 0.2866\n",
      "Epoch [2/10], Batch [136/1562], Loss: 0.2609\n",
      "Epoch [2/10], Batch [138/1562], Loss: 0.2857\n",
      "Epoch [2/10], Batch [140/1562], Loss: 0.2800\n",
      "Epoch [2/10], Batch [142/1562], Loss: 0.2973\n",
      "Epoch [2/10], Batch [144/1562], Loss: 0.2712\n",
      "Epoch [2/10], Batch [146/1562], Loss: 0.3208\n",
      "Epoch [2/10], Batch [148/1562], Loss: 0.2575\n",
      "Epoch [2/10], Batch [150/1562], Loss: 0.2666\n",
      "Epoch [2/10], Batch [152/1562], Loss: 0.3440\n",
      "Epoch [2/10], Batch [154/1562], Loss: 0.2727\n",
      "Epoch [2/10], Batch [156/1562], Loss: 0.2805\n",
      "Epoch [2/10], Batch [158/1562], Loss: 0.3067\n",
      "Epoch [2/10], Batch [160/1562], Loss: 0.3122\n",
      "Epoch [2/10], Batch [162/1562], Loss: 0.2781\n",
      "Epoch [2/10], Batch [164/1562], Loss: 0.2948\n",
      "Epoch [2/10], Batch [166/1562], Loss: 0.2909\n",
      "Epoch [2/10], Batch [168/1562], Loss: 0.2904\n",
      "Epoch [2/10], Batch [170/1562], Loss: 0.2736\n",
      "Epoch [2/10], Batch [172/1562], Loss: 0.2658\n",
      "Epoch [2/10], Batch [174/1562], Loss: 0.2814\n",
      "Epoch [2/10], Batch [176/1562], Loss: 0.3325\n",
      "Epoch [2/10], Batch [178/1562], Loss: 0.3287\n",
      "Epoch [2/10], Batch [180/1562], Loss: 0.2817\n",
      "Epoch [2/10], Batch [182/1562], Loss: 0.2807\n",
      "Epoch [2/10], Batch [184/1562], Loss: 0.2749\n",
      "Epoch [2/10], Batch [186/1562], Loss: 0.2847\n",
      "Epoch [2/10], Batch [188/1562], Loss: 0.2665\n",
      "Epoch [2/10], Batch [190/1562], Loss: 0.2890\n",
      "Epoch [2/10], Batch [192/1562], Loss: 0.3128\n",
      "Epoch [2/10], Batch [194/1562], Loss: 0.2786\n",
      "Epoch [2/10], Batch [196/1562], Loss: 0.2551\n",
      "Epoch [2/10], Batch [198/1562], Loss: 0.3155\n",
      "Epoch [2/10], Batch [200/1562], Loss: 0.2725\n",
      "Epoch [2/10], Batch [202/1562], Loss: 0.3025\n",
      "Epoch [2/10], Batch [204/1562], Loss: 0.2778\n",
      "Epoch [2/10], Batch [206/1562], Loss: 0.3105\n",
      "Epoch [2/10], Batch [208/1562], Loss: 0.2772\n",
      "Epoch [2/10], Batch [210/1562], Loss: 0.2644\n",
      "Epoch [2/10], Batch [212/1562], Loss: 0.2854\n",
      "Epoch [2/10], Batch [214/1562], Loss: 0.2928\n",
      "Epoch [2/10], Batch [216/1562], Loss: 0.2745\n",
      "Epoch [2/10], Batch [218/1562], Loss: 0.2963\n",
      "Epoch [2/10], Batch [220/1562], Loss: 0.2940\n",
      "Epoch [2/10], Batch [222/1562], Loss: 0.2849\n",
      "Epoch [2/10], Batch [224/1562], Loss: 0.3169\n",
      "Epoch [2/10], Batch [226/1562], Loss: 0.2703\n",
      "Epoch [2/10], Batch [228/1562], Loss: 0.2838\n",
      "Epoch [2/10], Batch [230/1562], Loss: 0.2800\n",
      "Epoch [2/10], Batch [232/1562], Loss: 0.3165\n",
      "Epoch [2/10], Batch [234/1562], Loss: 0.2421\n",
      "Epoch [2/10], Batch [236/1562], Loss: 0.3203\n",
      "Epoch [2/10], Batch [238/1562], Loss: 0.2627\n",
      "Epoch [2/10], Batch [240/1562], Loss: 0.2867\n",
      "Epoch [2/10], Batch [242/1562], Loss: 0.2915\n",
      "Epoch [2/10], Batch [244/1562], Loss: 0.3115\n",
      "Epoch [2/10], Batch [246/1562], Loss: 0.2552\n",
      "Epoch [2/10], Batch [248/1562], Loss: 0.2525\n",
      "Epoch [2/10], Batch [250/1562], Loss: 0.2857\n",
      "Epoch [2/10], Batch [252/1562], Loss: 0.3099\n",
      "Epoch [2/10], Batch [254/1562], Loss: 0.2829\n",
      "Epoch [2/10], Batch [256/1562], Loss: 0.3067\n",
      "Epoch [2/10], Batch [258/1562], Loss: 0.3090\n",
      "Epoch [2/10], Batch [260/1562], Loss: 0.3011\n",
      "Epoch [2/10], Batch [262/1562], Loss: 0.2757\n",
      "Epoch [2/10], Batch [264/1562], Loss: 0.2626\n",
      "Epoch [2/10], Batch [266/1562], Loss: 0.2656\n",
      "Epoch [2/10], Batch [268/1562], Loss: 0.3220\n",
      "Epoch [2/10], Batch [270/1562], Loss: 0.3001\n",
      "Epoch [2/10], Batch [272/1562], Loss: 0.2778\n",
      "Epoch [2/10], Batch [274/1562], Loss: 0.2767\n",
      "Epoch [2/10], Batch [276/1562], Loss: 0.2761\n",
      "Epoch [2/10], Batch [278/1562], Loss: 0.3116\n",
      "Epoch [2/10], Batch [280/1562], Loss: 0.2876\n",
      "Epoch [2/10], Batch [282/1562], Loss: 0.3096\n",
      "Epoch [2/10], Batch [284/1562], Loss: 0.3133\n",
      "Epoch [2/10], Batch [286/1562], Loss: 0.2445\n",
      "Epoch [2/10], Batch [288/1562], Loss: 0.2761\n",
      "Epoch [2/10], Batch [290/1562], Loss: 0.2628\n",
      "Epoch [2/10], Batch [292/1562], Loss: 0.2960\n",
      "Epoch [2/10], Batch [294/1562], Loss: 0.3198\n",
      "Epoch [2/10], Batch [296/1562], Loss: 0.2456\n",
      "Epoch [2/10], Batch [298/1562], Loss: 0.3303\n",
      "Epoch [2/10], Batch [300/1562], Loss: 0.2623\n",
      "Epoch [2/10], Batch [302/1562], Loss: 0.3156\n",
      "Epoch [2/10], Batch [304/1562], Loss: 0.2969\n",
      "Epoch [2/10], Batch [306/1562], Loss: 0.2515\n",
      "Epoch [2/10], Batch [308/1562], Loss: 0.2916\n",
      "Epoch [2/10], Batch [310/1562], Loss: 0.2902\n",
      "Epoch [2/10], Batch [312/1562], Loss: 0.2674\n",
      "Epoch [2/10], Batch [314/1562], Loss: 0.2623\n",
      "Epoch [2/10], Batch [316/1562], Loss: 0.3234\n",
      "Epoch [2/10], Batch [318/1562], Loss: 0.2666\n",
      "Epoch [2/10], Batch [320/1562], Loss: 0.3159\n",
      "Epoch [2/10], Batch [322/1562], Loss: 0.2776\n",
      "Epoch [2/10], Batch [324/1562], Loss: 0.2109\n",
      "Epoch [2/10], Batch [326/1562], Loss: 0.2674\n",
      "Epoch [2/10], Batch [328/1562], Loss: 0.2562\n",
      "Epoch [2/10], Batch [330/1562], Loss: 0.2707\n",
      "Epoch [2/10], Batch [332/1562], Loss: 0.2670\n",
      "Epoch [2/10], Batch [334/1562], Loss: 0.2485\n",
      "Epoch [2/10], Batch [336/1562], Loss: 0.2960\n",
      "Epoch [2/10], Batch [338/1562], Loss: 0.2765\n",
      "Epoch [2/10], Batch [340/1562], Loss: 0.2753\n",
      "Epoch [2/10], Batch [342/1562], Loss: 0.2836\n",
      "Epoch [2/10], Batch [344/1562], Loss: 0.2680\n",
      "Epoch [2/10], Batch [346/1562], Loss: 0.3069\n",
      "Epoch [2/10], Batch [348/1562], Loss: 0.2491\n",
      "Epoch [2/10], Batch [350/1562], Loss: 0.2788\n",
      "Epoch [2/10], Batch [352/1562], Loss: 0.3072\n",
      "Epoch [2/10], Batch [354/1562], Loss: 0.2866\n",
      "Epoch [2/10], Batch [356/1562], Loss: 0.2792\n",
      "Epoch [2/10], Batch [358/1562], Loss: 0.2685\n",
      "Epoch [2/10], Batch [360/1562], Loss: 0.2845\n",
      "Epoch [2/10], Batch [362/1562], Loss: 0.2524\n",
      "Epoch [2/10], Batch [364/1562], Loss: 0.3177\n",
      "Epoch [2/10], Batch [366/1562], Loss: 0.2838\n",
      "Epoch [2/10], Batch [368/1562], Loss: 0.2713\n",
      "Epoch [2/10], Batch [370/1562], Loss: 0.2841\n",
      "Epoch [2/10], Batch [372/1562], Loss: 0.3055\n",
      "Epoch [2/10], Batch [374/1562], Loss: 0.2928\n",
      "Epoch [2/10], Batch [376/1562], Loss: 0.2985\n",
      "Epoch [2/10], Batch [378/1562], Loss: 0.2935\n",
      "Epoch [2/10], Batch [380/1562], Loss: 0.3124\n",
      "Epoch [2/10], Batch [382/1562], Loss: 0.2679\n",
      "Epoch [2/10], Batch [384/1562], Loss: 0.2741\n",
      "Epoch [2/10], Batch [386/1562], Loss: 0.3009\n",
      "Epoch [2/10], Batch [388/1562], Loss: 0.2705\n",
      "Epoch [2/10], Batch [390/1562], Loss: 0.3042\n",
      "Epoch [2/10], Batch [392/1562], Loss: 0.2660\n",
      "Epoch [2/10], Batch [394/1562], Loss: 0.2823\n",
      "Epoch [2/10], Batch [396/1562], Loss: 0.2569\n",
      "Epoch [2/10], Batch [398/1562], Loss: 0.2358\n",
      "Epoch [2/10], Batch [400/1562], Loss: 0.2791\n",
      "Epoch [2/10], Batch [402/1562], Loss: 0.3382\n",
      "Epoch [2/10], Batch [404/1562], Loss: 0.2598\n",
      "Epoch [2/10], Batch [406/1562], Loss: 0.2608\n",
      "Epoch [2/10], Batch [408/1562], Loss: 0.2593\n",
      "Epoch [2/10], Batch [410/1562], Loss: 0.2825\n",
      "Epoch [2/10], Batch [412/1562], Loss: 0.2902\n",
      "Epoch [2/10], Batch [414/1562], Loss: 0.3100\n",
      "Epoch [2/10], Batch [416/1562], Loss: 0.2690\n",
      "Epoch [2/10], Batch [418/1562], Loss: 0.3122\n",
      "Epoch [2/10], Batch [420/1562], Loss: 0.3212\n",
      "Epoch [2/10], Batch [422/1562], Loss: 0.2996\n",
      "Epoch [2/10], Batch [424/1562], Loss: 0.2954\n",
      "Epoch [2/10], Batch [426/1562], Loss: 0.2882\n",
      "Epoch [2/10], Batch [428/1562], Loss: 0.2757\n",
      "Epoch [2/10], Batch [430/1562], Loss: 0.3178\n",
      "Epoch [2/10], Batch [432/1562], Loss: 0.2848\n",
      "Epoch [2/10], Batch [434/1562], Loss: 0.2398\n",
      "Epoch [2/10], Batch [436/1562], Loss: 0.2750\n",
      "Epoch [2/10], Batch [438/1562], Loss: 0.2628\n",
      "Epoch [2/10], Batch [440/1562], Loss: 0.2676\n",
      "Epoch [2/10], Batch [442/1562], Loss: 0.3068\n",
      "Epoch [2/10], Batch [444/1562], Loss: 0.2398\n",
      "Epoch [2/10], Batch [446/1562], Loss: 0.3187\n",
      "Epoch [2/10], Batch [448/1562], Loss: 0.3025\n",
      "Epoch [2/10], Batch [450/1562], Loss: 0.2792\n",
      "Epoch [2/10], Batch [452/1562], Loss: 0.3121\n",
      "Epoch [2/10], Batch [454/1562], Loss: 0.2830\n",
      "Epoch [2/10], Batch [456/1562], Loss: 0.2741\n",
      "Epoch [2/10], Batch [458/1562], Loss: 0.2676\n",
      "Epoch [2/10], Batch [460/1562], Loss: 0.3261\n",
      "Epoch [2/10], Batch [462/1562], Loss: 0.2992\n",
      "Epoch [2/10], Batch [464/1562], Loss: 0.3002\n",
      "Epoch [2/10], Batch [466/1562], Loss: 0.2706\n",
      "Epoch [2/10], Batch [468/1562], Loss: 0.2636\n",
      "Epoch [2/10], Batch [470/1562], Loss: 0.2994\n",
      "Epoch [2/10], Batch [472/1562], Loss: 0.2793\n",
      "Epoch [2/10], Batch [474/1562], Loss: 0.2891\n",
      "Epoch [2/10], Batch [476/1562], Loss: 0.2654\n",
      "Epoch [2/10], Batch [478/1562], Loss: 0.2656\n",
      "Epoch [2/10], Batch [480/1562], Loss: 0.2655\n",
      "Epoch [2/10], Batch [482/1562], Loss: 0.2697\n",
      "Epoch [2/10], Batch [484/1562], Loss: 0.3165\n",
      "Epoch [2/10], Batch [486/1562], Loss: 0.3270\n",
      "Epoch [2/10], Batch [488/1562], Loss: 0.2889\n",
      "Epoch [2/10], Batch [490/1562], Loss: 0.2897\n",
      "Epoch [2/10], Batch [492/1562], Loss: 0.2661\n",
      "Epoch [2/10], Batch [494/1562], Loss: 0.3051\n",
      "Epoch [2/10], Batch [496/1562], Loss: 0.3419\n",
      "Epoch [2/10], Batch [498/1562], Loss: 0.2787\n",
      "Epoch [2/10], Batch [500/1562], Loss: 0.3460\n",
      "Epoch [2/10], Batch [502/1562], Loss: 0.3244\n",
      "Epoch [2/10], Batch [504/1562], Loss: 0.2914\n",
      "Epoch [2/10], Batch [506/1562], Loss: 0.3083\n",
      "Epoch [2/10], Batch [508/1562], Loss: 0.2902\n",
      "Epoch [2/10], Batch [510/1562], Loss: 0.2789\n",
      "Epoch [2/10], Batch [512/1562], Loss: 0.2885\n",
      "Epoch [2/10], Batch [514/1562], Loss: 0.3329\n",
      "Epoch [2/10], Batch [516/1562], Loss: 0.3184\n",
      "Epoch [2/10], Batch [518/1562], Loss: 0.2807\n",
      "Epoch [2/10], Batch [520/1562], Loss: 0.2988\n",
      "Epoch [2/10], Batch [522/1562], Loss: 0.2936\n",
      "Epoch [2/10], Batch [524/1562], Loss: 0.2506\n",
      "Epoch [2/10], Batch [526/1562], Loss: 0.3111\n",
      "Epoch [2/10], Batch [528/1562], Loss: 0.3307\n",
      "Epoch [2/10], Batch [530/1562], Loss: 0.2890\n",
      "Epoch [2/10], Batch [532/1562], Loss: 0.2666\n",
      "Epoch [2/10], Batch [534/1562], Loss: 0.2483\n",
      "Epoch [2/10], Batch [536/1562], Loss: 0.3584\n",
      "Epoch [2/10], Batch [538/1562], Loss: 0.3028\n",
      "Epoch [2/10], Batch [540/1562], Loss: 0.2707\n",
      "Epoch [2/10], Batch [542/1562], Loss: 0.2589\n",
      "Epoch [2/10], Batch [544/1562], Loss: 0.2825\n",
      "Epoch [2/10], Batch [546/1562], Loss: 0.2728\n",
      "Epoch [2/10], Batch [548/1562], Loss: 0.3277\n",
      "Epoch [2/10], Batch [550/1562], Loss: 0.2604\n",
      "Epoch [2/10], Batch [552/1562], Loss: 0.2952\n",
      "Epoch [2/10], Batch [554/1562], Loss: 0.2983\n",
      "Epoch [2/10], Batch [556/1562], Loss: 0.2890\n",
      "Epoch [2/10], Batch [558/1562], Loss: 0.2950\n",
      "Epoch [2/10], Batch [560/1562], Loss: 0.2843\n",
      "Epoch [2/10], Batch [562/1562], Loss: 0.2670\n",
      "Epoch [2/10], Batch [564/1562], Loss: 0.2756\n",
      "Epoch [2/10], Batch [566/1562], Loss: 0.2337\n",
      "Epoch [2/10], Batch [568/1562], Loss: 0.2637\n",
      "Epoch [2/10], Batch [570/1562], Loss: 0.3007\n",
      "Epoch [2/10], Batch [572/1562], Loss: 0.2548\n",
      "Epoch [2/10], Batch [574/1562], Loss: 0.2759\n",
      "Epoch [2/10], Batch [576/1562], Loss: 0.2569\n",
      "Epoch [2/10], Batch [578/1562], Loss: 0.2759\n",
      "Epoch [2/10], Batch [580/1562], Loss: 0.3209\n",
      "Epoch [2/10], Batch [582/1562], Loss: 0.2802\n",
      "Epoch [2/10], Batch [584/1562], Loss: 0.2919\n",
      "Epoch [2/10], Batch [586/1562], Loss: 0.3025\n",
      "Epoch [2/10], Batch [588/1562], Loss: 0.2442\n",
      "Epoch [2/10], Batch [590/1562], Loss: 0.2846\n",
      "Epoch [2/10], Batch [592/1562], Loss: 0.2725\n",
      "Epoch [2/10], Batch [594/1562], Loss: 0.2473\n",
      "Epoch [2/10], Batch [596/1562], Loss: 0.3060\n",
      "Epoch [2/10], Batch [598/1562], Loss: 0.2737\n",
      "Epoch [2/10], Batch [600/1562], Loss: 0.2760\n",
      "Epoch [2/10], Batch [602/1562], Loss: 0.3031\n",
      "Epoch [2/10], Batch [604/1562], Loss: 0.2863\n",
      "Epoch [2/10], Batch [606/1562], Loss: 0.3165\n",
      "Epoch [2/10], Batch [608/1562], Loss: 0.3060\n",
      "Epoch [2/10], Batch [610/1562], Loss: 0.2801\n",
      "Epoch [2/10], Batch [612/1562], Loss: 0.2721\n",
      "Epoch [2/10], Batch [614/1562], Loss: 0.3052\n",
      "Epoch [2/10], Batch [616/1562], Loss: 0.2700\n",
      "Epoch [2/10], Batch [618/1562], Loss: 0.3145\n",
      "Epoch [2/10], Batch [620/1562], Loss: 0.2858\n",
      "Epoch [2/10], Batch [622/1562], Loss: 0.2879\n",
      "Epoch [2/10], Batch [624/1562], Loss: 0.2986\n",
      "Epoch [2/10], Batch [626/1562], Loss: 0.2794\n",
      "Epoch [2/10], Batch [628/1562], Loss: 0.2483\n",
      "Epoch [2/10], Batch [630/1562], Loss: 0.2401\n",
      "Epoch [2/10], Batch [632/1562], Loss: 0.2948\n",
      "Epoch [2/10], Batch [634/1562], Loss: 0.2990\n",
      "Epoch [2/10], Batch [636/1562], Loss: 0.2808\n",
      "Epoch [2/10], Batch [638/1562], Loss: 0.2801\n",
      "Epoch [2/10], Batch [640/1562], Loss: 0.2763\n",
      "Epoch [2/10], Batch [642/1562], Loss: 0.2919\n",
      "Epoch [2/10], Batch [644/1562], Loss: 0.2545\n",
      "Epoch [2/10], Batch [646/1562], Loss: 0.2661\n",
      "Epoch [2/10], Batch [648/1562], Loss: 0.2515\n",
      "Epoch [2/10], Batch [650/1562], Loss: 0.2813\n",
      "Epoch [2/10], Batch [652/1562], Loss: 0.2845\n",
      "Epoch [2/10], Batch [654/1562], Loss: 0.2513\n",
      "Epoch [2/10], Batch [656/1562], Loss: 0.2669\n",
      "Epoch [2/10], Batch [658/1562], Loss: 0.2684\n",
      "Epoch [2/10], Batch [660/1562], Loss: 0.2953\n",
      "Epoch [2/10], Batch [662/1562], Loss: 0.2812\n",
      "Epoch [2/10], Batch [664/1562], Loss: 0.2826\n",
      "Epoch [2/10], Batch [666/1562], Loss: 0.2647\n",
      "Epoch [2/10], Batch [668/1562], Loss: 0.2775\n",
      "Epoch [2/10], Batch [670/1562], Loss: 0.2972\n",
      "Epoch [2/10], Batch [672/1562], Loss: 0.2814\n",
      "Epoch [2/10], Batch [674/1562], Loss: 0.2844\n",
      "Epoch [2/10], Batch [676/1562], Loss: 0.3029\n",
      "Epoch [2/10], Batch [678/1562], Loss: 0.2768\n",
      "Epoch [2/10], Batch [680/1562], Loss: 0.2793\n",
      "Epoch [2/10], Batch [682/1562], Loss: 0.3005\n",
      "Epoch [2/10], Batch [684/1562], Loss: 0.2730\n",
      "Epoch [2/10], Batch [686/1562], Loss: 0.2719\n",
      "Epoch [2/10], Batch [688/1562], Loss: 0.2440\n",
      "Epoch [2/10], Batch [690/1562], Loss: 0.3092\n",
      "Epoch [2/10], Batch [692/1562], Loss: 0.3030\n",
      "Epoch [2/10], Batch [694/1562], Loss: 0.3442\n",
      "Epoch [2/10], Batch [696/1562], Loss: 0.2537\n",
      "Epoch [2/10], Batch [698/1562], Loss: 0.2913\n",
      "Epoch [2/10], Batch [700/1562], Loss: 0.3051\n",
      "Epoch [2/10], Batch [702/1562], Loss: 0.3147\n",
      "Epoch [2/10], Batch [704/1562], Loss: 0.2721\n",
      "Epoch [2/10], Batch [706/1562], Loss: 0.3085\n",
      "Epoch [2/10], Batch [708/1562], Loss: 0.2510\n",
      "Epoch [2/10], Batch [710/1562], Loss: 0.2869\n",
      "Epoch [2/10], Batch [712/1562], Loss: 0.3187\n",
      "Epoch [2/10], Batch [714/1562], Loss: 0.2704\n",
      "Epoch [2/10], Batch [716/1562], Loss: 0.2936\n",
      "Epoch [2/10], Batch [718/1562], Loss: 0.2686\n",
      "Epoch [2/10], Batch [720/1562], Loss: 0.2846\n",
      "Epoch [2/10], Batch [722/1562], Loss: 0.2702\n",
      "Epoch [2/10], Batch [724/1562], Loss: 0.2821\n",
      "Epoch [2/10], Batch [726/1562], Loss: 0.2752\n",
      "Epoch [2/10], Batch [728/1562], Loss: 0.3203\n",
      "Epoch [2/10], Batch [730/1562], Loss: 0.3090\n",
      "Epoch [2/10], Batch [732/1562], Loss: 0.2507\n",
      "Epoch [2/10], Batch [734/1562], Loss: 0.2768\n",
      "Epoch [2/10], Batch [736/1562], Loss: 0.3189\n",
      "Epoch [2/10], Batch [738/1562], Loss: 0.2572\n",
      "Epoch [2/10], Batch [740/1562], Loss: 0.2766\n",
      "Epoch [2/10], Batch [742/1562], Loss: 0.2271\n",
      "Epoch [2/10], Batch [744/1562], Loss: 0.2825\n",
      "Epoch [2/10], Batch [746/1562], Loss: 0.2905\n",
      "Epoch [2/10], Batch [748/1562], Loss: 0.3137\n",
      "Epoch [2/10], Batch [750/1562], Loss: 0.2806\n",
      "Epoch [2/10], Batch [752/1562], Loss: 0.2913\n",
      "Epoch [2/10], Batch [754/1562], Loss: 0.3132\n",
      "Epoch [2/10], Batch [756/1562], Loss: 0.2867\n",
      "Epoch [2/10], Batch [758/1562], Loss: 0.3019\n",
      "Epoch [2/10], Batch [760/1562], Loss: 0.2845\n",
      "Epoch [2/10], Batch [762/1562], Loss: 0.2544\n",
      "Epoch [2/10], Batch [764/1562], Loss: 0.2735\n",
      "Epoch [2/10], Batch [766/1562], Loss: 0.2931\n",
      "Epoch [2/10], Batch [768/1562], Loss: 0.2656\n",
      "Epoch [2/10], Batch [770/1562], Loss: 0.2780\n",
      "Epoch [2/10], Batch [772/1562], Loss: 0.2999\n",
      "Epoch [2/10], Batch [774/1562], Loss: 0.3058\n",
      "Epoch [2/10], Batch [776/1562], Loss: 0.2892\n",
      "Epoch [2/10], Batch [778/1562], Loss: 0.3404\n",
      "Epoch [2/10], Batch [780/1562], Loss: 0.2538\n",
      "Epoch [2/10], Batch [782/1562], Loss: 0.3062\n",
      "Epoch [2/10], Batch [784/1562], Loss: 0.2876\n",
      "Epoch [2/10], Batch [786/1562], Loss: 0.2637\n",
      "Epoch [2/10], Batch [788/1562], Loss: 0.2650\n",
      "Epoch [2/10], Batch [790/1562], Loss: 0.2632\n",
      "Epoch [2/10], Batch [792/1562], Loss: 0.2765\n",
      "Epoch [2/10], Batch [794/1562], Loss: 0.2755\n",
      "Epoch [2/10], Batch [796/1562], Loss: 0.2935\n",
      "Epoch [2/10], Batch [798/1562], Loss: 0.3162\n",
      "Epoch [2/10], Batch [800/1562], Loss: 0.3155\n",
      "Epoch [2/10], Batch [802/1562], Loss: 0.2833\n",
      "Epoch [2/10], Batch [804/1562], Loss: 0.2961\n",
      "Epoch [2/10], Batch [806/1562], Loss: 0.3000\n",
      "Epoch [2/10], Batch [808/1562], Loss: 0.2253\n",
      "Epoch [2/10], Batch [810/1562], Loss: 0.2586\n",
      "Epoch [2/10], Batch [812/1562], Loss: 0.2874\n",
      "Epoch [2/10], Batch [814/1562], Loss: 0.2365\n",
      "Epoch [2/10], Batch [816/1562], Loss: 0.3357\n",
      "Epoch [2/10], Batch [818/1562], Loss: 0.3156\n",
      "Epoch [2/10], Batch [820/1562], Loss: 0.2378\n",
      "Epoch [2/10], Batch [822/1562], Loss: 0.2685\n",
      "Epoch [2/10], Batch [824/1562], Loss: 0.2717\n",
      "Epoch [2/10], Batch [826/1562], Loss: 0.3036\n",
      "Epoch [2/10], Batch [828/1562], Loss: 0.2848\n",
      "Epoch [2/10], Batch [830/1562], Loss: 0.2737\n",
      "Epoch [2/10], Batch [832/1562], Loss: 0.2970\n",
      "Epoch [2/10], Batch [834/1562], Loss: 0.2844\n",
      "Epoch [2/10], Batch [836/1562], Loss: 0.2703\n",
      "Epoch [2/10], Batch [838/1562], Loss: 0.2524\n",
      "Epoch [2/10], Batch [840/1562], Loss: 0.2789\n",
      "Epoch [2/10], Batch [842/1562], Loss: 0.2814\n",
      "Epoch [2/10], Batch [844/1562], Loss: 0.2644\n",
      "Epoch [2/10], Batch [846/1562], Loss: 0.2805\n",
      "Epoch [2/10], Batch [848/1562], Loss: 0.2878\n",
      "Epoch [2/10], Batch [850/1562], Loss: 0.2849\n",
      "Epoch [2/10], Batch [852/1562], Loss: 0.2464\n",
      "Epoch [2/10], Batch [854/1562], Loss: 0.2810\n",
      "Epoch [2/10], Batch [856/1562], Loss: 0.2814\n",
      "Epoch [2/10], Batch [858/1562], Loss: 0.2851\n",
      "Epoch [2/10], Batch [860/1562], Loss: 0.3138\n",
      "Epoch [2/10], Batch [862/1562], Loss: 0.2654\n",
      "Epoch [2/10], Batch [864/1562], Loss: 0.3058\n",
      "Epoch [2/10], Batch [866/1562], Loss: 0.2673\n",
      "Epoch [2/10], Batch [868/1562], Loss: 0.2320\n",
      "Epoch [2/10], Batch [870/1562], Loss: 0.2667\n",
      "Epoch [2/10], Batch [872/1562], Loss: 0.3006\n",
      "Epoch [2/10], Batch [874/1562], Loss: 0.2938\n",
      "Epoch [2/10], Batch [876/1562], Loss: 0.2851\n",
      "Epoch [2/10], Batch [878/1562], Loss: 0.3127\n",
      "Epoch [2/10], Batch [880/1562], Loss: 0.3200\n",
      "Epoch [2/10], Batch [882/1562], Loss: 0.2376\n",
      "Epoch [2/10], Batch [884/1562], Loss: 0.2724\n",
      "Epoch [2/10], Batch [886/1562], Loss: 0.2753\n",
      "Epoch [2/10], Batch [888/1562], Loss: 0.3281\n",
      "Epoch [2/10], Batch [890/1562], Loss: 0.3058\n",
      "Epoch [2/10], Batch [892/1562], Loss: 0.3120\n",
      "Epoch [2/10], Batch [894/1562], Loss: 0.2948\n",
      "Epoch [2/10], Batch [896/1562], Loss: 0.2708\n",
      "Epoch [2/10], Batch [898/1562], Loss: 0.2969\n",
      "Epoch [2/10], Batch [900/1562], Loss: 0.3376\n",
      "Epoch [2/10], Batch [902/1562], Loss: 0.2849\n",
      "Epoch [2/10], Batch [904/1562], Loss: 0.2988\n",
      "Epoch [2/10], Batch [906/1562], Loss: 0.2945\n",
      "Epoch [2/10], Batch [908/1562], Loss: 0.2985\n",
      "Epoch [2/10], Batch [910/1562], Loss: 0.2946\n",
      "Epoch [2/10], Batch [912/1562], Loss: 0.3069\n",
      "Epoch [2/10], Batch [914/1562], Loss: 0.2919\n",
      "Epoch [2/10], Batch [916/1562], Loss: 0.3059\n",
      "Epoch [2/10], Batch [918/1562], Loss: 0.2908\n",
      "Epoch [2/10], Batch [920/1562], Loss: 0.3075\n",
      "Epoch [2/10], Batch [922/1562], Loss: 0.3183\n",
      "Epoch [2/10], Batch [924/1562], Loss: 0.3056\n",
      "Epoch [2/10], Batch [926/1562], Loss: 0.2946\n",
      "Epoch [2/10], Batch [928/1562], Loss: 0.2717\n",
      "Epoch [2/10], Batch [930/1562], Loss: 0.3030\n",
      "Epoch [2/10], Batch [932/1562], Loss: 0.3209\n",
      "Epoch [2/10], Batch [934/1562], Loss: 0.3056\n",
      "Epoch [2/10], Batch [936/1562], Loss: 0.2593\n",
      "Epoch [2/10], Batch [938/1562], Loss: 0.3104\n",
      "Epoch [2/10], Batch [940/1562], Loss: 0.2791\n",
      "Epoch [2/10], Batch [942/1562], Loss: 0.2643\n",
      "Epoch [2/10], Batch [944/1562], Loss: 0.2651\n",
      "Epoch [2/10], Batch [946/1562], Loss: 0.2918\n",
      "Epoch [2/10], Batch [948/1562], Loss: 0.2692\n",
      "Epoch [2/10], Batch [950/1562], Loss: 0.3025\n",
      "Epoch [2/10], Batch [952/1562], Loss: 0.2657\n",
      "Epoch [2/10], Batch [954/1562], Loss: 0.2447\n",
      "Epoch [2/10], Batch [956/1562], Loss: 0.3014\n",
      "Epoch [2/10], Batch [958/1562], Loss: 0.2757\n",
      "Epoch [2/10], Batch [960/1562], Loss: 0.2994\n",
      "Epoch [2/10], Batch [962/1562], Loss: 0.3336\n",
      "Epoch [2/10], Batch [964/1562], Loss: 0.3193\n",
      "Epoch [2/10], Batch [966/1562], Loss: 0.2874\n",
      "Epoch [2/10], Batch [968/1562], Loss: 0.2864\n",
      "Epoch [2/10], Batch [970/1562], Loss: 0.2482\n",
      "Epoch [2/10], Batch [972/1562], Loss: 0.3034\n",
      "Epoch [2/10], Batch [974/1562], Loss: 0.2768\n",
      "Epoch [2/10], Batch [976/1562], Loss: 0.2846\n",
      "Epoch [2/10], Batch [978/1562], Loss: 0.2989\n",
      "Epoch [2/10], Batch [980/1562], Loss: 0.3276\n",
      "Epoch [2/10], Batch [982/1562], Loss: 0.2974\n",
      "Epoch [2/10], Batch [984/1562], Loss: 0.3098\n",
      "Epoch [2/10], Batch [986/1562], Loss: 0.2853\n",
      "Epoch [2/10], Batch [988/1562], Loss: 0.3017\n",
      "Epoch [2/10], Batch [990/1562], Loss: 0.3168\n",
      "Epoch [2/10], Batch [992/1562], Loss: 0.2895\n",
      "Epoch [2/10], Batch [994/1562], Loss: 0.2940\n",
      "Epoch [2/10], Batch [996/1562], Loss: 0.2908\n",
      "Epoch [2/10], Batch [998/1562], Loss: 0.3199\n",
      "Epoch [2/10], Batch [1000/1562], Loss: 0.2589\n",
      "Epoch [2/10], Batch [1002/1562], Loss: 0.2870\n",
      "Epoch [2/10], Batch [1004/1562], Loss: 0.2583\n",
      "Epoch [2/10], Batch [1006/1562], Loss: 0.2425\n",
      "Epoch [2/10], Batch [1008/1562], Loss: 0.2767\n",
      "Epoch [2/10], Batch [1010/1562], Loss: 0.2994\n",
      "Epoch [2/10], Batch [1012/1562], Loss: 0.2987\n",
      "Epoch [2/10], Batch [1014/1562], Loss: 0.3138\n",
      "Epoch [2/10], Batch [1016/1562], Loss: 0.3047\n",
      "Epoch [2/10], Batch [1018/1562], Loss: 0.2675\n",
      "Epoch [2/10], Batch [1020/1562], Loss: 0.2784\n",
      "Epoch [2/10], Batch [1022/1562], Loss: 0.2901\n",
      "Epoch [2/10], Batch [1024/1562], Loss: 0.2485\n",
      "Epoch [2/10], Batch [1026/1562], Loss: 0.2816\n",
      "Epoch [2/10], Batch [1028/1562], Loss: 0.2944\n",
      "Epoch [2/10], Batch [1030/1562], Loss: 0.3056\n",
      "Epoch [2/10], Batch [1032/1562], Loss: 0.2716\n",
      "Epoch [2/10], Batch [1034/1562], Loss: 0.2903\n",
      "Epoch [2/10], Batch [1036/1562], Loss: 0.2721\n",
      "Epoch [2/10], Batch [1038/1562], Loss: 0.3042\n",
      "Epoch [2/10], Batch [1040/1562], Loss: 0.3298\n",
      "Epoch [2/10], Batch [1042/1562], Loss: 0.2993\n",
      "Epoch [2/10], Batch [1044/1562], Loss: 0.2866\n",
      "Epoch [2/10], Batch [1046/1562], Loss: 0.2866\n",
      "Epoch [2/10], Batch [1048/1562], Loss: 0.2965\n",
      "Epoch [2/10], Batch [1050/1562], Loss: 0.2735\n",
      "Epoch [2/10], Batch [1052/1562], Loss: 0.2634\n",
      "Epoch [2/10], Batch [1054/1562], Loss: 0.2875\n",
      "Epoch [2/10], Batch [1056/1562], Loss: 0.2755\n",
      "Epoch [2/10], Batch [1058/1562], Loss: 0.2922\n",
      "Epoch [2/10], Batch [1060/1562], Loss: 0.2907\n",
      "Epoch [2/10], Batch [1062/1562], Loss: 0.2898\n",
      "Epoch [2/10], Batch [1064/1562], Loss: 0.2849\n",
      "Epoch [2/10], Batch [1066/1562], Loss: 0.2818\n",
      "Epoch [2/10], Batch [1068/1562], Loss: 0.2782\n",
      "Epoch [2/10], Batch [1070/1562], Loss: 0.3246\n",
      "Epoch [2/10], Batch [1072/1562], Loss: 0.2605\n",
      "Epoch [2/10], Batch [1074/1562], Loss: 0.2965\n",
      "Epoch [2/10], Batch [1076/1562], Loss: 0.2595\n",
      "Epoch [2/10], Batch [1078/1562], Loss: 0.2898\n",
      "Epoch [2/10], Batch [1080/1562], Loss: 0.2648\n",
      "Epoch [2/10], Batch [1082/1562], Loss: 0.3015\n",
      "Epoch [2/10], Batch [1084/1562], Loss: 0.2783\n",
      "Epoch [2/10], Batch [1086/1562], Loss: 0.2519\n",
      "Epoch [2/10], Batch [1088/1562], Loss: 0.2901\n",
      "Epoch [2/10], Batch [1090/1562], Loss: 0.2991\n",
      "Epoch [2/10], Batch [1092/1562], Loss: 0.3388\n",
      "Epoch [2/10], Batch [1094/1562], Loss: 0.2887\n",
      "Epoch [2/10], Batch [1096/1562], Loss: 0.2753\n",
      "Epoch [2/10], Batch [1098/1562], Loss: 0.3189\n",
      "Epoch [2/10], Batch [1100/1562], Loss: 0.2698\n",
      "Epoch [2/10], Batch [1102/1562], Loss: 0.2681\n",
      "Epoch [2/10], Batch [1104/1562], Loss: 0.2941\n",
      "Epoch [2/10], Batch [1106/1562], Loss: 0.2481\n",
      "Epoch [2/10], Batch [1108/1562], Loss: 0.3193\n",
      "Epoch [2/10], Batch [1110/1562], Loss: 0.2683\n",
      "Epoch [2/10], Batch [1112/1562], Loss: 0.2745\n",
      "Epoch [2/10], Batch [1114/1562], Loss: 0.2839\n",
      "Epoch [2/10], Batch [1116/1562], Loss: 0.2786\n",
      "Epoch [2/10], Batch [1118/1562], Loss: 0.3023\n",
      "Epoch [2/10], Batch [1120/1562], Loss: 0.3211\n",
      "Epoch [2/10], Batch [1122/1562], Loss: 0.2875\n",
      "Epoch [2/10], Batch [1124/1562], Loss: 0.2514\n",
      "Epoch [2/10], Batch [1126/1562], Loss: 0.3133\n",
      "Epoch [2/10], Batch [1128/1562], Loss: 0.2919\n",
      "Epoch [2/10], Batch [1130/1562], Loss: 0.3204\n",
      "Epoch [2/10], Batch [1132/1562], Loss: 0.3191\n",
      "Epoch [2/10], Batch [1134/1562], Loss: 0.2878\n",
      "Epoch [2/10], Batch [1136/1562], Loss: 0.2780\n",
      "Epoch [2/10], Batch [1138/1562], Loss: 0.2764\n",
      "Epoch [2/10], Batch [1140/1562], Loss: 0.3142\n",
      "Epoch [2/10], Batch [1142/1562], Loss: 0.2697\n",
      "Epoch [2/10], Batch [1144/1562], Loss: 0.2436\n",
      "Epoch [2/10], Batch [1146/1562], Loss: 0.2747\n",
      "Epoch [2/10], Batch [1148/1562], Loss: 0.2664\n",
      "Epoch [2/10], Batch [1150/1562], Loss: 0.2773\n",
      "Epoch [2/10], Batch [1152/1562], Loss: 0.2374\n",
      "Epoch [2/10], Batch [1154/1562], Loss: 0.2618\n",
      "Epoch [2/10], Batch [1156/1562], Loss: 0.2893\n",
      "Epoch [2/10], Batch [1158/1562], Loss: 0.2703\n",
      "Epoch [2/10], Batch [1160/1562], Loss: 0.2746\n",
      "Epoch [2/10], Batch [1162/1562], Loss: 0.3454\n",
      "Epoch [2/10], Batch [1164/1562], Loss: 0.2799\n",
      "Epoch [2/10], Batch [1166/1562], Loss: 0.2653\n",
      "Epoch [2/10], Batch [1168/1562], Loss: 0.2969\n",
      "Epoch [2/10], Batch [1170/1562], Loss: 0.2802\n",
      "Epoch [2/10], Batch [1172/1562], Loss: 0.3024\n",
      "Epoch [2/10], Batch [1174/1562], Loss: 0.2501\n",
      "Epoch [2/10], Batch [1176/1562], Loss: 0.2751\n",
      "Epoch [2/10], Batch [1178/1562], Loss: 0.2901\n",
      "Epoch [2/10], Batch [1180/1562], Loss: 0.2585\n",
      "Epoch [2/10], Batch [1182/1562], Loss: 0.2485\n",
      "Epoch [2/10], Batch [1184/1562], Loss: 0.2701\n",
      "Epoch [2/10], Batch [1186/1562], Loss: 0.2638\n",
      "Epoch [2/10], Batch [1188/1562], Loss: 0.3050\n",
      "Epoch [2/10], Batch [1190/1562], Loss: 0.2363\n",
      "Epoch [2/10], Batch [1192/1562], Loss: 0.2914\n",
      "Epoch [2/10], Batch [1194/1562], Loss: 0.2499\n",
      "Epoch [2/10], Batch [1196/1562], Loss: 0.2701\n",
      "Epoch [2/10], Batch [1198/1562], Loss: 0.2988\n",
      "Epoch [2/10], Batch [1200/1562], Loss: 0.2755\n",
      "Epoch [2/10], Batch [1202/1562], Loss: 0.2802\n",
      "Epoch [2/10], Batch [1204/1562], Loss: 0.3061\n",
      "Epoch [2/10], Batch [1206/1562], Loss: 0.3128\n",
      "Epoch [2/10], Batch [1208/1562], Loss: 0.3042\n",
      "Epoch [2/10], Batch [1210/1562], Loss: 0.2860\n",
      "Epoch [2/10], Batch [1212/1562], Loss: 0.2716\n",
      "Epoch [2/10], Batch [1214/1562], Loss: 0.3325\n",
      "Epoch [2/10], Batch [1216/1562], Loss: 0.2743\n",
      "Epoch [2/10], Batch [1218/1562], Loss: 0.2840\n",
      "Epoch [2/10], Batch [1220/1562], Loss: 0.3233\n",
      "Epoch [2/10], Batch [1222/1562], Loss: 0.2911\n",
      "Epoch [2/10], Batch [1224/1562], Loss: 0.2683\n",
      "Epoch [2/10], Batch [1226/1562], Loss: 0.2685\n",
      "Epoch [2/10], Batch [1228/1562], Loss: 0.2953\n",
      "Epoch [2/10], Batch [1230/1562], Loss: 0.2792\n",
      "Epoch [2/10], Batch [1232/1562], Loss: 0.2970\n",
      "Epoch [2/10], Batch [1234/1562], Loss: 0.2852\n",
      "Epoch [2/10], Batch [1236/1562], Loss: 0.2672\n",
      "Epoch [2/10], Batch [1238/1562], Loss: 0.3245\n",
      "Epoch [2/10], Batch [1240/1562], Loss: 0.3086\n",
      "Epoch [2/10], Batch [1242/1562], Loss: 0.3062\n",
      "Epoch [2/10], Batch [1244/1562], Loss: 0.2957\n",
      "Epoch [2/10], Batch [1246/1562], Loss: 0.2793\n",
      "Epoch [2/10], Batch [1248/1562], Loss: 0.2912\n",
      "Epoch [2/10], Batch [1250/1562], Loss: 0.2850\n",
      "Epoch [2/10], Batch [1252/1562], Loss: 0.3136\n",
      "Epoch [2/10], Batch [1254/1562], Loss: 0.2796\n",
      "Epoch [2/10], Batch [1256/1562], Loss: 0.2730\n",
      "Epoch [2/10], Batch [1258/1562], Loss: 0.2551\n",
      "Epoch [2/10], Batch [1260/1562], Loss: 0.3130\n",
      "Epoch [2/10], Batch [1262/1562], Loss: 0.2871\n",
      "Epoch [2/10], Batch [1264/1562], Loss: 0.2628\n",
      "Epoch [2/10], Batch [1266/1562], Loss: 0.3092\n",
      "Epoch [2/10], Batch [1268/1562], Loss: 0.3279\n",
      "Epoch [2/10], Batch [1270/1562], Loss: 0.2715\n",
      "Epoch [2/10], Batch [1272/1562], Loss: 0.3048\n",
      "Epoch [2/10], Batch [1274/1562], Loss: 0.3084\n",
      "Epoch [2/10], Batch [1276/1562], Loss: 0.2505\n",
      "Epoch [2/10], Batch [1278/1562], Loss: 0.2788\n",
      "Epoch [2/10], Batch [1280/1562], Loss: 0.2618\n",
      "Epoch [2/10], Batch [1282/1562], Loss: 0.3317\n",
      "Epoch [2/10], Batch [1284/1562], Loss: 0.3321\n",
      "Epoch [2/10], Batch [1286/1562], Loss: 0.2957\n",
      "Epoch [2/10], Batch [1288/1562], Loss: 0.2774\n",
      "Epoch [2/10], Batch [1290/1562], Loss: 0.2902\n",
      "Epoch [2/10], Batch [1292/1562], Loss: 0.2559\n",
      "Epoch [2/10], Batch [1294/1562], Loss: 0.2678\n",
      "Epoch [2/10], Batch [1296/1562], Loss: 0.2801\n",
      "Epoch [2/10], Batch [1298/1562], Loss: 0.3180\n",
      "Epoch [2/10], Batch [1300/1562], Loss: 0.2847\n",
      "Epoch [2/10], Batch [1302/1562], Loss: 0.2814\n",
      "Epoch [2/10], Batch [1304/1562], Loss: 0.2878\n",
      "Epoch [2/10], Batch [1306/1562], Loss: 0.2609\n",
      "Epoch [2/10], Batch [1308/1562], Loss: 0.2661\n",
      "Epoch [2/10], Batch [1310/1562], Loss: 0.2573\n",
      "Epoch [2/10], Batch [1312/1562], Loss: 0.2786\n",
      "Epoch [2/10], Batch [1314/1562], Loss: 0.2607\n",
      "Epoch [2/10], Batch [1316/1562], Loss: 0.3384\n",
      "Epoch [2/10], Batch [1318/1562], Loss: 0.3033\n",
      "Epoch [2/10], Batch [1320/1562], Loss: 0.2252\n",
      "Epoch [2/10], Batch [1322/1562], Loss: 0.2822\n",
      "Epoch [2/10], Batch [1324/1562], Loss: 0.2934\n",
      "Epoch [2/10], Batch [1326/1562], Loss: 0.2733\n",
      "Epoch [2/10], Batch [1328/1562], Loss: 0.2593\n",
      "Epoch [2/10], Batch [1330/1562], Loss: 0.2952\n",
      "Epoch [2/10], Batch [1332/1562], Loss: 0.2641\n",
      "Epoch [2/10], Batch [1334/1562], Loss: 0.2827\n",
      "Epoch [2/10], Batch [1336/1562], Loss: 0.2421\n",
      "Epoch [2/10], Batch [1338/1562], Loss: 0.3128\n",
      "Epoch [2/10], Batch [1340/1562], Loss: 0.2926\n",
      "Epoch [2/10], Batch [1342/1562], Loss: 0.2836\n",
      "Epoch [2/10], Batch [1344/1562], Loss: 0.2768\n",
      "Epoch [2/10], Batch [1346/1562], Loss: 0.2384\n",
      "Epoch [2/10], Batch [1348/1562], Loss: 0.2829\n",
      "Epoch [2/10], Batch [1350/1562], Loss: 0.2774\n",
      "Epoch [2/10], Batch [1352/1562], Loss: 0.2592\n",
      "Epoch [2/10], Batch [1354/1562], Loss: 0.2983\n",
      "Epoch [2/10], Batch [1356/1562], Loss: 0.2662\n",
      "Epoch [2/10], Batch [1358/1562], Loss: 0.3162\n",
      "Epoch [2/10], Batch [1360/1562], Loss: 0.3005\n",
      "Epoch [2/10], Batch [1362/1562], Loss: 0.2978\n",
      "Epoch [2/10], Batch [1364/1562], Loss: 0.2764\n",
      "Epoch [2/10], Batch [1366/1562], Loss: 0.2829\n",
      "Epoch [2/10], Batch [1368/1562], Loss: 0.2788\n",
      "Epoch [2/10], Batch [1370/1562], Loss: 0.2722\n",
      "Epoch [2/10], Batch [1372/1562], Loss: 0.2970\n",
      "Epoch [2/10], Batch [1374/1562], Loss: 0.2955\n",
      "Epoch [2/10], Batch [1376/1562], Loss: 0.2866\n",
      "Epoch [2/10], Batch [1378/1562], Loss: 0.2696\n",
      "Epoch [2/10], Batch [1380/1562], Loss: 0.2925\n",
      "Epoch [2/10], Batch [1382/1562], Loss: 0.3056\n",
      "Epoch [2/10], Batch [1384/1562], Loss: 0.2656\n",
      "Epoch [2/10], Batch [1386/1562], Loss: 0.2794\n",
      "Epoch [2/10], Batch [1388/1562], Loss: 0.2615\n",
      "Epoch [2/10], Batch [1390/1562], Loss: 0.3474\n",
      "Epoch [2/10], Batch [1392/1562], Loss: 0.2873\n",
      "Epoch [2/10], Batch [1394/1562], Loss: 0.2604\n",
      "Epoch [2/10], Batch [1396/1562], Loss: 0.3213\n",
      "Epoch [2/10], Batch [1398/1562], Loss: 0.3049\n",
      "Epoch [2/10], Batch [1400/1562], Loss: 0.2847\n",
      "Epoch [2/10], Batch [1402/1562], Loss: 0.2881\n",
      "Epoch [2/10], Batch [1404/1562], Loss: 0.3559\n",
      "Epoch [2/10], Batch [1406/1562], Loss: 0.2869\n",
      "Epoch [2/10], Batch [1408/1562], Loss: 0.2922\n",
      "Epoch [2/10], Batch [1410/1562], Loss: 0.2949\n",
      "Epoch [2/10], Batch [1412/1562], Loss: 0.2930\n",
      "Epoch [2/10], Batch [1414/1562], Loss: 0.2576\n",
      "Epoch [2/10], Batch [1416/1562], Loss: 0.2634\n",
      "Epoch [2/10], Batch [1418/1562], Loss: 0.2947\n",
      "Epoch [2/10], Batch [1420/1562], Loss: 0.2763\n",
      "Epoch [2/10], Batch [1422/1562], Loss: 0.2860\n",
      "Epoch [2/10], Batch [1424/1562], Loss: 0.2797\n",
      "Epoch [2/10], Batch [1426/1562], Loss: 0.2727\n",
      "Epoch [2/10], Batch [1428/1562], Loss: 0.2787\n",
      "Epoch [2/10], Batch [1430/1562], Loss: 0.2996\n",
      "Epoch [2/10], Batch [1432/1562], Loss: 0.2815\n",
      "Epoch [2/10], Batch [1434/1562], Loss: 0.2913\n",
      "Epoch [2/10], Batch [1436/1562], Loss: 0.2793\n",
      "Epoch [2/10], Batch [1438/1562], Loss: 0.3139\n",
      "Epoch [2/10], Batch [1440/1562], Loss: 0.2773\n",
      "Epoch [2/10], Batch [1442/1562], Loss: 0.2890\n",
      "Epoch [2/10], Batch [1444/1562], Loss: 0.3062\n",
      "Epoch [2/10], Batch [1446/1562], Loss: 0.2688\n",
      "Epoch [2/10], Batch [1448/1562], Loss: 0.2775\n",
      "Epoch [2/10], Batch [1450/1562], Loss: 0.2929\n",
      "Epoch [2/10], Batch [1452/1562], Loss: 0.2679\n",
      "Epoch [2/10], Batch [1454/1562], Loss: 0.3096\n",
      "Epoch [2/10], Batch [1456/1562], Loss: 0.2385\n",
      "Epoch [2/10], Batch [1458/1562], Loss: 0.2649\n",
      "Epoch [2/10], Batch [1460/1562], Loss: 0.2779\n",
      "Epoch [2/10], Batch [1462/1562], Loss: 0.3336\n",
      "Epoch [2/10], Batch [1464/1562], Loss: 0.2702\n",
      "Epoch [2/10], Batch [1466/1562], Loss: 0.3043\n",
      "Epoch [2/10], Batch [1468/1562], Loss: 0.3303\n",
      "Epoch [2/10], Batch [1470/1562], Loss: 0.3076\n",
      "Epoch [2/10], Batch [1472/1562], Loss: 0.3019\n",
      "Epoch [2/10], Batch [1474/1562], Loss: 0.2897\n",
      "Epoch [2/10], Batch [1476/1562], Loss: 0.2650\n",
      "Epoch [2/10], Batch [1478/1562], Loss: 0.2950\n",
      "Epoch [2/10], Batch [1480/1562], Loss: 0.2924\n",
      "Epoch [2/10], Batch [1482/1562], Loss: 0.3505\n",
      "Epoch [2/10], Batch [1484/1562], Loss: 0.2839\n",
      "Epoch [2/10], Batch [1486/1562], Loss: 0.2950\n",
      "Epoch [2/10], Batch [1488/1562], Loss: 0.2583\n",
      "Epoch [2/10], Batch [1490/1562], Loss: 0.2392\n",
      "Epoch [2/10], Batch [1492/1562], Loss: 0.2722\n",
      "Epoch [2/10], Batch [1494/1562], Loss: 0.2994\n",
      "Epoch [2/10], Batch [1496/1562], Loss: 0.3422\n",
      "Epoch [2/10], Batch [1498/1562], Loss: 0.3354\n",
      "Epoch [2/10], Batch [1500/1562], Loss: 0.2895\n",
      "Epoch [2/10], Batch [1502/1562], Loss: 0.2453\n",
      "Epoch [2/10], Batch [1504/1562], Loss: 0.2977\n",
      "Epoch [2/10], Batch [1506/1562], Loss: 0.2832\n",
      "Epoch [2/10], Batch [1508/1562], Loss: 0.2751\n",
      "Epoch [2/10], Batch [1510/1562], Loss: 0.3002\n",
      "Epoch [2/10], Batch [1512/1562], Loss: 0.2776\n",
      "Epoch [2/10], Batch [1514/1562], Loss: 0.2719\n",
      "Epoch [2/10], Batch [1516/1562], Loss: 0.2895\n",
      "Epoch [2/10], Batch [1518/1562], Loss: 0.2878\n",
      "Epoch [2/10], Batch [1520/1562], Loss: 0.2763\n",
      "Epoch [2/10], Batch [1522/1562], Loss: 0.2750\n",
      "Epoch [2/10], Batch [1524/1562], Loss: 0.3257\n",
      "Epoch [2/10], Batch [1526/1562], Loss: 0.2587\n",
      "Epoch [2/10], Batch [1528/1562], Loss: 0.2498\n",
      "Epoch [2/10], Batch [1530/1562], Loss: 0.2961\n",
      "Epoch [2/10], Batch [1532/1562], Loss: 0.2967\n",
      "Epoch [2/10], Batch [1534/1562], Loss: 0.3253\n",
      "Epoch [2/10], Batch [1536/1562], Loss: 0.3019\n",
      "Epoch [2/10], Batch [1538/1562], Loss: 0.2815\n",
      "Epoch [2/10], Batch [1540/1562], Loss: 0.3153\n",
      "Epoch [2/10], Batch [1542/1562], Loss: 0.2755\n",
      "Epoch [2/10], Batch [1544/1562], Loss: 0.3002\n",
      "Epoch [2/10], Batch [1546/1562], Loss: 0.2955\n",
      "Epoch [2/10], Batch [1548/1562], Loss: 0.2996\n",
      "Epoch [2/10], Batch [1550/1562], Loss: 0.2737\n",
      "Epoch [2/10], Batch [1552/1562], Loss: 0.2855\n",
      "Epoch [2/10], Batch [1554/1562], Loss: 0.2462\n",
      "Epoch [2/10], Batch [1556/1562], Loss: 0.2570\n",
      "Epoch [2/10], Batch [1558/1562], Loss: 0.2878\n",
      "Epoch [2/10], Batch [1560/1562], Loss: 0.3392\n",
      "Epoch [2/10], Batch [1562/1562], Loss: 0.2921\n",
      "Epoch [2/10] completed. Average Loss: 0.2866\n",
      "Epoch [3/10], Batch [2/1562], Loss: 0.3072\n",
      "Epoch [3/10], Batch [4/1562], Loss: 0.2528\n",
      "Epoch [3/10], Batch [6/1562], Loss: 0.2938\n",
      "Epoch [3/10], Batch [8/1562], Loss: 0.3016\n",
      "Epoch [3/10], Batch [10/1562], Loss: 0.2760\n",
      "Epoch [3/10], Batch [12/1562], Loss: 0.2932\n",
      "Epoch [3/10], Batch [14/1562], Loss: 0.3079\n",
      "Epoch [3/10], Batch [16/1562], Loss: 0.2989\n",
      "Epoch [3/10], Batch [18/1562], Loss: 0.2869\n",
      "Epoch [3/10], Batch [20/1562], Loss: 0.2687\n",
      "Epoch [3/10], Batch [22/1562], Loss: 0.2784\n",
      "Epoch [3/10], Batch [24/1562], Loss: 0.2851\n",
      "Epoch [3/10], Batch [26/1562], Loss: 0.2671\n",
      "Epoch [3/10], Batch [28/1562], Loss: 0.2731\n",
      "Epoch [3/10], Batch [30/1562], Loss: 0.3179\n",
      "Epoch [3/10], Batch [32/1562], Loss: 0.3011\n",
      "Epoch [3/10], Batch [34/1562], Loss: 0.3391\n",
      "Epoch [3/10], Batch [36/1562], Loss: 0.3072\n",
      "Epoch [3/10], Batch [38/1562], Loss: 0.2674\n",
      "Epoch [3/10], Batch [40/1562], Loss: 0.2811\n",
      "Epoch [3/10], Batch [42/1562], Loss: 0.2818\n",
      "Epoch [3/10], Batch [44/1562], Loss: 0.2985\n",
      "Epoch [3/10], Batch [46/1562], Loss: 0.2839\n",
      "Epoch [3/10], Batch [48/1562], Loss: 0.3088\n",
      "Epoch [3/10], Batch [50/1562], Loss: 0.2596\n",
      "Epoch [3/10], Batch [52/1562], Loss: 0.2697\n",
      "Epoch [3/10], Batch [54/1562], Loss: 0.2775\n",
      "Epoch [3/10], Batch [56/1562], Loss: 0.3079\n",
      "Epoch [3/10], Batch [58/1562], Loss: 0.2795\n",
      "Epoch [3/10], Batch [60/1562], Loss: 0.2742\n",
      "Epoch [3/10], Batch [62/1562], Loss: 0.2719\n",
      "Epoch [3/10], Batch [64/1562], Loss: 0.2775\n",
      "Epoch [3/10], Batch [66/1562], Loss: 0.3016\n",
      "Epoch [3/10], Batch [68/1562], Loss: 0.2707\n",
      "Epoch [3/10], Batch [70/1562], Loss: 0.2999\n",
      "Epoch [3/10], Batch [72/1562], Loss: 0.3354\n",
      "Epoch [3/10], Batch [74/1562], Loss: 0.2974\n",
      "Epoch [3/10], Batch [76/1562], Loss: 0.2847\n",
      "Epoch [3/10], Batch [78/1562], Loss: 0.3117\n",
      "Epoch [3/10], Batch [80/1562], Loss: 0.2587\n",
      "Epoch [3/10], Batch [82/1562], Loss: 0.2446\n",
      "Epoch [3/10], Batch [84/1562], Loss: 0.2809\n",
      "Epoch [3/10], Batch [86/1562], Loss: 0.2983\n",
      "Epoch [3/10], Batch [88/1562], Loss: 0.3032\n",
      "Epoch [3/10], Batch [90/1562], Loss: 0.2866\n",
      "Epoch [3/10], Batch [92/1562], Loss: 0.2965\n",
      "Epoch [3/10], Batch [94/1562], Loss: 0.3046\n",
      "Epoch [3/10], Batch [96/1562], Loss: 0.3001\n",
      "Epoch [3/10], Batch [98/1562], Loss: 0.2767\n",
      "Epoch [3/10], Batch [100/1562], Loss: 0.2815\n",
      "Epoch [3/10], Batch [102/1562], Loss: 0.2214\n",
      "Epoch [3/10], Batch [104/1562], Loss: 0.2667\n",
      "Epoch [3/10], Batch [106/1562], Loss: 0.3012\n",
      "Epoch [3/10], Batch [108/1562], Loss: 0.3012\n",
      "Epoch [3/10], Batch [110/1562], Loss: 0.2717\n",
      "Epoch [3/10], Batch [112/1562], Loss: 0.3171\n",
      "Epoch [3/10], Batch [114/1562], Loss: 0.2946\n",
      "Epoch [3/10], Batch [116/1562], Loss: 0.3087\n",
      "Epoch [3/10], Batch [118/1562], Loss: 0.2889\n",
      "Epoch [3/10], Batch [120/1562], Loss: 0.3675\n",
      "Epoch [3/10], Batch [122/1562], Loss: 0.3284\n",
      "Epoch [3/10], Batch [124/1562], Loss: 0.2999\n",
      "Epoch [3/10], Batch [126/1562], Loss: 0.3013\n",
      "Epoch [3/10], Batch [128/1562], Loss: 0.2601\n",
      "Epoch [3/10], Batch [130/1562], Loss: 0.2925\n",
      "Epoch [3/10], Batch [132/1562], Loss: 0.2766\n",
      "Epoch [3/10], Batch [134/1562], Loss: 0.2964\n",
      "Epoch [3/10], Batch [136/1562], Loss: 0.2637\n",
      "Epoch [3/10], Batch [138/1562], Loss: 0.2822\n",
      "Epoch [3/10], Batch [140/1562], Loss: 0.2858\n",
      "Epoch [3/10], Batch [142/1562], Loss: 0.2737\n",
      "Epoch [3/10], Batch [144/1562], Loss: 0.2919\n",
      "Epoch [3/10], Batch [146/1562], Loss: 0.3014\n",
      "Epoch [3/10], Batch [148/1562], Loss: 0.2734\n",
      "Epoch [3/10], Batch [150/1562], Loss: 0.2502\n",
      "Epoch [3/10], Batch [152/1562], Loss: 0.2480\n",
      "Epoch [3/10], Batch [154/1562], Loss: 0.2857\n",
      "Epoch [3/10], Batch [156/1562], Loss: 0.2976\n",
      "Epoch [3/10], Batch [158/1562], Loss: 0.2776\n",
      "Epoch [3/10], Batch [160/1562], Loss: 0.2583\n",
      "Epoch [3/10], Batch [162/1562], Loss: 0.2546\n",
      "Epoch [3/10], Batch [164/1562], Loss: 0.2678\n",
      "Epoch [3/10], Batch [166/1562], Loss: 0.2968\n",
      "Epoch [3/10], Batch [168/1562], Loss: 0.3138\n",
      "Epoch [3/10], Batch [170/1562], Loss: 0.2922\n",
      "Epoch [3/10], Batch [172/1562], Loss: 0.3053\n",
      "Epoch [3/10], Batch [174/1562], Loss: 0.2759\n",
      "Epoch [3/10], Batch [176/1562], Loss: 0.2909\n",
      "Epoch [3/10], Batch [178/1562], Loss: 0.2684\n",
      "Epoch [3/10], Batch [180/1562], Loss: 0.3116\n",
      "Epoch [3/10], Batch [182/1562], Loss: 0.3089\n",
      "Epoch [3/10], Batch [184/1562], Loss: 0.2958\n",
      "Epoch [3/10], Batch [186/1562], Loss: 0.2657\n",
      "Epoch [3/10], Batch [188/1562], Loss: 0.2686\n",
      "Epoch [3/10], Batch [190/1562], Loss: 0.2937\n",
      "Epoch [3/10], Batch [192/1562], Loss: 0.2732\n",
      "Epoch [3/10], Batch [194/1562], Loss: 0.2682\n",
      "Epoch [3/10], Batch [196/1562], Loss: 0.3133\n",
      "Epoch [3/10], Batch [198/1562], Loss: 0.2996\n",
      "Epoch [3/10], Batch [200/1562], Loss: 0.2516\n",
      "Epoch [3/10], Batch [202/1562], Loss: 0.2937\n",
      "Epoch [3/10], Batch [204/1562], Loss: 0.2991\n",
      "Epoch [3/10], Batch [206/1562], Loss: 0.2881\n",
      "Epoch [3/10], Batch [208/1562], Loss: 0.2891\n",
      "Epoch [3/10], Batch [210/1562], Loss: 0.2492\n",
      "Epoch [3/10], Batch [212/1562], Loss: 0.2938\n",
      "Epoch [3/10], Batch [214/1562], Loss: 0.2823\n",
      "Epoch [3/10], Batch [216/1562], Loss: 0.2891\n",
      "Epoch [3/10], Batch [218/1562], Loss: 0.2820\n",
      "Epoch [3/10], Batch [220/1562], Loss: 0.2524\n",
      "Epoch [3/10], Batch [222/1562], Loss: 0.3006\n",
      "Epoch [3/10], Batch [224/1562], Loss: 0.3023\n",
      "Epoch [3/10], Batch [226/1562], Loss: 0.2918\n",
      "Epoch [3/10], Batch [228/1562], Loss: 0.2473\n",
      "Epoch [3/10], Batch [230/1562], Loss: 0.2769\n",
      "Epoch [3/10], Batch [232/1562], Loss: 0.3093\n",
      "Epoch [3/10], Batch [234/1562], Loss: 0.3384\n",
      "Epoch [3/10], Batch [236/1562], Loss: 0.2843\n",
      "Epoch [3/10], Batch [238/1562], Loss: 0.3116\n",
      "Epoch [3/10], Batch [240/1562], Loss: 0.2672\n",
      "Epoch [3/10], Batch [242/1562], Loss: 0.2902\n",
      "Epoch [3/10], Batch [244/1562], Loss: 0.2762\n",
      "Epoch [3/10], Batch [246/1562], Loss: 0.2455\n",
      "Epoch [3/10], Batch [248/1562], Loss: 0.3093\n",
      "Epoch [3/10], Batch [250/1562], Loss: 0.3073\n",
      "Epoch [3/10], Batch [252/1562], Loss: 0.2553\n",
      "Epoch [3/10], Batch [254/1562], Loss: 0.3062\n",
      "Epoch [3/10], Batch [256/1562], Loss: 0.2941\n",
      "Epoch [3/10], Batch [258/1562], Loss: 0.3228\n",
      "Epoch [3/10], Batch [260/1562], Loss: 0.2775\n",
      "Epoch [3/10], Batch [262/1562], Loss: 0.2909\n",
      "Epoch [3/10], Batch [264/1562], Loss: 0.2530\n",
      "Epoch [3/10], Batch [266/1562], Loss: 0.3045\n",
      "Epoch [3/10], Batch [268/1562], Loss: 0.2383\n",
      "Epoch [3/10], Batch [270/1562], Loss: 0.2806\n",
      "Epoch [3/10], Batch [272/1562], Loss: 0.2697\n",
      "Epoch [3/10], Batch [274/1562], Loss: 0.3288\n",
      "Epoch [3/10], Batch [276/1562], Loss: 0.3322\n",
      "Epoch [3/10], Batch [278/1562], Loss: 0.2653\n",
      "Epoch [3/10], Batch [280/1562], Loss: 0.2991\n",
      "Epoch [3/10], Batch [282/1562], Loss: 0.3126\n",
      "Epoch [3/10], Batch [284/1562], Loss: 0.3263\n",
      "Epoch [3/10], Batch [286/1562], Loss: 0.2682\n",
      "Epoch [3/10], Batch [288/1562], Loss: 0.2803\n",
      "Epoch [3/10], Batch [290/1562], Loss: 0.2859\n",
      "Epoch [3/10], Batch [292/1562], Loss: 0.2627\n",
      "Epoch [3/10], Batch [294/1562], Loss: 0.2625\n",
      "Epoch [3/10], Batch [296/1562], Loss: 0.2844\n",
      "Epoch [3/10], Batch [298/1562], Loss: 0.2729\n",
      "Epoch [3/10], Batch [300/1562], Loss: 0.2841\n",
      "Epoch [3/10], Batch [302/1562], Loss: 0.2935\n",
      "Epoch [3/10], Batch [304/1562], Loss: 0.2920\n",
      "Epoch [3/10], Batch [306/1562], Loss: 0.3040\n",
      "Epoch [3/10], Batch [308/1562], Loss: 0.2798\n",
      "Epoch [3/10], Batch [310/1562], Loss: 0.2776\n",
      "Epoch [3/10], Batch [312/1562], Loss: 0.3007\n",
      "Epoch [3/10], Batch [314/1562], Loss: 0.2975\n",
      "Epoch [3/10], Batch [316/1562], Loss: 0.2755\n",
      "Epoch [3/10], Batch [318/1562], Loss: 0.2985\n",
      "Epoch [3/10], Batch [320/1562], Loss: 0.2629\n",
      "Epoch [3/10], Batch [322/1562], Loss: 0.2563\n",
      "Epoch [3/10], Batch [324/1562], Loss: 0.3028\n",
      "Epoch [3/10], Batch [326/1562], Loss: 0.3348\n",
      "Epoch [3/10], Batch [328/1562], Loss: 0.2518\n",
      "Epoch [3/10], Batch [330/1562], Loss: 0.2963\n",
      "Epoch [3/10], Batch [332/1562], Loss: 0.2894\n",
      "Epoch [3/10], Batch [334/1562], Loss: 0.2760\n",
      "Epoch [3/10], Batch [336/1562], Loss: 0.2673\n",
      "Epoch [3/10], Batch [338/1562], Loss: 0.2849\n",
      "Epoch [3/10], Batch [340/1562], Loss: 0.3052\n",
      "Epoch [3/10], Batch [342/1562], Loss: 0.3177\n",
      "Epoch [3/10], Batch [344/1562], Loss: 0.2786\n",
      "Epoch [3/10], Batch [346/1562], Loss: 0.2707\n",
      "Epoch [3/10], Batch [348/1562], Loss: 0.2603\n",
      "Epoch [3/10], Batch [350/1562], Loss: 0.2455\n",
      "Epoch [3/10], Batch [352/1562], Loss: 0.3417\n",
      "Epoch [3/10], Batch [354/1562], Loss: 0.3205\n",
      "Epoch [3/10], Batch [356/1562], Loss: 0.3145\n",
      "Epoch [3/10], Batch [358/1562], Loss: 0.2745\n",
      "Epoch [3/10], Batch [360/1562], Loss: 0.3050\n",
      "Epoch [3/10], Batch [362/1562], Loss: 0.2851\n",
      "Epoch [3/10], Batch [364/1562], Loss: 0.2846\n",
      "Epoch [3/10], Batch [366/1562], Loss: 0.2994\n",
      "Epoch [3/10], Batch [368/1562], Loss: 0.2616\n",
      "Epoch [3/10], Batch [370/1562], Loss: 0.2740\n",
      "Epoch [3/10], Batch [372/1562], Loss: 0.3091\n",
      "Epoch [3/10], Batch [374/1562], Loss: 0.2814\n",
      "Epoch [3/10], Batch [376/1562], Loss: 0.2747\n",
      "Epoch [3/10], Batch [378/1562], Loss: 0.3005\n",
      "Epoch [3/10], Batch [380/1562], Loss: 0.2723\n",
      "Epoch [3/10], Batch [382/1562], Loss: 0.2504\n",
      "Epoch [3/10], Batch [384/1562], Loss: 0.2986\n",
      "Epoch [3/10], Batch [386/1562], Loss: 0.3074\n",
      "Epoch [3/10], Batch [388/1562], Loss: 0.2963\n",
      "Epoch [3/10], Batch [390/1562], Loss: 0.3064\n",
      "Epoch [3/10], Batch [392/1562], Loss: 0.3169\n",
      "Epoch [3/10], Batch [394/1562], Loss: 0.2513\n",
      "Epoch [3/10], Batch [396/1562], Loss: 0.3261\n",
      "Epoch [3/10], Batch [398/1562], Loss: 0.3309\n",
      "Epoch [3/10], Batch [400/1562], Loss: 0.2889\n",
      "Epoch [3/10], Batch [402/1562], Loss: 0.2949\n",
      "Epoch [3/10], Batch [404/1562], Loss: 0.2466\n",
      "Epoch [3/10], Batch [406/1562], Loss: 0.2827\n",
      "Epoch [3/10], Batch [408/1562], Loss: 0.2920\n",
      "Epoch [3/10], Batch [410/1562], Loss: 0.2844\n",
      "Epoch [3/10], Batch [412/1562], Loss: 0.2953\n",
      "Epoch [3/10], Batch [414/1562], Loss: 0.2737\n",
      "Epoch [3/10], Batch [416/1562], Loss: 0.2680\n",
      "Epoch [3/10], Batch [418/1562], Loss: 0.2798\n",
      "Epoch [3/10], Batch [420/1562], Loss: 0.2918\n",
      "Epoch [3/10], Batch [422/1562], Loss: 0.2761\n",
      "Epoch [3/10], Batch [424/1562], Loss: 0.2881\n",
      "Epoch [3/10], Batch [426/1562], Loss: 0.2857\n",
      "Epoch [3/10], Batch [428/1562], Loss: 0.3454\n",
      "Epoch [3/10], Batch [430/1562], Loss: 0.3092\n",
      "Epoch [3/10], Batch [432/1562], Loss: 0.2842\n",
      "Epoch [3/10], Batch [434/1562], Loss: 0.2662\n",
      "Epoch [3/10], Batch [436/1562], Loss: 0.2599\n",
      "Epoch [3/10], Batch [438/1562], Loss: 0.2726\n",
      "Epoch [3/10], Batch [440/1562], Loss: 0.2689\n",
      "Epoch [3/10], Batch [442/1562], Loss: 0.2836\n",
      "Epoch [3/10], Batch [444/1562], Loss: 0.2697\n",
      "Epoch [3/10], Batch [446/1562], Loss: 0.2741\n",
      "Epoch [3/10], Batch [448/1562], Loss: 0.2874\n",
      "Epoch [3/10], Batch [450/1562], Loss: 0.2984\n",
      "Epoch [3/10], Batch [452/1562], Loss: 0.3324\n",
      "Epoch [3/10], Batch [454/1562], Loss: 0.3034\n",
      "Epoch [3/10], Batch [456/1562], Loss: 0.2664\n",
      "Epoch [3/10], Batch [458/1562], Loss: 0.2896\n",
      "Epoch [3/10], Batch [460/1562], Loss: 0.3178\n",
      "Epoch [3/10], Batch [462/1562], Loss: 0.2929\n",
      "Epoch [3/10], Batch [464/1562], Loss: 0.2771\n",
      "Epoch [3/10], Batch [466/1562], Loss: 0.3060\n",
      "Epoch [3/10], Batch [468/1562], Loss: 0.2678\n",
      "Epoch [3/10], Batch [470/1562], Loss: 0.3166\n",
      "Epoch [3/10], Batch [472/1562], Loss: 0.2763\n",
      "Epoch [3/10], Batch [474/1562], Loss: 0.2612\n",
      "Epoch [3/10], Batch [476/1562], Loss: 0.2453\n",
      "Epoch [3/10], Batch [478/1562], Loss: 0.2743\n",
      "Epoch [3/10], Batch [480/1562], Loss: 0.3078\n",
      "Epoch [3/10], Batch [482/1562], Loss: 0.3212\n",
      "Epoch [3/10], Batch [484/1562], Loss: 0.2969\n",
      "Epoch [3/10], Batch [486/1562], Loss: 0.3288\n",
      "Epoch [3/10], Batch [488/1562], Loss: 0.2817\n",
      "Epoch [3/10], Batch [490/1562], Loss: 0.2777\n",
      "Epoch [3/10], Batch [492/1562], Loss: 0.2750\n",
      "Epoch [3/10], Batch [494/1562], Loss: 0.2574\n",
      "Epoch [3/10], Batch [496/1562], Loss: 0.3032\n",
      "Epoch [3/10], Batch [498/1562], Loss: 0.2771\n",
      "Epoch [3/10], Batch [500/1562], Loss: 0.3103\n",
      "Epoch [3/10], Batch [502/1562], Loss: 0.2957\n",
      "Epoch [3/10], Batch [504/1562], Loss: 0.2551\n",
      "Epoch [3/10], Batch [506/1562], Loss: 0.3114\n",
      "Epoch [3/10], Batch [508/1562], Loss: 0.2780\n",
      "Epoch [3/10], Batch [510/1562], Loss: 0.2769\n",
      "Epoch [3/10], Batch [512/1562], Loss: 0.3267\n",
      "Epoch [3/10], Batch [514/1562], Loss: 0.2792\n",
      "Epoch [3/10], Batch [516/1562], Loss: 0.2991\n",
      "Epoch [3/10], Batch [518/1562], Loss: 0.2909\n",
      "Epoch [3/10], Batch [520/1562], Loss: 0.3085\n",
      "Epoch [3/10], Batch [522/1562], Loss: 0.2686\n",
      "Epoch [3/10], Batch [524/1562], Loss: 0.2466\n",
      "Epoch [3/10], Batch [526/1562], Loss: 0.2739\n",
      "Epoch [3/10], Batch [528/1562], Loss: 0.2782\n",
      "Epoch [3/10], Batch [530/1562], Loss: 0.3029\n",
      "Epoch [3/10], Batch [532/1562], Loss: 0.3028\n",
      "Epoch [3/10], Batch [534/1562], Loss: 0.2960\n",
      "Epoch [3/10], Batch [536/1562], Loss: 0.2538\n",
      "Epoch [3/10], Batch [538/1562], Loss: 0.2809\n",
      "Epoch [3/10], Batch [540/1562], Loss: 0.2789\n",
      "Epoch [3/10], Batch [542/1562], Loss: 0.2902\n",
      "Epoch [3/10], Batch [544/1562], Loss: 0.2923\n",
      "Epoch [3/10], Batch [546/1562], Loss: 0.3008\n",
      "Epoch [3/10], Batch [548/1562], Loss: 0.2779\n",
      "Epoch [3/10], Batch [550/1562], Loss: 0.2804\n",
      "Epoch [3/10], Batch [552/1562], Loss: 0.2805\n",
      "Epoch [3/10], Batch [554/1562], Loss: 0.2818\n",
      "Epoch [3/10], Batch [556/1562], Loss: 0.3038\n",
      "Epoch [3/10], Batch [558/1562], Loss: 0.2853\n",
      "Epoch [3/10], Batch [560/1562], Loss: 0.2450\n",
      "Epoch [3/10], Batch [562/1562], Loss: 0.2630\n",
      "Epoch [3/10], Batch [564/1562], Loss: 0.2909\n",
      "Epoch [3/10], Batch [566/1562], Loss: 0.2785\n",
      "Epoch [3/10], Batch [568/1562], Loss: 0.3052\n",
      "Epoch [3/10], Batch [570/1562], Loss: 0.2554\n",
      "Epoch [3/10], Batch [572/1562], Loss: 0.2519\n",
      "Epoch [3/10], Batch [574/1562], Loss: 0.2486\n",
      "Epoch [3/10], Batch [576/1562], Loss: 0.2596\n",
      "Epoch [3/10], Batch [578/1562], Loss: 0.2876\n",
      "Epoch [3/10], Batch [580/1562], Loss: 0.3032\n",
      "Epoch [3/10], Batch [582/1562], Loss: 0.2333\n",
      "Epoch [3/10], Batch [584/1562], Loss: 0.2859\n",
      "Epoch [3/10], Batch [586/1562], Loss: 0.3027\n",
      "Epoch [3/10], Batch [588/1562], Loss: 0.2706\n",
      "Epoch [3/10], Batch [590/1562], Loss: 0.2606\n",
      "Epoch [3/10], Batch [592/1562], Loss: 0.2698\n",
      "Epoch [3/10], Batch [594/1562], Loss: 0.2872\n",
      "Epoch [3/10], Batch [596/1562], Loss: 0.2600\n",
      "Epoch [3/10], Batch [598/1562], Loss: 0.2547\n",
      "Epoch [3/10], Batch [600/1562], Loss: 0.3037\n",
      "Epoch [3/10], Batch [602/1562], Loss: 0.3212\n",
      "Epoch [3/10], Batch [604/1562], Loss: 0.2845\n",
      "Epoch [3/10], Batch [606/1562], Loss: 0.3076\n",
      "Epoch [3/10], Batch [608/1562], Loss: 0.2729\n",
      "Epoch [3/10], Batch [610/1562], Loss: 0.2718\n",
      "Epoch [3/10], Batch [612/1562], Loss: 0.3062\n",
      "Epoch [3/10], Batch [614/1562], Loss: 0.2379\n",
      "Epoch [3/10], Batch [616/1562], Loss: 0.3071\n",
      "Epoch [3/10], Batch [618/1562], Loss: 0.2429\n",
      "Epoch [3/10], Batch [620/1562], Loss: 0.2750\n",
      "Epoch [3/10], Batch [622/1562], Loss: 0.2541\n",
      "Epoch [3/10], Batch [624/1562], Loss: 0.2564\n",
      "Epoch [3/10], Batch [626/1562], Loss: 0.2843\n",
      "Epoch [3/10], Batch [628/1562], Loss: 0.2607\n",
      "Epoch [3/10], Batch [630/1562], Loss: 0.2902\n",
      "Epoch [3/10], Batch [632/1562], Loss: 0.2701\n",
      "Epoch [3/10], Batch [634/1562], Loss: 0.3074\n",
      "Epoch [3/10], Batch [636/1562], Loss: 0.2794\n",
      "Epoch [3/10], Batch [638/1562], Loss: 0.2998\n",
      "Epoch [3/10], Batch [640/1562], Loss: 0.3254\n",
      "Epoch [3/10], Batch [642/1562], Loss: 0.2852\n",
      "Epoch [3/10], Batch [644/1562], Loss: 0.2981\n",
      "Epoch [3/10], Batch [646/1562], Loss: 0.2842\n",
      "Epoch [3/10], Batch [648/1562], Loss: 0.3237\n",
      "Epoch [3/10], Batch [650/1562], Loss: 0.2724\n",
      "Epoch [3/10], Batch [652/1562], Loss: 0.3197\n",
      "Epoch [3/10], Batch [654/1562], Loss: 0.2811\n",
      "Epoch [3/10], Batch [656/1562], Loss: 0.2815\n",
      "Epoch [3/10], Batch [658/1562], Loss: 0.3029\n",
      "Epoch [3/10], Batch [660/1562], Loss: 0.2674\n",
      "Epoch [3/10], Batch [662/1562], Loss: 0.2680\n",
      "Epoch [3/10], Batch [664/1562], Loss: 0.2350\n",
      "Epoch [3/10], Batch [666/1562], Loss: 0.2867\n",
      "Epoch [3/10], Batch [668/1562], Loss: 0.2929\n",
      "Epoch [3/10], Batch [670/1562], Loss: 0.2743\n",
      "Epoch [3/10], Batch [672/1562], Loss: 0.3169\n",
      "Epoch [3/10], Batch [674/1562], Loss: 0.2975\n",
      "Epoch [3/10], Batch [676/1562], Loss: 0.2652\n",
      "Epoch [3/10], Batch [678/1562], Loss: 0.3140\n",
      "Epoch [3/10], Batch [680/1562], Loss: 0.2694\n",
      "Epoch [3/10], Batch [682/1562], Loss: 0.2735\n",
      "Epoch [3/10], Batch [684/1562], Loss: 0.2366\n",
      "Epoch [3/10], Batch [686/1562], Loss: 0.2730\n",
      "Epoch [3/10], Batch [688/1562], Loss: 0.3034\n",
      "Epoch [3/10], Batch [690/1562], Loss: 0.2837\n",
      "Epoch [3/10], Batch [692/1562], Loss: 0.2836\n",
      "Epoch [3/10], Batch [694/1562], Loss: 0.2838\n",
      "Epoch [3/10], Batch [696/1562], Loss: 0.2964\n",
      "Epoch [3/10], Batch [698/1562], Loss: 0.2601\n",
      "Epoch [3/10], Batch [700/1562], Loss: 0.3043\n",
      "Epoch [3/10], Batch [702/1562], Loss: 0.2968\n",
      "Epoch [3/10], Batch [704/1562], Loss: 0.2979\n",
      "Epoch [3/10], Batch [706/1562], Loss: 0.3121\n",
      "Epoch [3/10], Batch [708/1562], Loss: 0.2906\n",
      "Epoch [3/10], Batch [710/1562], Loss: 0.2485\n",
      "Epoch [3/10], Batch [712/1562], Loss: 0.2973\n",
      "Epoch [3/10], Batch [714/1562], Loss: 0.3238\n",
      "Epoch [3/10], Batch [716/1562], Loss: 0.2934\n",
      "Epoch [3/10], Batch [718/1562], Loss: 0.2900\n",
      "Epoch [3/10], Batch [720/1562], Loss: 0.3319\n",
      "Epoch [3/10], Batch [722/1562], Loss: 0.3109\n",
      "Epoch [3/10], Batch [724/1562], Loss: 0.2692\n",
      "Epoch [3/10], Batch [726/1562], Loss: 0.2794\n",
      "Epoch [3/10], Batch [728/1562], Loss: 0.3019\n",
      "Epoch [3/10], Batch [730/1562], Loss: 0.2703\n",
      "Epoch [3/10], Batch [732/1562], Loss: 0.2745\n",
      "Epoch [3/10], Batch [734/1562], Loss: 0.2759\n",
      "Epoch [3/10], Batch [736/1562], Loss: 0.2986\n",
      "Epoch [3/10], Batch [738/1562], Loss: 0.2653\n",
      "Epoch [3/10], Batch [740/1562], Loss: 0.2744\n",
      "Epoch [3/10], Batch [742/1562], Loss: 0.2859\n",
      "Epoch [3/10], Batch [744/1562], Loss: 0.2844\n",
      "Epoch [3/10], Batch [746/1562], Loss: 0.2550\n",
      "Epoch [3/10], Batch [748/1562], Loss: 0.2783\n",
      "Epoch [3/10], Batch [750/1562], Loss: 0.2911\n",
      "Epoch [3/10], Batch [752/1562], Loss: 0.2828\n",
      "Epoch [3/10], Batch [754/1562], Loss: 0.3354\n",
      "Epoch [3/10], Batch [756/1562], Loss: 0.2767\n",
      "Epoch [3/10], Batch [758/1562], Loss: 0.2654\n",
      "Epoch [3/10], Batch [760/1562], Loss: 0.2689\n",
      "Epoch [3/10], Batch [762/1562], Loss: 0.2790\n",
      "Epoch [3/10], Batch [764/1562], Loss: 0.3171\n",
      "Epoch [3/10], Batch [766/1562], Loss: 0.2675\n",
      "Epoch [3/10], Batch [768/1562], Loss: 0.2446\n",
      "Epoch [3/10], Batch [770/1562], Loss: 0.3065\n",
      "Epoch [3/10], Batch [772/1562], Loss: 0.2832\n",
      "Epoch [3/10], Batch [774/1562], Loss: 0.3224\n",
      "Epoch [3/10], Batch [776/1562], Loss: 0.2891\n",
      "Epoch [3/10], Batch [778/1562], Loss: 0.2629\n",
      "Epoch [3/10], Batch [780/1562], Loss: 0.2507\n",
      "Epoch [3/10], Batch [782/1562], Loss: 0.2590\n",
      "Epoch [3/10], Batch [784/1562], Loss: 0.2880\n",
      "Epoch [3/10], Batch [786/1562], Loss: 0.2989\n",
      "Epoch [3/10], Batch [788/1562], Loss: 0.2906\n",
      "Epoch [3/10], Batch [790/1562], Loss: 0.2737\n",
      "Epoch [3/10], Batch [792/1562], Loss: 0.3150\n",
      "Epoch [3/10], Batch [794/1562], Loss: 0.2809\n",
      "Epoch [3/10], Batch [796/1562], Loss: 0.3020\n",
      "Epoch [3/10], Batch [798/1562], Loss: 0.2403\n",
      "Epoch [3/10], Batch [800/1562], Loss: 0.2773\n",
      "Epoch [3/10], Batch [802/1562], Loss: 0.3103\n",
      "Epoch [3/10], Batch [804/1562], Loss: 0.2458\n",
      "Epoch [3/10], Batch [806/1562], Loss: 0.2532\n",
      "Epoch [3/10], Batch [808/1562], Loss: 0.3333\n",
      "Epoch [3/10], Batch [810/1562], Loss: 0.2641\n",
      "Epoch [3/10], Batch [812/1562], Loss: 0.3251\n",
      "Epoch [3/10], Batch [814/1562], Loss: 0.2733\n",
      "Epoch [3/10], Batch [816/1562], Loss: 0.2608\n",
      "Epoch [3/10], Batch [818/1562], Loss: 0.2882\n",
      "Epoch [3/10], Batch [820/1562], Loss: 0.3408\n",
      "Epoch [3/10], Batch [822/1562], Loss: 0.2946\n",
      "Epoch [3/10], Batch [824/1562], Loss: 0.3066\n",
      "Epoch [3/10], Batch [826/1562], Loss: 0.2711\n",
      "Epoch [3/10], Batch [828/1562], Loss: 0.2645\n",
      "Epoch [3/10], Batch [830/1562], Loss: 0.3223\n",
      "Epoch [3/10], Batch [832/1562], Loss: 0.3269\n",
      "Epoch [3/10], Batch [834/1562], Loss: 0.3020\n",
      "Epoch [3/10], Batch [836/1562], Loss: 0.3126\n",
      "Epoch [3/10], Batch [838/1562], Loss: 0.3190\n",
      "Epoch [3/10], Batch [840/1562], Loss: 0.2728\n",
      "Epoch [3/10], Batch [842/1562], Loss: 0.2798\n",
      "Epoch [3/10], Batch [844/1562], Loss: 0.2803\n",
      "Epoch [3/10], Batch [846/1562], Loss: 0.2570\n",
      "Epoch [3/10], Batch [848/1562], Loss: 0.2892\n",
      "Epoch [3/10], Batch [850/1562], Loss: 0.3326\n",
      "Epoch [3/10], Batch [852/1562], Loss: 0.2793\n",
      "Epoch [3/10], Batch [854/1562], Loss: 0.2441\n",
      "Epoch [3/10], Batch [856/1562], Loss: 0.2949\n",
      "Epoch [3/10], Batch [858/1562], Loss: 0.3025\n",
      "Epoch [3/10], Batch [860/1562], Loss: 0.3105\n",
      "Epoch [3/10], Batch [862/1562], Loss: 0.2802\n",
      "Epoch [3/10], Batch [864/1562], Loss: 0.2585\n",
      "Epoch [3/10], Batch [866/1562], Loss: 0.3100\n",
      "Epoch [3/10], Batch [868/1562], Loss: 0.2492\n",
      "Epoch [3/10], Batch [870/1562], Loss: 0.3140\n",
      "Epoch [3/10], Batch [872/1562], Loss: 0.3065\n",
      "Epoch [3/10], Batch [874/1562], Loss: 0.3260\n",
      "Epoch [3/10], Batch [876/1562], Loss: 0.2794\n",
      "Epoch [3/10], Batch [878/1562], Loss: 0.2946\n",
      "Epoch [3/10], Batch [880/1562], Loss: 0.2787\n",
      "Epoch [3/10], Batch [882/1562], Loss: 0.3003\n",
      "Epoch [3/10], Batch [884/1562], Loss: 0.2724\n",
      "Epoch [3/10], Batch [886/1562], Loss: 0.2967\n",
      "Epoch [3/10], Batch [888/1562], Loss: 0.2720\n",
      "Epoch [3/10], Batch [890/1562], Loss: 0.3004\n",
      "Epoch [3/10], Batch [892/1562], Loss: 0.3098\n",
      "Epoch [3/10], Batch [894/1562], Loss: 0.3141\n",
      "Epoch [3/10], Batch [896/1562], Loss: 0.2927\n",
      "Epoch [3/10], Batch [898/1562], Loss: 0.3086\n",
      "Epoch [3/10], Batch [900/1562], Loss: 0.2379\n",
      "Epoch [3/10], Batch [902/1562], Loss: 0.2867\n",
      "Epoch [3/10], Batch [904/1562], Loss: 0.3106\n",
      "Epoch [3/10], Batch [906/1562], Loss: 0.2473\n",
      "Epoch [3/10], Batch [908/1562], Loss: 0.2984\n",
      "Epoch [3/10], Batch [910/1562], Loss: 0.3013\n",
      "Epoch [3/10], Batch [912/1562], Loss: 0.2792\n",
      "Epoch [3/10], Batch [914/1562], Loss: 0.3044\n",
      "Epoch [3/10], Batch [916/1562], Loss: 0.2746\n",
      "Epoch [3/10], Batch [918/1562], Loss: 0.3228\n",
      "Epoch [3/10], Batch [920/1562], Loss: 0.3019\n",
      "Epoch [3/10], Batch [922/1562], Loss: 0.2706\n",
      "Epoch [3/10], Batch [924/1562], Loss: 0.2981\n",
      "Epoch [3/10], Batch [926/1562], Loss: 0.3404\n",
      "Epoch [3/10], Batch [928/1562], Loss: 0.2865\n",
      "Epoch [3/10], Batch [930/1562], Loss: 0.3002\n",
      "Epoch [3/10], Batch [932/1562], Loss: 0.2532\n",
      "Epoch [3/10], Batch [934/1562], Loss: 0.2506\n",
      "Epoch [3/10], Batch [936/1562], Loss: 0.2998\n",
      "Epoch [3/10], Batch [938/1562], Loss: 0.2680\n",
      "Epoch [3/10], Batch [940/1562], Loss: 0.3066\n",
      "Epoch [3/10], Batch [942/1562], Loss: 0.2942\n",
      "Epoch [3/10], Batch [944/1562], Loss: 0.2636\n",
      "Epoch [3/10], Batch [946/1562], Loss: 0.3009\n",
      "Epoch [3/10], Batch [948/1562], Loss: 0.2867\n",
      "Epoch [3/10], Batch [950/1562], Loss: 0.2557\n",
      "Epoch [3/10], Batch [952/1562], Loss: 0.2820\n",
      "Epoch [3/10], Batch [954/1562], Loss: 0.2635\n",
      "Epoch [3/10], Batch [956/1562], Loss: 0.2998\n",
      "Epoch [3/10], Batch [958/1562], Loss: 0.2762\n",
      "Epoch [3/10], Batch [960/1562], Loss: 0.3245\n",
      "Epoch [3/10], Batch [962/1562], Loss: 0.3137\n",
      "Epoch [3/10], Batch [964/1562], Loss: 0.2916\n",
      "Epoch [3/10], Batch [966/1562], Loss: 0.3141\n",
      "Epoch [3/10], Batch [968/1562], Loss: 0.3115\n",
      "Epoch [3/10], Batch [970/1562], Loss: 0.2750\n",
      "Epoch [3/10], Batch [972/1562], Loss: 0.3294\n",
      "Epoch [3/10], Batch [974/1562], Loss: 0.2531\n",
      "Epoch [3/10], Batch [976/1562], Loss: 0.2851\n",
      "Epoch [3/10], Batch [978/1562], Loss: 0.3049\n",
      "Epoch [3/10], Batch [980/1562], Loss: 0.2676\n",
      "Epoch [3/10], Batch [982/1562], Loss: 0.3015\n",
      "Epoch [3/10], Batch [984/1562], Loss: 0.3214\n",
      "Epoch [3/10], Batch [986/1562], Loss: 0.2606\n",
      "Epoch [3/10], Batch [988/1562], Loss: 0.2708\n",
      "Epoch [3/10], Batch [990/1562], Loss: 0.3199\n",
      "Epoch [3/10], Batch [992/1562], Loss: 0.3043\n",
      "Epoch [3/10], Batch [994/1562], Loss: 0.3369\n",
      "Epoch [3/10], Batch [996/1562], Loss: 0.2783\n",
      "Epoch [3/10], Batch [998/1562], Loss: 0.3222\n",
      "Epoch [3/10], Batch [1000/1562], Loss: 0.2855\n",
      "Epoch [3/10], Batch [1002/1562], Loss: 0.2771\n",
      "Epoch [3/10], Batch [1004/1562], Loss: 0.2811\n",
      "Epoch [3/10], Batch [1006/1562], Loss: 0.2611\n",
      "Epoch [3/10], Batch [1008/1562], Loss: 0.2958\n",
      "Epoch [3/10], Batch [1010/1562], Loss: 0.3376\n",
      "Epoch [3/10], Batch [1012/1562], Loss: 0.3154\n",
      "Epoch [3/10], Batch [1014/1562], Loss: 0.3275\n",
      "Epoch [3/10], Batch [1016/1562], Loss: 0.2947\n",
      "Epoch [3/10], Batch [1018/1562], Loss: 0.2632\n",
      "Epoch [3/10], Batch [1020/1562], Loss: 0.2979\n",
      "Epoch [3/10], Batch [1022/1562], Loss: 0.2470\n",
      "Epoch [3/10], Batch [1024/1562], Loss: 0.2755\n",
      "Epoch [3/10], Batch [1026/1562], Loss: 0.3074\n",
      "Epoch [3/10], Batch [1028/1562], Loss: 0.2446\n",
      "Epoch [3/10], Batch [1030/1562], Loss: 0.2608\n",
      "Epoch [3/10], Batch [1032/1562], Loss: 0.2706\n",
      "Epoch [3/10], Batch [1034/1562], Loss: 0.2582\n",
      "Epoch [3/10], Batch [1036/1562], Loss: 0.2830\n",
      "Epoch [3/10], Batch [1038/1562], Loss: 0.3123\n",
      "Epoch [3/10], Batch [1040/1562], Loss: 0.2981\n",
      "Epoch [3/10], Batch [1042/1562], Loss: 0.2709\n",
      "Epoch [3/10], Batch [1044/1562], Loss: 0.2772\n",
      "Epoch [3/10], Batch [1046/1562], Loss: 0.3171\n",
      "Epoch [3/10], Batch [1048/1562], Loss: 0.2892\n",
      "Epoch [3/10], Batch [1050/1562], Loss: 0.2884\n",
      "Epoch [3/10], Batch [1052/1562], Loss: 0.2956\n",
      "Epoch [3/10], Batch [1054/1562], Loss: 0.2801\n",
      "Epoch [3/10], Batch [1056/1562], Loss: 0.2849\n",
      "Epoch [3/10], Batch [1058/1562], Loss: 0.2575\n",
      "Epoch [3/10], Batch [1060/1562], Loss: 0.2552\n",
      "Epoch [3/10], Batch [1062/1562], Loss: 0.2892\n",
      "Epoch [3/10], Batch [1064/1562], Loss: 0.2923\n",
      "Epoch [3/10], Batch [1066/1562], Loss: 0.2486\n",
      "Epoch [3/10], Batch [1068/1562], Loss: 0.3000\n",
      "Epoch [3/10], Batch [1070/1562], Loss: 0.2691\n",
      "Epoch [3/10], Batch [1072/1562], Loss: 0.3197\n",
      "Epoch [3/10], Batch [1074/1562], Loss: 0.2944\n",
      "Epoch [3/10], Batch [1076/1562], Loss: 0.2406\n",
      "Epoch [3/10], Batch [1078/1562], Loss: 0.2991\n",
      "Epoch [3/10], Batch [1080/1562], Loss: 0.2567\n",
      "Epoch [3/10], Batch [1082/1562], Loss: 0.3151\n",
      "Epoch [3/10], Batch [1084/1562], Loss: 0.2873\n",
      "Epoch [3/10], Batch [1086/1562], Loss: 0.3563\n",
      "Epoch [3/10], Batch [1088/1562], Loss: 0.2940\n",
      "Epoch [3/10], Batch [1090/1562], Loss: 0.3159\n",
      "Epoch [3/10], Batch [1092/1562], Loss: 0.2939\n",
      "Epoch [3/10], Batch [1094/1562], Loss: 0.2652\n",
      "Epoch [3/10], Batch [1096/1562], Loss: 0.2900\n",
      "Epoch [3/10], Batch [1098/1562], Loss: 0.3115\n",
      "Epoch [3/10], Batch [1100/1562], Loss: 0.2746\n",
      "Epoch [3/10], Batch [1102/1562], Loss: 0.2557\n",
      "Epoch [3/10], Batch [1104/1562], Loss: 0.2849\n",
      "Epoch [3/10], Batch [1106/1562], Loss: 0.2751\n",
      "Epoch [3/10], Batch [1108/1562], Loss: 0.2914\n",
      "Epoch [3/10], Batch [1110/1562], Loss: 0.2807\n",
      "Epoch [3/10], Batch [1112/1562], Loss: 0.3583\n",
      "Epoch [3/10], Batch [1114/1562], Loss: 0.2801\n",
      "Epoch [3/10], Batch [1116/1562], Loss: 0.2655\n",
      "Epoch [3/10], Batch [1118/1562], Loss: 0.2698\n",
      "Epoch [3/10], Batch [1120/1562], Loss: 0.2955\n",
      "Epoch [3/10], Batch [1122/1562], Loss: 0.2960\n",
      "Epoch [3/10], Batch [1124/1562], Loss: 0.2638\n",
      "Epoch [3/10], Batch [1126/1562], Loss: 0.3183\n",
      "Epoch [3/10], Batch [1128/1562], Loss: 0.2667\n",
      "Epoch [3/10], Batch [1130/1562], Loss: 0.3034\n",
      "Epoch [3/10], Batch [1132/1562], Loss: 0.2867\n",
      "Epoch [3/10], Batch [1134/1562], Loss: 0.2446\n",
      "Epoch [3/10], Batch [1136/1562], Loss: 0.2722\n",
      "Epoch [3/10], Batch [1138/1562], Loss: 0.2683\n",
      "Epoch [3/10], Batch [1140/1562], Loss: 0.3571\n",
      "Epoch [3/10], Batch [1142/1562], Loss: 0.2573\n",
      "Epoch [3/10], Batch [1144/1562], Loss: 0.2563\n",
      "Epoch [3/10], Batch [1146/1562], Loss: 0.2806\n",
      "Epoch [3/10], Batch [1148/1562], Loss: 0.3065\n",
      "Epoch [3/10], Batch [1150/1562], Loss: 0.3077\n",
      "Epoch [3/10], Batch [1152/1562], Loss: 0.2708\n",
      "Epoch [3/10], Batch [1154/1562], Loss: 0.2924\n",
      "Epoch [3/10], Batch [1156/1562], Loss: 0.2736\n",
      "Epoch [3/10], Batch [1158/1562], Loss: 0.3050\n",
      "Epoch [3/10], Batch [1160/1562], Loss: 0.3008\n",
      "Epoch [3/10], Batch [1162/1562], Loss: 0.2552\n",
      "Epoch [3/10], Batch [1164/1562], Loss: 0.3047\n",
      "Epoch [3/10], Batch [1166/1562], Loss: 0.2646\n",
      "Epoch [3/10], Batch [1168/1562], Loss: 0.3115\n",
      "Epoch [3/10], Batch [1170/1562], Loss: 0.2598\n",
      "Epoch [3/10], Batch [1172/1562], Loss: 0.2831\n",
      "Epoch [3/10], Batch [1174/1562], Loss: 0.3094\n",
      "Epoch [3/10], Batch [1176/1562], Loss: 0.2326\n",
      "Epoch [3/10], Batch [1178/1562], Loss: 0.2754\n",
      "Epoch [3/10], Batch [1180/1562], Loss: 0.2803\n",
      "Epoch [3/10], Batch [1182/1562], Loss: 0.2653\n",
      "Epoch [3/10], Batch [1184/1562], Loss: 0.2708\n",
      "Epoch [3/10], Batch [1186/1562], Loss: 0.2832\n",
      "Epoch [3/10], Batch [1188/1562], Loss: 0.2699\n",
      "Epoch [3/10], Batch [1190/1562], Loss: 0.2947\n",
      "Epoch [3/10], Batch [1192/1562], Loss: 0.2727\n",
      "Epoch [3/10], Batch [1194/1562], Loss: 0.2417\n",
      "Epoch [3/10], Batch [1196/1562], Loss: 0.2952\n",
      "Epoch [3/10], Batch [1198/1562], Loss: 0.3326\n",
      "Epoch [3/10], Batch [1200/1562], Loss: 0.2764\n",
      "Epoch [3/10], Batch [1202/1562], Loss: 0.2623\n",
      "Epoch [3/10], Batch [1204/1562], Loss: 0.2755\n",
      "Epoch [3/10], Batch [1206/1562], Loss: 0.2828\n",
      "Epoch [3/10], Batch [1208/1562], Loss: 0.2421\n",
      "Epoch [3/10], Batch [1210/1562], Loss: 0.3126\n",
      "Epoch [3/10], Batch [1212/1562], Loss: 0.3006\n",
      "Epoch [3/10], Batch [1214/1562], Loss: 0.2948\n",
      "Epoch [3/10], Batch [1216/1562], Loss: 0.2801\n",
      "Epoch [3/10], Batch [1218/1562], Loss: 0.3112\n",
      "Epoch [3/10], Batch [1220/1562], Loss: 0.2844\n",
      "Epoch [3/10], Batch [1222/1562], Loss: 0.2976\n",
      "Epoch [3/10], Batch [1224/1562], Loss: 0.2635\n",
      "Epoch [3/10], Batch [1226/1562], Loss: 0.2796\n",
      "Epoch [3/10], Batch [1228/1562], Loss: 0.2730\n",
      "Epoch [3/10], Batch [1230/1562], Loss: 0.2919\n",
      "Epoch [3/10], Batch [1232/1562], Loss: 0.2871\n",
      "Epoch [3/10], Batch [1234/1562], Loss: 0.3100\n",
      "Epoch [3/10], Batch [1236/1562], Loss: 0.3057\n",
      "Epoch [3/10], Batch [1238/1562], Loss: 0.2877\n",
      "Epoch [3/10], Batch [1240/1562], Loss: 0.2828\n",
      "Epoch [3/10], Batch [1242/1562], Loss: 0.3260\n",
      "Epoch [3/10], Batch [1244/1562], Loss: 0.2868\n",
      "Epoch [3/10], Batch [1246/1562], Loss: 0.3229\n",
      "Epoch [3/10], Batch [1248/1562], Loss: 0.3018\n",
      "Epoch [3/10], Batch [1250/1562], Loss: 0.3033\n",
      "Epoch [3/10], Batch [1252/1562], Loss: 0.2952\n",
      "Epoch [3/10], Batch [1254/1562], Loss: 0.2943\n",
      "Epoch [3/10], Batch [1256/1562], Loss: 0.3125\n",
      "Epoch [3/10], Batch [1258/1562], Loss: 0.2764\n",
      "Epoch [3/10], Batch [1260/1562], Loss: 0.2967\n",
      "Epoch [3/10], Batch [1262/1562], Loss: 0.2895\n",
      "Epoch [3/10], Batch [1264/1562], Loss: 0.3001\n",
      "Epoch [3/10], Batch [1266/1562], Loss: 0.3268\n",
      "Epoch [3/10], Batch [1268/1562], Loss: 0.3082\n",
      "Epoch [3/10], Batch [1270/1562], Loss: 0.3057\n",
      "Epoch [3/10], Batch [1272/1562], Loss: 0.2759\n",
      "Epoch [3/10], Batch [1274/1562], Loss: 0.3237\n",
      "Epoch [3/10], Batch [1276/1562], Loss: 0.3176\n",
      "Epoch [3/10], Batch [1278/1562], Loss: 0.3143\n",
      "Epoch [3/10], Batch [1280/1562], Loss: 0.2686\n",
      "Epoch [3/10], Batch [1282/1562], Loss: 0.2647\n",
      "Epoch [3/10], Batch [1284/1562], Loss: 0.2557\n",
      "Epoch [3/10], Batch [1286/1562], Loss: 0.3342\n",
      "Epoch [3/10], Batch [1288/1562], Loss: 0.2512\n",
      "Epoch [3/10], Batch [1290/1562], Loss: 0.2985\n",
      "Epoch [3/10], Batch [1292/1562], Loss: 0.2981\n",
      "Epoch [3/10], Batch [1294/1562], Loss: 0.2771\n",
      "Epoch [3/10], Batch [1296/1562], Loss: 0.2695\n",
      "Epoch [3/10], Batch [1298/1562], Loss: 0.2633\n",
      "Epoch [3/10], Batch [1300/1562], Loss: 0.2611\n",
      "Epoch [3/10], Batch [1302/1562], Loss: 0.3588\n",
      "Epoch [3/10], Batch [1304/1562], Loss: 0.3160\n",
      "Epoch [3/10], Batch [1306/1562], Loss: 0.2996\n",
      "Epoch [3/10], Batch [1308/1562], Loss: 0.2684\n",
      "Epoch [3/10], Batch [1310/1562], Loss: 0.2413\n",
      "Epoch [3/10], Batch [1312/1562], Loss: 0.2732\n",
      "Epoch [3/10], Batch [1314/1562], Loss: 0.2700\n",
      "Epoch [3/10], Batch [1316/1562], Loss: 0.2795\n",
      "Epoch [3/10], Batch [1318/1562], Loss: 0.2502\n",
      "Epoch [3/10], Batch [1320/1562], Loss: 0.2612\n",
      "Epoch [3/10], Batch [1322/1562], Loss: 0.2518\n",
      "Epoch [3/10], Batch [1324/1562], Loss: 0.3368\n",
      "Epoch [3/10], Batch [1326/1562], Loss: 0.2955\n",
      "Epoch [3/10], Batch [1328/1562], Loss: 0.2650\n",
      "Epoch [3/10], Batch [1330/1562], Loss: 0.2745\n",
      "Epoch [3/10], Batch [1332/1562], Loss: 0.2892\n",
      "Epoch [3/10], Batch [1334/1562], Loss: 0.3208\n",
      "Epoch [3/10], Batch [1336/1562], Loss: 0.2887\n",
      "Epoch [3/10], Batch [1338/1562], Loss: 0.2990\n",
      "Epoch [3/10], Batch [1340/1562], Loss: 0.2907\n",
      "Epoch [3/10], Batch [1342/1562], Loss: 0.2959\n",
      "Epoch [3/10], Batch [1344/1562], Loss: 0.2826\n",
      "Epoch [3/10], Batch [1346/1562], Loss: 0.2782\n",
      "Epoch [3/10], Batch [1348/1562], Loss: 0.3018\n",
      "Epoch [3/10], Batch [1350/1562], Loss: 0.2829\n",
      "Epoch [3/10], Batch [1352/1562], Loss: 0.3053\n",
      "Epoch [3/10], Batch [1354/1562], Loss: 0.2861\n",
      "Epoch [3/10], Batch [1356/1562], Loss: 0.3154\n",
      "Epoch [3/10], Batch [1358/1562], Loss: 0.2763\n",
      "Epoch [3/10], Batch [1360/1562], Loss: 0.2243\n",
      "Epoch [3/10], Batch [1362/1562], Loss: 0.2518\n",
      "Epoch [3/10], Batch [1364/1562], Loss: 0.2838\n",
      "Epoch [3/10], Batch [1366/1562], Loss: 0.2657\n",
      "Epoch [3/10], Batch [1368/1562], Loss: 0.2595\n",
      "Epoch [3/10], Batch [1370/1562], Loss: 0.2472\n",
      "Epoch [3/10], Batch [1372/1562], Loss: 0.2917\n",
      "Epoch [3/10], Batch [1374/1562], Loss: 0.3119\n",
      "Epoch [3/10], Batch [1376/1562], Loss: 0.3133\n",
      "Epoch [3/10], Batch [1378/1562], Loss: 0.3144\n",
      "Epoch [3/10], Batch [1380/1562], Loss: 0.3018\n",
      "Epoch [3/10], Batch [1382/1562], Loss: 0.3033\n",
      "Epoch [3/10], Batch [1384/1562], Loss: 0.2729\n",
      "Epoch [3/10], Batch [1386/1562], Loss: 0.3132\n",
      "Epoch [3/10], Batch [1388/1562], Loss: 0.2678\n",
      "Epoch [3/10], Batch [1390/1562], Loss: 0.2473\n",
      "Epoch [3/10], Batch [1392/1562], Loss: 0.2787\n",
      "Epoch [3/10], Batch [1394/1562], Loss: 0.2626\n",
      "Epoch [3/10], Batch [1396/1562], Loss: 0.2835\n",
      "Epoch [3/10], Batch [1398/1562], Loss: 0.2501\n",
      "Epoch [3/10], Batch [1400/1562], Loss: 0.2870\n",
      "Epoch [3/10], Batch [1402/1562], Loss: 0.3072\n",
      "Epoch [3/10], Batch [1404/1562], Loss: 0.2710\n",
      "Epoch [3/10], Batch [1406/1562], Loss: 0.2770\n",
      "Epoch [3/10], Batch [1408/1562], Loss: 0.3260\n",
      "Epoch [3/10], Batch [1410/1562], Loss: 0.2885\n",
      "Epoch [3/10], Batch [1412/1562], Loss: 0.2886\n",
      "Epoch [3/10], Batch [1414/1562], Loss: 0.3057\n",
      "Epoch [3/10], Batch [1416/1562], Loss: 0.3042\n",
      "Epoch [3/10], Batch [1418/1562], Loss: 0.3099\n",
      "Epoch [3/10], Batch [1420/1562], Loss: 0.2800\n",
      "Epoch [3/10], Batch [1422/1562], Loss: 0.3070\n",
      "Epoch [3/10], Batch [1424/1562], Loss: 0.3024\n",
      "Epoch [3/10], Batch [1426/1562], Loss: 0.2795\n",
      "Epoch [3/10], Batch [1428/1562], Loss: 0.2957\n",
      "Epoch [3/10], Batch [1430/1562], Loss: 0.2681\n",
      "Epoch [3/10], Batch [1432/1562], Loss: 0.2818\n",
      "Epoch [3/10], Batch [1434/1562], Loss: 0.2942\n",
      "Epoch [3/10], Batch [1436/1562], Loss: 0.2866\n",
      "Epoch [3/10], Batch [1438/1562], Loss: 0.3159\n",
      "Epoch [3/10], Batch [1440/1562], Loss: 0.3030\n",
      "Epoch [3/10], Batch [1442/1562], Loss: 0.3306\n",
      "Epoch [3/10], Batch [1444/1562], Loss: 0.3224\n",
      "Epoch [3/10], Batch [1446/1562], Loss: 0.2514\n",
      "Epoch [3/10], Batch [1448/1562], Loss: 0.2734\n",
      "Epoch [3/10], Batch [1450/1562], Loss: 0.2587\n",
      "Epoch [3/10], Batch [1452/1562], Loss: 0.2901\n",
      "Epoch [3/10], Batch [1454/1562], Loss: 0.3046\n",
      "Epoch [3/10], Batch [1456/1562], Loss: 0.2645\n",
      "Epoch [3/10], Batch [1458/1562], Loss: 0.2936\n",
      "Epoch [3/10], Batch [1460/1562], Loss: 0.3028\n",
      "Epoch [3/10], Batch [1462/1562], Loss: 0.2753\n",
      "Epoch [3/10], Batch [1464/1562], Loss: 0.2727\n",
      "Epoch [3/10], Batch [1466/1562], Loss: 0.2928\n",
      "Epoch [3/10], Batch [1468/1562], Loss: 0.2351\n",
      "Epoch [3/10], Batch [1470/1562], Loss: 0.2927\n",
      "Epoch [3/10], Batch [1472/1562], Loss: 0.2480\n",
      "Epoch [3/10], Batch [1474/1562], Loss: 0.2331\n",
      "Epoch [3/10], Batch [1476/1562], Loss: 0.2915\n",
      "Epoch [3/10], Batch [1478/1562], Loss: 0.2852\n",
      "Epoch [3/10], Batch [1480/1562], Loss: 0.3000\n",
      "Epoch [3/10], Batch [1482/1562], Loss: 0.2765\n",
      "Epoch [3/10], Batch [1484/1562], Loss: 0.2795\n",
      "Epoch [3/10], Batch [1486/1562], Loss: 0.2620\n",
      "Epoch [3/10], Batch [1488/1562], Loss: 0.2873\n",
      "Epoch [3/10], Batch [1490/1562], Loss: 0.2469\n",
      "Epoch [3/10], Batch [1492/1562], Loss: 0.2538\n",
      "Epoch [3/10], Batch [1494/1562], Loss: 0.2644\n",
      "Epoch [3/10], Batch [1496/1562], Loss: 0.2979\n",
      "Epoch [3/10], Batch [1498/1562], Loss: 0.2443\n",
      "Epoch [3/10], Batch [1500/1562], Loss: 0.2367\n",
      "Epoch [3/10], Batch [1502/1562], Loss: 0.2659\n",
      "Epoch [3/10], Batch [1504/1562], Loss: 0.3238\n",
      "Epoch [3/10], Batch [1506/1562], Loss: 0.2810\n",
      "Epoch [3/10], Batch [1508/1562], Loss: 0.2523\n",
      "Epoch [3/10], Batch [1510/1562], Loss: 0.2779\n",
      "Epoch [3/10], Batch [1512/1562], Loss: 0.2910\n",
      "Epoch [3/10], Batch [1514/1562], Loss: 0.3130\n",
      "Epoch [3/10], Batch [1516/1562], Loss: 0.2819\n",
      "Epoch [3/10], Batch [1518/1562], Loss: 0.2654\n",
      "Epoch [3/10], Batch [1520/1562], Loss: 0.3154\n",
      "Epoch [3/10], Batch [1522/1562], Loss: 0.2512\n",
      "Epoch [3/10], Batch [1524/1562], Loss: 0.3023\n",
      "Epoch [3/10], Batch [1526/1562], Loss: 0.2920\n",
      "Epoch [3/10], Batch [1528/1562], Loss: 0.2863\n",
      "Epoch [3/10], Batch [1530/1562], Loss: 0.2535\n",
      "Epoch [3/10], Batch [1532/1562], Loss: 0.3111\n",
      "Epoch [3/10], Batch [1534/1562], Loss: 0.2244\n",
      "Epoch [3/10], Batch [1536/1562], Loss: 0.2994\n",
      "Epoch [3/10], Batch [1538/1562], Loss: 0.2652\n",
      "Epoch [3/10], Batch [1540/1562], Loss: 0.2325\n",
      "Epoch [3/10], Batch [1542/1562], Loss: 0.3009\n",
      "Epoch [3/10], Batch [1544/1562], Loss: 0.2865\n",
      "Epoch [3/10], Batch [1546/1562], Loss: 0.3131\n",
      "Epoch [3/10], Batch [1548/1562], Loss: 0.2591\n",
      "Epoch [3/10], Batch [1550/1562], Loss: 0.3051\n",
      "Epoch [3/10], Batch [1552/1562], Loss: 0.2911\n",
      "Epoch [3/10], Batch [1554/1562], Loss: 0.2830\n",
      "Epoch [3/10], Batch [1556/1562], Loss: 0.2719\n",
      "Epoch [3/10], Batch [1558/1562], Loss: 0.2803\n",
      "Epoch [3/10], Batch [1560/1562], Loss: 0.2982\n",
      "Epoch [3/10], Batch [1562/1562], Loss: 0.3360\n",
      "Epoch [3/10] completed. Average Loss: 0.2862\n",
      "Epoch [4/10], Batch [2/1562], Loss: 0.2590\n",
      "Epoch [4/10], Batch [4/1562], Loss: 0.2816\n",
      "Epoch [4/10], Batch [6/1562], Loss: 0.2686\n",
      "Epoch [4/10], Batch [8/1562], Loss: 0.2970\n",
      "Epoch [4/10], Batch [10/1562], Loss: 0.2584\n",
      "Epoch [4/10], Batch [12/1562], Loss: 0.2830\n",
      "Epoch [4/10], Batch [14/1562], Loss: 0.2829\n",
      "Epoch [4/10], Batch [16/1562], Loss: 0.2929\n",
      "Epoch [4/10], Batch [18/1562], Loss: 0.3201\n",
      "Epoch [4/10], Batch [20/1562], Loss: 0.2719\n",
      "Epoch [4/10], Batch [22/1562], Loss: 0.2820\n",
      "Epoch [4/10], Batch [24/1562], Loss: 0.3028\n",
      "Epoch [4/10], Batch [26/1562], Loss: 0.3014\n",
      "Epoch [4/10], Batch [28/1562], Loss: 0.2483\n",
      "Epoch [4/10], Batch [30/1562], Loss: 0.2558\n",
      "Epoch [4/10], Batch [32/1562], Loss: 0.2444\n",
      "Epoch [4/10], Batch [34/1562], Loss: 0.2570\n",
      "Epoch [4/10], Batch [36/1562], Loss: 0.3101\n",
      "Epoch [4/10], Batch [38/1562], Loss: 0.3258\n",
      "Epoch [4/10], Batch [40/1562], Loss: 0.3251\n",
      "Epoch [4/10], Batch [42/1562], Loss: 0.2445\n",
      "Epoch [4/10], Batch [44/1562], Loss: 0.2634\n",
      "Epoch [4/10], Batch [46/1562], Loss: 0.2735\n",
      "Epoch [4/10], Batch [48/1562], Loss: 0.2786\n",
      "Epoch [4/10], Batch [50/1562], Loss: 0.3172\n",
      "Epoch [4/10], Batch [52/1562], Loss: 0.3121\n",
      "Epoch [4/10], Batch [54/1562], Loss: 0.3014\n",
      "Epoch [4/10], Batch [56/1562], Loss: 0.2915\n",
      "Epoch [4/10], Batch [58/1562], Loss: 0.3018\n",
      "Epoch [4/10], Batch [60/1562], Loss: 0.2472\n",
      "Epoch [4/10], Batch [62/1562], Loss: 0.2739\n",
      "Epoch [4/10], Batch [64/1562], Loss: 0.2982\n",
      "Epoch [4/10], Batch [66/1562], Loss: 0.2834\n",
      "Epoch [4/10], Batch [68/1562], Loss: 0.2806\n",
      "Epoch [4/10], Batch [70/1562], Loss: 0.2742\n",
      "Epoch [4/10], Batch [72/1562], Loss: 0.2935\n",
      "Epoch [4/10], Batch [74/1562], Loss: 0.2396\n",
      "Epoch [4/10], Batch [76/1562], Loss: 0.2964\n",
      "Epoch [4/10], Batch [78/1562], Loss: 0.2377\n",
      "Epoch [4/10], Batch [80/1562], Loss: 0.2896\n",
      "Epoch [4/10], Batch [82/1562], Loss: 0.2784\n",
      "Epoch [4/10], Batch [84/1562], Loss: 0.2700\n",
      "Epoch [4/10], Batch [86/1562], Loss: 0.2508\n",
      "Epoch [4/10], Batch [88/1562], Loss: 0.3052\n",
      "Epoch [4/10], Batch [90/1562], Loss: 0.2749\n",
      "Epoch [4/10], Batch [92/1562], Loss: 0.2672\n",
      "Epoch [4/10], Batch [94/1562], Loss: 0.2941\n",
      "Epoch [4/10], Batch [96/1562], Loss: 0.2973\n",
      "Epoch [4/10], Batch [98/1562], Loss: 0.2726\n",
      "Epoch [4/10], Batch [100/1562], Loss: 0.3001\n",
      "Epoch [4/10], Batch [102/1562], Loss: 0.2823\n",
      "Epoch [4/10], Batch [104/1562], Loss: 0.2881\n",
      "Epoch [4/10], Batch [106/1562], Loss: 0.2870\n",
      "Epoch [4/10], Batch [108/1562], Loss: 0.2611\n",
      "Epoch [4/10], Batch [110/1562], Loss: 0.2869\n",
      "Epoch [4/10], Batch [112/1562], Loss: 0.3041\n",
      "Epoch [4/10], Batch [114/1562], Loss: 0.2623\n",
      "Epoch [4/10], Batch [116/1562], Loss: 0.2828\n",
      "Epoch [4/10], Batch [118/1562], Loss: 0.3089\n",
      "Epoch [4/10], Batch [120/1562], Loss: 0.2563\n",
      "Epoch [4/10], Batch [122/1562], Loss: 0.2824\n",
      "Epoch [4/10], Batch [124/1562], Loss: 0.2849\n",
      "Epoch [4/10], Batch [126/1562], Loss: 0.3150\n",
      "Epoch [4/10], Batch [128/1562], Loss: 0.3052\n",
      "Epoch [4/10], Batch [130/1562], Loss: 0.2619\n",
      "Epoch [4/10], Batch [132/1562], Loss: 0.3106\n",
      "Epoch [4/10], Batch [134/1562], Loss: 0.3110\n",
      "Epoch [4/10], Batch [136/1562], Loss: 0.2874\n",
      "Epoch [4/10], Batch [138/1562], Loss: 0.2756\n",
      "Epoch [4/10], Batch [140/1562], Loss: 0.3211\n",
      "Epoch [4/10], Batch [142/1562], Loss: 0.2860\n",
      "Epoch [4/10], Batch [144/1562], Loss: 0.2851\n",
      "Epoch [4/10], Batch [146/1562], Loss: 0.2818\n",
      "Epoch [4/10], Batch [148/1562], Loss: 0.2818\n",
      "Epoch [4/10], Batch [150/1562], Loss: 0.2746\n",
      "Epoch [4/10], Batch [152/1562], Loss: 0.2782\n",
      "Epoch [4/10], Batch [154/1562], Loss: 0.2735\n",
      "Epoch [4/10], Batch [156/1562], Loss: 0.2573\n",
      "Epoch [4/10], Batch [158/1562], Loss: 0.3342\n",
      "Epoch [4/10], Batch [160/1562], Loss: 0.2906\n",
      "Epoch [4/10], Batch [162/1562], Loss: 0.2869\n",
      "Epoch [4/10], Batch [164/1562], Loss: 0.3283\n",
      "Epoch [4/10], Batch [166/1562], Loss: 0.3025\n",
      "Epoch [4/10], Batch [168/1562], Loss: 0.2928\n",
      "Epoch [4/10], Batch [170/1562], Loss: 0.3053\n",
      "Epoch [4/10], Batch [172/1562], Loss: 0.3267\n",
      "Epoch [4/10], Batch [174/1562], Loss: 0.2672\n",
      "Epoch [4/10], Batch [176/1562], Loss: 0.2891\n",
      "Epoch [4/10], Batch [178/1562], Loss: 0.2989\n",
      "Epoch [4/10], Batch [180/1562], Loss: 0.2771\n",
      "Epoch [4/10], Batch [182/1562], Loss: 0.2415\n",
      "Epoch [4/10], Batch [184/1562], Loss: 0.2858\n",
      "Epoch [4/10], Batch [186/1562], Loss: 0.2977\n",
      "Epoch [4/10], Batch [188/1562], Loss: 0.3181\n",
      "Epoch [4/10], Batch [190/1562], Loss: 0.3104\n",
      "Epoch [4/10], Batch [192/1562], Loss: 0.2777\n",
      "Epoch [4/10], Batch [194/1562], Loss: 0.2870\n",
      "Epoch [4/10], Batch [196/1562], Loss: 0.2421\n",
      "Epoch [4/10], Batch [198/1562], Loss: 0.2803\n",
      "Epoch [4/10], Batch [200/1562], Loss: 0.3251\n",
      "Epoch [4/10], Batch [202/1562], Loss: 0.3272\n",
      "Epoch [4/10], Batch [204/1562], Loss: 0.2513\n",
      "Epoch [4/10], Batch [206/1562], Loss: 0.3124\n",
      "Epoch [4/10], Batch [208/1562], Loss: 0.3034\n",
      "Epoch [4/10], Batch [210/1562], Loss: 0.2655\n",
      "Epoch [4/10], Batch [212/1562], Loss: 0.3017\n",
      "Epoch [4/10], Batch [214/1562], Loss: 0.2801\n",
      "Epoch [4/10], Batch [216/1562], Loss: 0.2768\n",
      "Epoch [4/10], Batch [218/1562], Loss: 0.3314\n",
      "Epoch [4/10], Batch [220/1562], Loss: 0.2650\n",
      "Epoch [4/10], Batch [222/1562], Loss: 0.2661\n",
      "Epoch [4/10], Batch [224/1562], Loss: 0.3133\n",
      "Epoch [4/10], Batch [226/1562], Loss: 0.2724\n",
      "Epoch [4/10], Batch [228/1562], Loss: 0.3025\n",
      "Epoch [4/10], Batch [230/1562], Loss: 0.2887\n",
      "Epoch [4/10], Batch [232/1562], Loss: 0.2959\n",
      "Epoch [4/10], Batch [234/1562], Loss: 0.3023\n",
      "Epoch [4/10], Batch [236/1562], Loss: 0.2877\n",
      "Epoch [4/10], Batch [238/1562], Loss: 0.2926\n",
      "Epoch [4/10], Batch [240/1562], Loss: 0.2600\n",
      "Epoch [4/10], Batch [242/1562], Loss: 0.3112\n",
      "Epoch [4/10], Batch [244/1562], Loss: 0.2381\n",
      "Epoch [4/10], Batch [246/1562], Loss: 0.2814\n",
      "Epoch [4/10], Batch [248/1562], Loss: 0.3132\n",
      "Epoch [4/10], Batch [250/1562], Loss: 0.3217\n",
      "Epoch [4/10], Batch [252/1562], Loss: 0.2468\n",
      "Epoch [4/10], Batch [254/1562], Loss: 0.3069\n",
      "Epoch [4/10], Batch [256/1562], Loss: 0.2955\n",
      "Epoch [4/10], Batch [258/1562], Loss: 0.3198\n",
      "Epoch [4/10], Batch [260/1562], Loss: 0.3063\n",
      "Epoch [4/10], Batch [262/1562], Loss: 0.2922\n",
      "Epoch [4/10], Batch [264/1562], Loss: 0.2612\n",
      "Epoch [4/10], Batch [266/1562], Loss: 0.2691\n",
      "Epoch [4/10], Batch [268/1562], Loss: 0.3042\n",
      "Epoch [4/10], Batch [270/1562], Loss: 0.2870\n",
      "Epoch [4/10], Batch [272/1562], Loss: 0.3403\n",
      "Epoch [4/10], Batch [274/1562], Loss: 0.2524\n",
      "Epoch [4/10], Batch [276/1562], Loss: 0.2812\n",
      "Epoch [4/10], Batch [278/1562], Loss: 0.3140\n",
      "Epoch [4/10], Batch [280/1562], Loss: 0.2880\n",
      "Epoch [4/10], Batch [282/1562], Loss: 0.2390\n",
      "Epoch [4/10], Batch [284/1562], Loss: 0.3158\n",
      "Epoch [4/10], Batch [286/1562], Loss: 0.3110\n",
      "Epoch [4/10], Batch [288/1562], Loss: 0.3266\n",
      "Epoch [4/10], Batch [290/1562], Loss: 0.2724\n",
      "Epoch [4/10], Batch [292/1562], Loss: 0.2977\n",
      "Epoch [4/10], Batch [294/1562], Loss: 0.3375\n",
      "Epoch [4/10], Batch [296/1562], Loss: 0.3060\n",
      "Epoch [4/10], Batch [298/1562], Loss: 0.3024\n",
      "Epoch [4/10], Batch [300/1562], Loss: 0.2627\n",
      "Epoch [4/10], Batch [302/1562], Loss: 0.3083\n",
      "Epoch [4/10], Batch [304/1562], Loss: 0.2792\n",
      "Epoch [4/10], Batch [306/1562], Loss: 0.2917\n",
      "Epoch [4/10], Batch [308/1562], Loss: 0.3156\n",
      "Epoch [4/10], Batch [310/1562], Loss: 0.2873\n",
      "Epoch [4/10], Batch [312/1562], Loss: 0.2721\n",
      "Epoch [4/10], Batch [314/1562], Loss: 0.2730\n",
      "Epoch [4/10], Batch [316/1562], Loss: 0.2954\n",
      "Epoch [4/10], Batch [318/1562], Loss: 0.2976\n",
      "Epoch [4/10], Batch [320/1562], Loss: 0.2881\n",
      "Epoch [4/10], Batch [322/1562], Loss: 0.3105\n",
      "Epoch [4/10], Batch [324/1562], Loss: 0.2906\n",
      "Epoch [4/10], Batch [326/1562], Loss: 0.2614\n",
      "Epoch [4/10], Batch [328/1562], Loss: 0.2612\n",
      "Epoch [4/10], Batch [330/1562], Loss: 0.3041\n",
      "Epoch [4/10], Batch [332/1562], Loss: 0.3079\n",
      "Epoch [4/10], Batch [334/1562], Loss: 0.2895\n",
      "Epoch [4/10], Batch [336/1562], Loss: 0.3009\n",
      "Epoch [4/10], Batch [338/1562], Loss: 0.2602\n",
      "Epoch [4/10], Batch [340/1562], Loss: 0.2741\n",
      "Epoch [4/10], Batch [342/1562], Loss: 0.2896\n",
      "Epoch [4/10], Batch [344/1562], Loss: 0.2451\n",
      "Epoch [4/10], Batch [346/1562], Loss: 0.2961\n",
      "Epoch [4/10], Batch [348/1562], Loss: 0.2841\n",
      "Epoch [4/10], Batch [350/1562], Loss: 0.2742\n",
      "Epoch [4/10], Batch [352/1562], Loss: 0.2572\n",
      "Epoch [4/10], Batch [354/1562], Loss: 0.2620\n",
      "Epoch [4/10], Batch [356/1562], Loss: 0.2750\n",
      "Epoch [4/10], Batch [358/1562], Loss: 0.2751\n",
      "Epoch [4/10], Batch [360/1562], Loss: 0.3073\n",
      "Epoch [4/10], Batch [362/1562], Loss: 0.2788\n",
      "Epoch [4/10], Batch [364/1562], Loss: 0.2912\n",
      "Epoch [4/10], Batch [366/1562], Loss: 0.2467\n",
      "Epoch [4/10], Batch [368/1562], Loss: 0.3161\n",
      "Epoch [4/10], Batch [370/1562], Loss: 0.2876\n",
      "Epoch [4/10], Batch [372/1562], Loss: 0.2783\n",
      "Epoch [4/10], Batch [374/1562], Loss: 0.2724\n",
      "Epoch [4/10], Batch [376/1562], Loss: 0.2700\n",
      "Epoch [4/10], Batch [378/1562], Loss: 0.2577\n",
      "Epoch [4/10], Batch [380/1562], Loss: 0.2428\n",
      "Epoch [4/10], Batch [382/1562], Loss: 0.2638\n",
      "Epoch [4/10], Batch [384/1562], Loss: 0.3392\n",
      "Epoch [4/10], Batch [386/1562], Loss: 0.2820\n",
      "Epoch [4/10], Batch [388/1562], Loss: 0.3145\n",
      "Epoch [4/10], Batch [390/1562], Loss: 0.2620\n",
      "Epoch [4/10], Batch [392/1562], Loss: 0.2623\n",
      "Epoch [4/10], Batch [394/1562], Loss: 0.2965\n",
      "Epoch [4/10], Batch [396/1562], Loss: 0.2510\n",
      "Epoch [4/10], Batch [398/1562], Loss: 0.3049\n",
      "Epoch [4/10], Batch [400/1562], Loss: 0.2299\n",
      "Epoch [4/10], Batch [402/1562], Loss: 0.2717\n",
      "Epoch [4/10], Batch [404/1562], Loss: 0.3019\n",
      "Epoch [4/10], Batch [406/1562], Loss: 0.2712\n",
      "Epoch [4/10], Batch [408/1562], Loss: 0.2864\n",
      "Epoch [4/10], Batch [410/1562], Loss: 0.2992\n",
      "Epoch [4/10], Batch [412/1562], Loss: 0.2888\n",
      "Epoch [4/10], Batch [414/1562], Loss: 0.2686\n",
      "Epoch [4/10], Batch [416/1562], Loss: 0.2846\n",
      "Epoch [4/10], Batch [418/1562], Loss: 0.2580\n",
      "Epoch [4/10], Batch [420/1562], Loss: 0.2944\n",
      "Epoch [4/10], Batch [422/1562], Loss: 0.2918\n",
      "Epoch [4/10], Batch [424/1562], Loss: 0.2646\n",
      "Epoch [4/10], Batch [426/1562], Loss: 0.2516\n",
      "Epoch [4/10], Batch [428/1562], Loss: 0.3053\n",
      "Epoch [4/10], Batch [430/1562], Loss: 0.2803\n",
      "Epoch [4/10], Batch [432/1562], Loss: 0.2891\n",
      "Epoch [4/10], Batch [434/1562], Loss: 0.2911\n",
      "Epoch [4/10], Batch [436/1562], Loss: 0.2883\n",
      "Epoch [4/10], Batch [438/1562], Loss: 0.3142\n",
      "Epoch [4/10], Batch [440/1562], Loss: 0.2683\n",
      "Epoch [4/10], Batch [442/1562], Loss: 0.3075\n",
      "Epoch [4/10], Batch [444/1562], Loss: 0.3131\n",
      "Epoch [4/10], Batch [446/1562], Loss: 0.2659\n",
      "Epoch [4/10], Batch [448/1562], Loss: 0.2930\n",
      "Epoch [4/10], Batch [450/1562], Loss: 0.2653\n",
      "Epoch [4/10], Batch [452/1562], Loss: 0.2938\n",
      "Epoch [4/10], Batch [454/1562], Loss: 0.2985\n",
      "Epoch [4/10], Batch [456/1562], Loss: 0.3539\n",
      "Epoch [4/10], Batch [458/1562], Loss: 0.2664\n",
      "Epoch [4/10], Batch [460/1562], Loss: 0.2885\n",
      "Epoch [4/10], Batch [462/1562], Loss: 0.2959\n",
      "Epoch [4/10], Batch [464/1562], Loss: 0.2920\n",
      "Epoch [4/10], Batch [466/1562], Loss: 0.2746\n",
      "Epoch [4/10], Batch [468/1562], Loss: 0.2364\n",
      "Epoch [4/10], Batch [470/1562], Loss: 0.2770\n",
      "Epoch [4/10], Batch [472/1562], Loss: 0.2961\n",
      "Epoch [4/10], Batch [474/1562], Loss: 0.2665\n",
      "Epoch [4/10], Batch [476/1562], Loss: 0.2734\n",
      "Epoch [4/10], Batch [478/1562], Loss: 0.2792\n",
      "Epoch [4/10], Batch [480/1562], Loss: 0.2668\n",
      "Epoch [4/10], Batch [482/1562], Loss: 0.3422\n",
      "Epoch [4/10], Batch [484/1562], Loss: 0.2769\n",
      "Epoch [4/10], Batch [486/1562], Loss: 0.2481\n",
      "Epoch [4/10], Batch [488/1562], Loss: 0.2888\n",
      "Epoch [4/10], Batch [490/1562], Loss: 0.2975\n",
      "Epoch [4/10], Batch [492/1562], Loss: 0.2977\n",
      "Epoch [4/10], Batch [494/1562], Loss: 0.3456\n",
      "Epoch [4/10], Batch [496/1562], Loss: 0.2833\n",
      "Epoch [4/10], Batch [498/1562], Loss: 0.2929\n",
      "Epoch [4/10], Batch [500/1562], Loss: 0.2808\n",
      "Epoch [4/10], Batch [502/1562], Loss: 0.3020\n",
      "Epoch [4/10], Batch [504/1562], Loss: 0.2666\n",
      "Epoch [4/10], Batch [506/1562], Loss: 0.2971\n",
      "Epoch [4/10], Batch [508/1562], Loss: 0.2789\n",
      "Epoch [4/10], Batch [510/1562], Loss: 0.2942\n",
      "Epoch [4/10], Batch [512/1562], Loss: 0.3055\n",
      "Epoch [4/10], Batch [514/1562], Loss: 0.3022\n",
      "Epoch [4/10], Batch [516/1562], Loss: 0.2745\n",
      "Epoch [4/10], Batch [518/1562], Loss: 0.2875\n",
      "Epoch [4/10], Batch [520/1562], Loss: 0.2973\n",
      "Epoch [4/10], Batch [522/1562], Loss: 0.2714\n",
      "Epoch [4/10], Batch [524/1562], Loss: 0.2847\n",
      "Epoch [4/10], Batch [526/1562], Loss: 0.2690\n",
      "Epoch [4/10], Batch [528/1562], Loss: 0.3140\n",
      "Epoch [4/10], Batch [530/1562], Loss: 0.3452\n",
      "Epoch [4/10], Batch [532/1562], Loss: 0.2995\n",
      "Epoch [4/10], Batch [534/1562], Loss: 0.2742\n",
      "Epoch [4/10], Batch [536/1562], Loss: 0.2859\n",
      "Epoch [4/10], Batch [538/1562], Loss: 0.2885\n",
      "Epoch [4/10], Batch [540/1562], Loss: 0.2823\n",
      "Epoch [4/10], Batch [542/1562], Loss: 0.2677\n",
      "Epoch [4/10], Batch [544/1562], Loss: 0.2765\n",
      "Epoch [4/10], Batch [546/1562], Loss: 0.3280\n",
      "Epoch [4/10], Batch [548/1562], Loss: 0.2946\n",
      "Epoch [4/10], Batch [550/1562], Loss: 0.3406\n",
      "Epoch [4/10], Batch [552/1562], Loss: 0.2818\n",
      "Epoch [4/10], Batch [554/1562], Loss: 0.3493\n",
      "Epoch [4/10], Batch [556/1562], Loss: 0.2885\n",
      "Epoch [4/10], Batch [558/1562], Loss: 0.2960\n",
      "Epoch [4/10], Batch [560/1562], Loss: 0.3354\n",
      "Epoch [4/10], Batch [562/1562], Loss: 0.3019\n",
      "Epoch [4/10], Batch [564/1562], Loss: 0.2825\n",
      "Epoch [4/10], Batch [566/1562], Loss: 0.3142\n",
      "Epoch [4/10], Batch [568/1562], Loss: 0.2368\n",
      "Epoch [4/10], Batch [570/1562], Loss: 0.2877\n",
      "Epoch [4/10], Batch [572/1562], Loss: 0.2854\n",
      "Epoch [4/10], Batch [574/1562], Loss: 0.3070\n",
      "Epoch [4/10], Batch [576/1562], Loss: 0.2818\n",
      "Epoch [4/10], Batch [578/1562], Loss: 0.3328\n",
      "Epoch [4/10], Batch [580/1562], Loss: 0.2806\n",
      "Epoch [4/10], Batch [582/1562], Loss: 0.2882\n",
      "Epoch [4/10], Batch [584/1562], Loss: 0.2902\n",
      "Epoch [4/10], Batch [586/1562], Loss: 0.2802\n",
      "Epoch [4/10], Batch [588/1562], Loss: 0.3153\n",
      "Epoch [4/10], Batch [590/1562], Loss: 0.2827\n",
      "Epoch [4/10], Batch [592/1562], Loss: 0.2798\n",
      "Epoch [4/10], Batch [594/1562], Loss: 0.2863\n",
      "Epoch [4/10], Batch [596/1562], Loss: 0.2963\n",
      "Epoch [4/10], Batch [598/1562], Loss: 0.2830\n",
      "Epoch [4/10], Batch [600/1562], Loss: 0.2508\n",
      "Epoch [4/10], Batch [602/1562], Loss: 0.2541\n",
      "Epoch [4/10], Batch [604/1562], Loss: 0.2671\n",
      "Epoch [4/10], Batch [606/1562], Loss: 0.3238\n",
      "Epoch [4/10], Batch [608/1562], Loss: 0.2996\n",
      "Epoch [4/10], Batch [610/1562], Loss: 0.2414\n",
      "Epoch [4/10], Batch [612/1562], Loss: 0.3060\n",
      "Epoch [4/10], Batch [614/1562], Loss: 0.2954\n",
      "Epoch [4/10], Batch [616/1562], Loss: 0.3104\n",
      "Epoch [4/10], Batch [618/1562], Loss: 0.3276\n",
      "Epoch [4/10], Batch [620/1562], Loss: 0.3246\n",
      "Epoch [4/10], Batch [622/1562], Loss: 0.2793\n",
      "Epoch [4/10], Batch [624/1562], Loss: 0.2669\n",
      "Epoch [4/10], Batch [626/1562], Loss: 0.2780\n",
      "Epoch [4/10], Batch [628/1562], Loss: 0.2817\n",
      "Epoch [4/10], Batch [630/1562], Loss: 0.2887\n",
      "Epoch [4/10], Batch [632/1562], Loss: 0.2517\n",
      "Epoch [4/10], Batch [634/1562], Loss: 0.2921\n",
      "Epoch [4/10], Batch [636/1562], Loss: 0.2641\n",
      "Epoch [4/10], Batch [638/1562], Loss: 0.3032\n",
      "Epoch [4/10], Batch [640/1562], Loss: 0.2789\n",
      "Epoch [4/10], Batch [642/1562], Loss: 0.2429\n",
      "Epoch [4/10], Batch [644/1562], Loss: 0.2891\n",
      "Epoch [4/10], Batch [646/1562], Loss: 0.2778\n",
      "Epoch [4/10], Batch [648/1562], Loss: 0.2286\n",
      "Epoch [4/10], Batch [650/1562], Loss: 0.2574\n",
      "Epoch [4/10], Batch [652/1562], Loss: 0.3134\n",
      "Epoch [4/10], Batch [654/1562], Loss: 0.3301\n",
      "Epoch [4/10], Batch [656/1562], Loss: 0.2438\n",
      "Epoch [4/10], Batch [658/1562], Loss: 0.2960\n",
      "Epoch [4/10], Batch [660/1562], Loss: 0.3119\n",
      "Epoch [4/10], Batch [662/1562], Loss: 0.2629\n",
      "Epoch [4/10], Batch [664/1562], Loss: 0.2941\n",
      "Epoch [4/10], Batch [666/1562], Loss: 0.3098\n",
      "Epoch [4/10], Batch [668/1562], Loss: 0.3128\n",
      "Epoch [4/10], Batch [670/1562], Loss: 0.2814\n",
      "Epoch [4/10], Batch [672/1562], Loss: 0.2961\n",
      "Epoch [4/10], Batch [674/1562], Loss: 0.3343\n",
      "Epoch [4/10], Batch [676/1562], Loss: 0.3002\n",
      "Epoch [4/10], Batch [678/1562], Loss: 0.2549\n",
      "Epoch [4/10], Batch [680/1562], Loss: 0.2881\n",
      "Epoch [4/10], Batch [682/1562], Loss: 0.2724\n",
      "Epoch [4/10], Batch [684/1562], Loss: 0.2955\n",
      "Epoch [4/10], Batch [686/1562], Loss: 0.3056\n",
      "Epoch [4/10], Batch [688/1562], Loss: 0.2861\n",
      "Epoch [4/10], Batch [690/1562], Loss: 0.2736\n",
      "Epoch [4/10], Batch [692/1562], Loss: 0.2669\n",
      "Epoch [4/10], Batch [694/1562], Loss: 0.2776\n",
      "Epoch [4/10], Batch [696/1562], Loss: 0.2894\n",
      "Epoch [4/10], Batch [698/1562], Loss: 0.2831\n",
      "Epoch [4/10], Batch [700/1562], Loss: 0.2977\n",
      "Epoch [4/10], Batch [702/1562], Loss: 0.3189\n",
      "Epoch [4/10], Batch [704/1562], Loss: 0.3147\n",
      "Epoch [4/10], Batch [706/1562], Loss: 0.2961\n",
      "Epoch [4/10], Batch [708/1562], Loss: 0.2918\n",
      "Epoch [4/10], Batch [710/1562], Loss: 0.3224\n",
      "Epoch [4/10], Batch [712/1562], Loss: 0.3210\n",
      "Epoch [4/10], Batch [714/1562], Loss: 0.3047\n",
      "Epoch [4/10], Batch [716/1562], Loss: 0.2933\n",
      "Epoch [4/10], Batch [718/1562], Loss: 0.2652\n",
      "Epoch [4/10], Batch [720/1562], Loss: 0.2785\n",
      "Epoch [4/10], Batch [722/1562], Loss: 0.2880\n",
      "Epoch [4/10], Batch [724/1562], Loss: 0.2479\n",
      "Epoch [4/10], Batch [726/1562], Loss: 0.2986\n",
      "Epoch [4/10], Batch [728/1562], Loss: 0.2846\n",
      "Epoch [4/10], Batch [730/1562], Loss: 0.2835\n",
      "Epoch [4/10], Batch [732/1562], Loss: 0.3328\n",
      "Epoch [4/10], Batch [734/1562], Loss: 0.2758\n",
      "Epoch [4/10], Batch [736/1562], Loss: 0.3206\n",
      "Epoch [4/10], Batch [738/1562], Loss: 0.2668\n",
      "Epoch [4/10], Batch [740/1562], Loss: 0.2431\n",
      "Epoch [4/10], Batch [742/1562], Loss: 0.2742\n",
      "Epoch [4/10], Batch [744/1562], Loss: 0.3036\n",
      "Epoch [4/10], Batch [746/1562], Loss: 0.2784\n",
      "Epoch [4/10], Batch [748/1562], Loss: 0.2943\n",
      "Epoch [4/10], Batch [750/1562], Loss: 0.2609\n",
      "Epoch [4/10], Batch [752/1562], Loss: 0.2848\n",
      "Epoch [4/10], Batch [754/1562], Loss: 0.2502\n",
      "Epoch [4/10], Batch [756/1562], Loss: 0.2838\n",
      "Epoch [4/10], Batch [758/1562], Loss: 0.3211\n",
      "Epoch [4/10], Batch [760/1562], Loss: 0.3343\n",
      "Epoch [4/10], Batch [762/1562], Loss: 0.3477\n",
      "Epoch [4/10], Batch [764/1562], Loss: 0.2786\n",
      "Epoch [4/10], Batch [766/1562], Loss: 0.3154\n",
      "Epoch [4/10], Batch [768/1562], Loss: 0.2595\n",
      "Epoch [4/10], Batch [770/1562], Loss: 0.2587\n",
      "Epoch [4/10], Batch [772/1562], Loss: 0.2713\n",
      "Epoch [4/10], Batch [774/1562], Loss: 0.2862\n",
      "Epoch [4/10], Batch [776/1562], Loss: 0.2475\n",
      "Epoch [4/10], Batch [778/1562], Loss: 0.3265\n",
      "Epoch [4/10], Batch [780/1562], Loss: 0.2920\n",
      "Epoch [4/10], Batch [782/1562], Loss: 0.2581\n",
      "Epoch [4/10], Batch [784/1562], Loss: 0.2895\n",
      "Epoch [4/10], Batch [786/1562], Loss: 0.2891\n",
      "Epoch [4/10], Batch [788/1562], Loss: 0.2683\n",
      "Epoch [4/10], Batch [790/1562], Loss: 0.2970\n",
      "Epoch [4/10], Batch [792/1562], Loss: 0.2819\n",
      "Epoch [4/10], Batch [794/1562], Loss: 0.2923\n",
      "Epoch [4/10], Batch [796/1562], Loss: 0.3093\n",
      "Epoch [4/10], Batch [798/1562], Loss: 0.3108\n",
      "Epoch [4/10], Batch [800/1562], Loss: 0.2815\n",
      "Epoch [4/10], Batch [802/1562], Loss: 0.3205\n",
      "Epoch [4/10], Batch [804/1562], Loss: 0.3236\n",
      "Epoch [4/10], Batch [806/1562], Loss: 0.2566\n",
      "Epoch [4/10], Batch [808/1562], Loss: 0.2912\n",
      "Epoch [4/10], Batch [810/1562], Loss: 0.2671\n",
      "Epoch [4/10], Batch [812/1562], Loss: 0.2932\n",
      "Epoch [4/10], Batch [814/1562], Loss: 0.2422\n",
      "Epoch [4/10], Batch [816/1562], Loss: 0.2621\n",
      "Epoch [4/10], Batch [818/1562], Loss: 0.2557\n",
      "Epoch [4/10], Batch [820/1562], Loss: 0.3117\n",
      "Epoch [4/10], Batch [822/1562], Loss: 0.2678\n",
      "Epoch [4/10], Batch [824/1562], Loss: 0.2654\n",
      "Epoch [4/10], Batch [826/1562], Loss: 0.2696\n",
      "Epoch [4/10], Batch [828/1562], Loss: 0.2673\n",
      "Epoch [4/10], Batch [830/1562], Loss: 0.3055\n",
      "Epoch [4/10], Batch [832/1562], Loss: 0.2893\n",
      "Epoch [4/10], Batch [834/1562], Loss: 0.2708\n",
      "Epoch [4/10], Batch [836/1562], Loss: 0.2812\n",
      "Epoch [4/10], Batch [838/1562], Loss: 0.3140\n",
      "Epoch [4/10], Batch [840/1562], Loss: 0.2488\n",
      "Epoch [4/10], Batch [842/1562], Loss: 0.2923\n",
      "Epoch [4/10], Batch [844/1562], Loss: 0.2492\n",
      "Epoch [4/10], Batch [846/1562], Loss: 0.3157\n",
      "Epoch [4/10], Batch [848/1562], Loss: 0.2789\n",
      "Epoch [4/10], Batch [850/1562], Loss: 0.3060\n",
      "Epoch [4/10], Batch [852/1562], Loss: 0.3106\n",
      "Epoch [4/10], Batch [854/1562], Loss: 0.3252\n",
      "Epoch [4/10], Batch [856/1562], Loss: 0.3160\n",
      "Epoch [4/10], Batch [858/1562], Loss: 0.2886\n",
      "Epoch [4/10], Batch [860/1562], Loss: 0.2778\n",
      "Epoch [4/10], Batch [862/1562], Loss: 0.2750\n",
      "Epoch [4/10], Batch [864/1562], Loss: 0.2745\n",
      "Epoch [4/10], Batch [866/1562], Loss: 0.2737\n",
      "Epoch [4/10], Batch [868/1562], Loss: 0.2803\n",
      "Epoch [4/10], Batch [870/1562], Loss: 0.2898\n",
      "Epoch [4/10], Batch [872/1562], Loss: 0.2961\n",
      "Epoch [4/10], Batch [874/1562], Loss: 0.2575\n",
      "Epoch [4/10], Batch [876/1562], Loss: 0.2501\n",
      "Epoch [4/10], Batch [878/1562], Loss: 0.2747\n",
      "Epoch [4/10], Batch [880/1562], Loss: 0.3103\n",
      "Epoch [4/10], Batch [882/1562], Loss: 0.3097\n",
      "Epoch [4/10], Batch [884/1562], Loss: 0.3284\n",
      "Epoch [4/10], Batch [886/1562], Loss: 0.2946\n",
      "Epoch [4/10], Batch [888/1562], Loss: 0.2867\n",
      "Epoch [4/10], Batch [890/1562], Loss: 0.3023\n",
      "Epoch [4/10], Batch [892/1562], Loss: 0.3064\n",
      "Epoch [4/10], Batch [894/1562], Loss: 0.3040\n",
      "Epoch [4/10], Batch [896/1562], Loss: 0.2634\n",
      "Epoch [4/10], Batch [898/1562], Loss: 0.2992\n",
      "Epoch [4/10], Batch [900/1562], Loss: 0.2742\n",
      "Epoch [4/10], Batch [902/1562], Loss: 0.2471\n",
      "Epoch [4/10], Batch [904/1562], Loss: 0.3016\n",
      "Epoch [4/10], Batch [906/1562], Loss: 0.3647\n",
      "Epoch [4/10], Batch [908/1562], Loss: 0.2976\n",
      "Epoch [4/10], Batch [910/1562], Loss: 0.2910\n",
      "Epoch [4/10], Batch [912/1562], Loss: 0.2928\n",
      "Epoch [4/10], Batch [914/1562], Loss: 0.2828\n",
      "Epoch [4/10], Batch [916/1562], Loss: 0.2918\n",
      "Epoch [4/10], Batch [918/1562], Loss: 0.2466\n",
      "Epoch [4/10], Batch [920/1562], Loss: 0.2789\n",
      "Epoch [4/10], Batch [922/1562], Loss: 0.2759\n",
      "Epoch [4/10], Batch [924/1562], Loss: 0.2924\n",
      "Epoch [4/10], Batch [926/1562], Loss: 0.2829\n",
      "Epoch [4/10], Batch [928/1562], Loss: 0.2779\n",
      "Epoch [4/10], Batch [930/1562], Loss: 0.3159\n",
      "Epoch [4/10], Batch [932/1562], Loss: 0.2748\n",
      "Epoch [4/10], Batch [934/1562], Loss: 0.3133\n",
      "Epoch [4/10], Batch [936/1562], Loss: 0.2909\n",
      "Epoch [4/10], Batch [938/1562], Loss: 0.2754\n",
      "Epoch [4/10], Batch [940/1562], Loss: 0.2856\n",
      "Epoch [4/10], Batch [942/1562], Loss: 0.2728\n",
      "Epoch [4/10], Batch [944/1562], Loss: 0.3251\n",
      "Epoch [4/10], Batch [946/1562], Loss: 0.2891\n",
      "Epoch [4/10], Batch [948/1562], Loss: 0.2550\n",
      "Epoch [4/10], Batch [950/1562], Loss: 0.2874\n",
      "Epoch [4/10], Batch [952/1562], Loss: 0.2871\n",
      "Epoch [4/10], Batch [954/1562], Loss: 0.3004\n",
      "Epoch [4/10], Batch [956/1562], Loss: 0.3224\n",
      "Epoch [4/10], Batch [958/1562], Loss: 0.3198\n",
      "Epoch [4/10], Batch [960/1562], Loss: 0.2667\n",
      "Epoch [4/10], Batch [962/1562], Loss: 0.2553\n",
      "Epoch [4/10], Batch [964/1562], Loss: 0.3136\n",
      "Epoch [4/10], Batch [966/1562], Loss: 0.2612\n",
      "Epoch [4/10], Batch [968/1562], Loss: 0.3101\n",
      "Epoch [4/10], Batch [970/1562], Loss: 0.2424\n",
      "Epoch [4/10], Batch [972/1562], Loss: 0.2816\n",
      "Epoch [4/10], Batch [974/1562], Loss: 0.2309\n",
      "Epoch [4/10], Batch [976/1562], Loss: 0.2972\n",
      "Epoch [4/10], Batch [978/1562], Loss: 0.2930\n",
      "Epoch [4/10], Batch [980/1562], Loss: 0.2833\n",
      "Epoch [4/10], Batch [982/1562], Loss: 0.2598\n",
      "Epoch [4/10], Batch [984/1562], Loss: 0.2781\n",
      "Epoch [4/10], Batch [986/1562], Loss: 0.2632\n",
      "Epoch [4/10], Batch [988/1562], Loss: 0.2649\n",
      "Epoch [4/10], Batch [990/1562], Loss: 0.3169\n",
      "Epoch [4/10], Batch [992/1562], Loss: 0.3066\n",
      "Epoch [4/10], Batch [994/1562], Loss: 0.2618\n",
      "Epoch [4/10], Batch [996/1562], Loss: 0.3377\n",
      "Epoch [4/10], Batch [998/1562], Loss: 0.2796\n",
      "Epoch [4/10], Batch [1000/1562], Loss: 0.2957\n",
      "Epoch [4/10], Batch [1002/1562], Loss: 0.2699\n",
      "Epoch [4/10], Batch [1004/1562], Loss: 0.2839\n",
      "Epoch [4/10], Batch [1006/1562], Loss: 0.2569\n",
      "Epoch [4/10], Batch [1008/1562], Loss: 0.2679\n",
      "Epoch [4/10], Batch [1010/1562], Loss: 0.3248\n",
      "Epoch [4/10], Batch [1012/1562], Loss: 0.2921\n",
      "Epoch [4/10], Batch [1014/1562], Loss: 0.2771\n",
      "Epoch [4/10], Batch [1016/1562], Loss: 0.3663\n",
      "Epoch [4/10], Batch [1018/1562], Loss: 0.2942\n",
      "Epoch [4/10], Batch [1020/1562], Loss: 0.2968\n",
      "Epoch [4/10], Batch [1022/1562], Loss: 0.2511\n",
      "Epoch [4/10], Batch [1024/1562], Loss: 0.3094\n",
      "Epoch [4/10], Batch [1026/1562], Loss: 0.3436\n",
      "Epoch [4/10], Batch [1028/1562], Loss: 0.2715\n",
      "Epoch [4/10], Batch [1030/1562], Loss: 0.2677\n",
      "Epoch [4/10], Batch [1032/1562], Loss: 0.3245\n",
      "Epoch [4/10], Batch [1034/1562], Loss: 0.3015\n",
      "Epoch [4/10], Batch [1036/1562], Loss: 0.2715\n",
      "Epoch [4/10], Batch [1038/1562], Loss: 0.3099\n",
      "Epoch [4/10], Batch [1040/1562], Loss: 0.2920\n",
      "Epoch [4/10], Batch [1042/1562], Loss: 0.2947\n",
      "Epoch [4/10], Batch [1044/1562], Loss: 0.2993\n",
      "Epoch [4/10], Batch [1046/1562], Loss: 0.2625\n",
      "Epoch [4/10], Batch [1048/1562], Loss: 0.3007\n",
      "Epoch [4/10], Batch [1050/1562], Loss: 0.2746\n",
      "Epoch [4/10], Batch [1052/1562], Loss: 0.3056\n",
      "Epoch [4/10], Batch [1054/1562], Loss: 0.2849\n",
      "Epoch [4/10], Batch [1056/1562], Loss: 0.3246\n",
      "Epoch [4/10], Batch [1058/1562], Loss: 0.2929\n",
      "Epoch [4/10], Batch [1060/1562], Loss: 0.3091\n",
      "Epoch [4/10], Batch [1062/1562], Loss: 0.2576\n",
      "Epoch [4/10], Batch [1064/1562], Loss: 0.2989\n",
      "Epoch [4/10], Batch [1066/1562], Loss: 0.2651\n",
      "Epoch [4/10], Batch [1068/1562], Loss: 0.2605\n",
      "Epoch [4/10], Batch [1070/1562], Loss: 0.2672\n",
      "Epoch [4/10], Batch [1072/1562], Loss: 0.2869\n",
      "Epoch [4/10], Batch [1074/1562], Loss: 0.2546\n",
      "Epoch [4/10], Batch [1076/1562], Loss: 0.2565\n",
      "Epoch [4/10], Batch [1078/1562], Loss: 0.3091\n",
      "Epoch [4/10], Batch [1080/1562], Loss: 0.2864\n",
      "Epoch [4/10], Batch [1082/1562], Loss: 0.2964\n",
      "Epoch [4/10], Batch [1084/1562], Loss: 0.2619\n",
      "Epoch [4/10], Batch [1086/1562], Loss: 0.2488\n",
      "Epoch [4/10], Batch [1088/1562], Loss: 0.2373\n",
      "Epoch [4/10], Batch [1090/1562], Loss: 0.2559\n",
      "Epoch [4/10], Batch [1092/1562], Loss: 0.2889\n",
      "Epoch [4/10], Batch [1094/1562], Loss: 0.2558\n",
      "Epoch [4/10], Batch [1096/1562], Loss: 0.3262\n",
      "Epoch [4/10], Batch [1098/1562], Loss: 0.2742\n",
      "Epoch [4/10], Batch [1100/1562], Loss: 0.3041\n",
      "Epoch [4/10], Batch [1102/1562], Loss: 0.3072\n",
      "Epoch [4/10], Batch [1104/1562], Loss: 0.2612\n",
      "Epoch [4/10], Batch [1106/1562], Loss: 0.2744\n",
      "Epoch [4/10], Batch [1108/1562], Loss: 0.2678\n",
      "Epoch [4/10], Batch [1110/1562], Loss: 0.2879\n",
      "Epoch [4/10], Batch [1112/1562], Loss: 0.3106\n",
      "Epoch [4/10], Batch [1114/1562], Loss: 0.2742\n",
      "Epoch [4/10], Batch [1116/1562], Loss: 0.2688\n",
      "Epoch [4/10], Batch [1118/1562], Loss: 0.2921\n",
      "Epoch [4/10], Batch [1120/1562], Loss: 0.3070\n",
      "Epoch [4/10], Batch [1122/1562], Loss: 0.2755\n",
      "Epoch [4/10], Batch [1124/1562], Loss: 0.2823\n",
      "Epoch [4/10], Batch [1126/1562], Loss: 0.3309\n",
      "Epoch [4/10], Batch [1128/1562], Loss: 0.2733\n",
      "Epoch [4/10], Batch [1130/1562], Loss: 0.2616\n",
      "Epoch [4/10], Batch [1132/1562], Loss: 0.2698\n",
      "Epoch [4/10], Batch [1134/1562], Loss: 0.3353\n",
      "Epoch [4/10], Batch [1136/1562], Loss: 0.2866\n",
      "Epoch [4/10], Batch [1138/1562], Loss: 0.2555\n",
      "Epoch [4/10], Batch [1140/1562], Loss: 0.2906\n",
      "Epoch [4/10], Batch [1142/1562], Loss: 0.2792\n",
      "Epoch [4/10], Batch [1144/1562], Loss: 0.2721\n",
      "Epoch [4/10], Batch [1146/1562], Loss: 0.2807\n",
      "Epoch [4/10], Batch [1148/1562], Loss: 0.2908\n",
      "Epoch [4/10], Batch [1150/1562], Loss: 0.3259\n",
      "Epoch [4/10], Batch [1152/1562], Loss: 0.2875\n",
      "Epoch [4/10], Batch [1154/1562], Loss: 0.2615\n",
      "Epoch [4/10], Batch [1156/1562], Loss: 0.2615\n",
      "Epoch [4/10], Batch [1158/1562], Loss: 0.2996\n",
      "Epoch [4/10], Batch [1160/1562], Loss: 0.3219\n",
      "Epoch [4/10], Batch [1162/1562], Loss: 0.2829\n",
      "Epoch [4/10], Batch [1164/1562], Loss: 0.2424\n",
      "Epoch [4/10], Batch [1166/1562], Loss: 0.2991\n",
      "Epoch [4/10], Batch [1168/1562], Loss: 0.2766\n",
      "Epoch [4/10], Batch [1170/1562], Loss: 0.2534\n",
      "Epoch [4/10], Batch [1172/1562], Loss: 0.2627\n",
      "Epoch [4/10], Batch [1174/1562], Loss: 0.2536\n",
      "Epoch [4/10], Batch [1176/1562], Loss: 0.2935\n",
      "Epoch [4/10], Batch [1178/1562], Loss: 0.2807\n",
      "Epoch [4/10], Batch [1180/1562], Loss: 0.2949\n",
      "Epoch [4/10], Batch [1182/1562], Loss: 0.3091\n",
      "Epoch [4/10], Batch [1184/1562], Loss: 0.2753\n",
      "Epoch [4/10], Batch [1186/1562], Loss: 0.2780\n",
      "Epoch [4/10], Batch [1188/1562], Loss: 0.2565\n",
      "Epoch [4/10], Batch [1190/1562], Loss: 0.2973\n",
      "Epoch [4/10], Batch [1192/1562], Loss: 0.2757\n",
      "Epoch [4/10], Batch [1194/1562], Loss: 0.2826\n",
      "Epoch [4/10], Batch [1196/1562], Loss: 0.3004\n",
      "Epoch [4/10], Batch [1198/1562], Loss: 0.2667\n",
      "Epoch [4/10], Batch [1200/1562], Loss: 0.3209\n",
      "Epoch [4/10], Batch [1202/1562], Loss: 0.2766\n",
      "Epoch [4/10], Batch [1204/1562], Loss: 0.3015\n",
      "Epoch [4/10], Batch [1206/1562], Loss: 0.2664\n",
      "Epoch [4/10], Batch [1208/1562], Loss: 0.2993\n",
      "Epoch [4/10], Batch [1210/1562], Loss: 0.3030\n",
      "Epoch [4/10], Batch [1212/1562], Loss: 0.2712\n",
      "Epoch [4/10], Batch [1214/1562], Loss: 0.2832\n",
      "Epoch [4/10], Batch [1216/1562], Loss: 0.2939\n",
      "Epoch [4/10], Batch [1218/1562], Loss: 0.2705\n",
      "Epoch [4/10], Batch [1220/1562], Loss: 0.2928\n",
      "Epoch [4/10], Batch [1222/1562], Loss: 0.2903\n",
      "Epoch [4/10], Batch [1224/1562], Loss: 0.2936\n",
      "Epoch [4/10], Batch [1226/1562], Loss: 0.2690\n",
      "Epoch [4/10], Batch [1228/1562], Loss: 0.2827\n",
      "Epoch [4/10], Batch [1230/1562], Loss: 0.2721\n",
      "Epoch [4/10], Batch [1232/1562], Loss: 0.2982\n",
      "Epoch [4/10], Batch [1234/1562], Loss: 0.3014\n",
      "Epoch [4/10], Batch [1236/1562], Loss: 0.3244\n",
      "Epoch [4/10], Batch [1238/1562], Loss: 0.2844\n",
      "Epoch [4/10], Batch [1240/1562], Loss: 0.2799\n",
      "Epoch [4/10], Batch [1242/1562], Loss: 0.2823\n",
      "Epoch [4/10], Batch [1244/1562], Loss: 0.2870\n",
      "Epoch [4/10], Batch [1246/1562], Loss: 0.3073\n",
      "Epoch [4/10], Batch [1248/1562], Loss: 0.2700\n",
      "Epoch [4/10], Batch [1250/1562], Loss: 0.3150\n",
      "Epoch [4/10], Batch [1252/1562], Loss: 0.3043\n",
      "Epoch [4/10], Batch [1254/1562], Loss: 0.2918\n",
      "Epoch [4/10], Batch [1256/1562], Loss: 0.2660\n",
      "Epoch [4/10], Batch [1258/1562], Loss: 0.2656\n",
      "Epoch [4/10], Batch [1260/1562], Loss: 0.2899\n",
      "Epoch [4/10], Batch [1262/1562], Loss: 0.2708\n",
      "Epoch [4/10], Batch [1264/1562], Loss: 0.2350\n",
      "Epoch [4/10], Batch [1266/1562], Loss: 0.2558\n",
      "Epoch [4/10], Batch [1268/1562], Loss: 0.2755\n",
      "Epoch [4/10], Batch [1270/1562], Loss: 0.2463\n",
      "Epoch [4/10], Batch [1272/1562], Loss: 0.2654\n",
      "Epoch [4/10], Batch [1274/1562], Loss: 0.2749\n",
      "Epoch [4/10], Batch [1276/1562], Loss: 0.2883\n",
      "Epoch [4/10], Batch [1278/1562], Loss: 0.2838\n",
      "Epoch [4/10], Batch [1280/1562], Loss: 0.2585\n",
      "Epoch [4/10], Batch [1282/1562], Loss: 0.2874\n",
      "Epoch [4/10], Batch [1284/1562], Loss: 0.3145\n",
      "Epoch [4/10], Batch [1286/1562], Loss: 0.2984\n",
      "Epoch [4/10], Batch [1288/1562], Loss: 0.2552\n",
      "Epoch [4/10], Batch [1290/1562], Loss: 0.2934\n",
      "Epoch [4/10], Batch [1292/1562], Loss: 0.2621\n",
      "Epoch [4/10], Batch [1294/1562], Loss: 0.2367\n",
      "Epoch [4/10], Batch [1296/1562], Loss: 0.3065\n",
      "Epoch [4/10], Batch [1298/1562], Loss: 0.2885\n",
      "Epoch [4/10], Batch [1300/1562], Loss: 0.2671\n",
      "Epoch [4/10], Batch [1302/1562], Loss: 0.3185\n",
      "Epoch [4/10], Batch [1304/1562], Loss: 0.2725\n",
      "Epoch [4/10], Batch [1306/1562], Loss: 0.2645\n",
      "Epoch [4/10], Batch [1308/1562], Loss: 0.2987\n",
      "Epoch [4/10], Batch [1310/1562], Loss: 0.3106\n",
      "Epoch [4/10], Batch [1312/1562], Loss: 0.2720\n",
      "Epoch [4/10], Batch [1314/1562], Loss: 0.3018\n",
      "Epoch [4/10], Batch [1316/1562], Loss: 0.2705\n",
      "Epoch [4/10], Batch [1318/1562], Loss: 0.2866\n",
      "Epoch [4/10], Batch [1320/1562], Loss: 0.2794\n",
      "Epoch [4/10], Batch [1322/1562], Loss: 0.2673\n",
      "Epoch [4/10], Batch [1324/1562], Loss: 0.2745\n",
      "Epoch [4/10], Batch [1326/1562], Loss: 0.2659\n",
      "Epoch [4/10], Batch [1328/1562], Loss: 0.3096\n",
      "Epoch [4/10], Batch [1330/1562], Loss: 0.2792\n",
      "Epoch [4/10], Batch [1332/1562], Loss: 0.3132\n",
      "Epoch [4/10], Batch [1334/1562], Loss: 0.3098\n",
      "Epoch [4/10], Batch [1336/1562], Loss: 0.2601\n",
      "Epoch [4/10], Batch [1338/1562], Loss: 0.2977\n",
      "Epoch [4/10], Batch [1340/1562], Loss: 0.2594\n",
      "Epoch [4/10], Batch [1342/1562], Loss: 0.2967\n",
      "Epoch [4/10], Batch [1344/1562], Loss: 0.2873\n",
      "Epoch [4/10], Batch [1346/1562], Loss: 0.2708\n",
      "Epoch [4/10], Batch [1348/1562], Loss: 0.3078\n",
      "Epoch [4/10], Batch [1350/1562], Loss: 0.3101\n",
      "Epoch [4/10], Batch [1352/1562], Loss: 0.2612\n",
      "Epoch [4/10], Batch [1354/1562], Loss: 0.2426\n",
      "Epoch [4/10], Batch [1356/1562], Loss: 0.3253\n",
      "Epoch [4/10], Batch [1358/1562], Loss: 0.2627\n",
      "Epoch [4/10], Batch [1360/1562], Loss: 0.3337\n",
      "Epoch [4/10], Batch [1362/1562], Loss: 0.3067\n",
      "Epoch [4/10], Batch [1364/1562], Loss: 0.3010\n",
      "Epoch [4/10], Batch [1366/1562], Loss: 0.2882\n",
      "Epoch [4/10], Batch [1368/1562], Loss: 0.3077\n",
      "Epoch [4/10], Batch [1370/1562], Loss: 0.2813\n",
      "Epoch [4/10], Batch [1372/1562], Loss: 0.3161\n",
      "Epoch [4/10], Batch [1374/1562], Loss: 0.3126\n",
      "Epoch [4/10], Batch [1376/1562], Loss: 0.2676\n",
      "Epoch [4/10], Batch [1378/1562], Loss: 0.2957\n",
      "Epoch [4/10], Batch [1380/1562], Loss: 0.2673\n",
      "Epoch [4/10], Batch [1382/1562], Loss: 0.3056\n",
      "Epoch [4/10], Batch [1384/1562], Loss: 0.2978\n",
      "Epoch [4/10], Batch [1386/1562], Loss: 0.2486\n",
      "Epoch [4/10], Batch [1388/1562], Loss: 0.2791\n",
      "Epoch [4/10], Batch [1390/1562], Loss: 0.2757\n",
      "Epoch [4/10], Batch [1392/1562], Loss: 0.2853\n",
      "Epoch [4/10], Batch [1394/1562], Loss: 0.2532\n",
      "Epoch [4/10], Batch [1396/1562], Loss: 0.2906\n",
      "Epoch [4/10], Batch [1398/1562], Loss: 0.2957\n",
      "Epoch [4/10], Batch [1400/1562], Loss: 0.3284\n",
      "Epoch [4/10], Batch [1402/1562], Loss: 0.2916\n",
      "Epoch [4/10], Batch [1404/1562], Loss: 0.3199\n",
      "Epoch [4/10], Batch [1406/1562], Loss: 0.2835\n",
      "Epoch [4/10], Batch [1408/1562], Loss: 0.2625\n",
      "Epoch [4/10], Batch [1410/1562], Loss: 0.2861\n",
      "Epoch [4/10], Batch [1412/1562], Loss: 0.3195\n",
      "Epoch [4/10], Batch [1414/1562], Loss: 0.3113\n",
      "Epoch [4/10], Batch [1416/1562], Loss: 0.3287\n",
      "Epoch [4/10], Batch [1418/1562], Loss: 0.2656\n",
      "Epoch [4/10], Batch [1420/1562], Loss: 0.2831\n",
      "Epoch [4/10], Batch [1422/1562], Loss: 0.3211\n",
      "Epoch [4/10], Batch [1424/1562], Loss: 0.3089\n",
      "Epoch [4/10], Batch [1426/1562], Loss: 0.2546\n",
      "Epoch [4/10], Batch [1428/1562], Loss: 0.2806\n",
      "Epoch [4/10], Batch [1430/1562], Loss: 0.2799\n",
      "Epoch [4/10], Batch [1432/1562], Loss: 0.2816\n",
      "Epoch [4/10], Batch [1434/1562], Loss: 0.2868\n",
      "Epoch [4/10], Batch [1436/1562], Loss: 0.3043\n",
      "Epoch [4/10], Batch [1438/1562], Loss: 0.3090\n",
      "Epoch [4/10], Batch [1440/1562], Loss: 0.2886\n",
      "Epoch [4/10], Batch [1442/1562], Loss: 0.2654\n",
      "Epoch [4/10], Batch [1444/1562], Loss: 0.2880\n",
      "Epoch [4/10], Batch [1446/1562], Loss: 0.3080\n",
      "Epoch [4/10], Batch [1448/1562], Loss: 0.2804\n",
      "Epoch [4/10], Batch [1450/1562], Loss: 0.3167\n",
      "Epoch [4/10], Batch [1452/1562], Loss: 0.2986\n",
      "Epoch [4/10], Batch [1454/1562], Loss: 0.2751\n",
      "Epoch [4/10], Batch [1456/1562], Loss: 0.2941\n",
      "Epoch [4/10], Batch [1458/1562], Loss: 0.3104\n",
      "Epoch [4/10], Batch [1460/1562], Loss: 0.2834\n",
      "Epoch [4/10], Batch [1462/1562], Loss: 0.2687\n",
      "Epoch [4/10], Batch [1464/1562], Loss: 0.2949\n",
      "Epoch [4/10], Batch [1466/1562], Loss: 0.2984\n",
      "Epoch [4/10], Batch [1468/1562], Loss: 0.2696\n",
      "Epoch [4/10], Batch [1470/1562], Loss: 0.2422\n",
      "Epoch [4/10], Batch [1472/1562], Loss: 0.2854\n",
      "Epoch [4/10], Batch [1474/1562], Loss: 0.3112\n",
      "Epoch [4/10], Batch [1476/1562], Loss: 0.2904\n",
      "Epoch [4/10], Batch [1478/1562], Loss: 0.2952\n",
      "Epoch [4/10], Batch [1480/1562], Loss: 0.3256\n",
      "Epoch [4/10], Batch [1482/1562], Loss: 0.2868\n",
      "Epoch [4/10], Batch [1484/1562], Loss: 0.2821\n",
      "Epoch [4/10], Batch [1486/1562], Loss: 0.3004\n",
      "Epoch [4/10], Batch [1488/1562], Loss: 0.2980\n",
      "Epoch [4/10], Batch [1490/1562], Loss: 0.3145\n",
      "Epoch [4/10], Batch [1492/1562], Loss: 0.2845\n",
      "Epoch [4/10], Batch [1494/1562], Loss: 0.3146\n",
      "Epoch [4/10], Batch [1496/1562], Loss: 0.2482\n",
      "Epoch [4/10], Batch [1498/1562], Loss: 0.2583\n",
      "Epoch [4/10], Batch [1500/1562], Loss: 0.2898\n",
      "Epoch [4/10], Batch [1502/1562], Loss: 0.2937\n",
      "Epoch [4/10], Batch [1504/1562], Loss: 0.2751\n",
      "Epoch [4/10], Batch [1506/1562], Loss: 0.2887\n",
      "Epoch [4/10], Batch [1508/1562], Loss: 0.2743\n",
      "Epoch [4/10], Batch [1510/1562], Loss: 0.2543\n",
      "Epoch [4/10], Batch [1512/1562], Loss: 0.2752\n",
      "Epoch [4/10], Batch [1514/1562], Loss: 0.2564\n",
      "Epoch [4/10], Batch [1516/1562], Loss: 0.2963\n",
      "Epoch [4/10], Batch [1518/1562], Loss: 0.2910\n",
      "Epoch [4/10], Batch [1520/1562], Loss: 0.3149\n",
      "Epoch [4/10], Batch [1522/1562], Loss: 0.2860\n",
      "Epoch [4/10], Batch [1524/1562], Loss: 0.2836\n",
      "Epoch [4/10], Batch [1526/1562], Loss: 0.2847\n",
      "Epoch [4/10], Batch [1528/1562], Loss: 0.3365\n",
      "Epoch [4/10], Batch [1530/1562], Loss: 0.3058\n",
      "Epoch [4/10], Batch [1532/1562], Loss: 0.2600\n",
      "Epoch [4/10], Batch [1534/1562], Loss: 0.3006\n",
      "Epoch [4/10], Batch [1536/1562], Loss: 0.3086\n",
      "Epoch [4/10], Batch [1538/1562], Loss: 0.3041\n",
      "Epoch [4/10], Batch [1540/1562], Loss: 0.3099\n",
      "Epoch [4/10], Batch [1542/1562], Loss: 0.2835\n",
      "Epoch [4/10], Batch [1544/1562], Loss: 0.2650\n",
      "Epoch [4/10], Batch [1546/1562], Loss: 0.2993\n",
      "Epoch [4/10], Batch [1548/1562], Loss: 0.3314\n",
      "Epoch [4/10], Batch [1550/1562], Loss: 0.2915\n",
      "Epoch [4/10], Batch [1552/1562], Loss: 0.2580\n",
      "Epoch [4/10], Batch [1554/1562], Loss: 0.2938\n",
      "Epoch [4/10], Batch [1556/1562], Loss: 0.3104\n",
      "Epoch [4/10], Batch [1558/1562], Loss: 0.3132\n",
      "Epoch [4/10], Batch [1560/1562], Loss: 0.2954\n",
      "Epoch [4/10], Batch [1562/1562], Loss: 0.2839\n",
      "Epoch [4/10] completed. Average Loss: 0.2870\n",
      "Epoch [5/10], Batch [2/1562], Loss: 0.2758\n",
      "Epoch [5/10], Batch [4/1562], Loss: 0.2943\n",
      "Epoch [5/10], Batch [6/1562], Loss: 0.3245\n",
      "Epoch [5/10], Batch [8/1562], Loss: 0.2909\n",
      "Epoch [5/10], Batch [10/1562], Loss: 0.3115\n",
      "Epoch [5/10], Batch [12/1562], Loss: 0.2899\n",
      "Epoch [5/10], Batch [14/1562], Loss: 0.2805\n",
      "Epoch [5/10], Batch [16/1562], Loss: 0.2946\n",
      "Epoch [5/10], Batch [18/1562], Loss: 0.3257\n",
      "Epoch [5/10], Batch [20/1562], Loss: 0.2537\n",
      "Epoch [5/10], Batch [22/1562], Loss: 0.2849\n",
      "Epoch [5/10], Batch [24/1562], Loss: 0.2466\n",
      "Epoch [5/10], Batch [26/1562], Loss: 0.3090\n",
      "Epoch [5/10], Batch [28/1562], Loss: 0.2945\n",
      "Epoch [5/10], Batch [30/1562], Loss: 0.2706\n",
      "Epoch [5/10], Batch [32/1562], Loss: 0.2686\n",
      "Epoch [5/10], Batch [34/1562], Loss: 0.2586\n",
      "Epoch [5/10], Batch [36/1562], Loss: 0.2885\n",
      "Epoch [5/10], Batch [38/1562], Loss: 0.3189\n",
      "Epoch [5/10], Batch [40/1562], Loss: 0.2446\n",
      "Epoch [5/10], Batch [42/1562], Loss: 0.3125\n",
      "Epoch [5/10], Batch [44/1562], Loss: 0.2445\n",
      "Epoch [5/10], Batch [46/1562], Loss: 0.3178\n",
      "Epoch [5/10], Batch [48/1562], Loss: 0.3020\n",
      "Epoch [5/10], Batch [50/1562], Loss: 0.2925\n",
      "Epoch [5/10], Batch [52/1562], Loss: 0.2772\n",
      "Epoch [5/10], Batch [54/1562], Loss: 0.2451\n",
      "Epoch [5/10], Batch [56/1562], Loss: 0.2656\n",
      "Epoch [5/10], Batch [58/1562], Loss: 0.3486\n",
      "Epoch [5/10], Batch [60/1562], Loss: 0.2777\n",
      "Epoch [5/10], Batch [62/1562], Loss: 0.2830\n",
      "Epoch [5/10], Batch [64/1562], Loss: 0.3302\n",
      "Epoch [5/10], Batch [66/1562], Loss: 0.3112\n",
      "Epoch [5/10], Batch [68/1562], Loss: 0.3396\n",
      "Epoch [5/10], Batch [70/1562], Loss: 0.2725\n",
      "Epoch [5/10], Batch [72/1562], Loss: 0.3255\n",
      "Epoch [5/10], Batch [74/1562], Loss: 0.3273\n",
      "Epoch [5/10], Batch [76/1562], Loss: 0.2428\n",
      "Epoch [5/10], Batch [78/1562], Loss: 0.2916\n",
      "Epoch [5/10], Batch [80/1562], Loss: 0.3177\n",
      "Epoch [5/10], Batch [82/1562], Loss: 0.2935\n",
      "Epoch [5/10], Batch [84/1562], Loss: 0.2847\n",
      "Epoch [5/10], Batch [86/1562], Loss: 0.3459\n",
      "Epoch [5/10], Batch [88/1562], Loss: 0.3128\n",
      "Epoch [5/10], Batch [90/1562], Loss: 0.2816\n",
      "Epoch [5/10], Batch [92/1562], Loss: 0.2780\n",
      "Epoch [5/10], Batch [94/1562], Loss: 0.2514\n",
      "Epoch [5/10], Batch [96/1562], Loss: 0.2988\n",
      "Epoch [5/10], Batch [98/1562], Loss: 0.3163\n",
      "Epoch [5/10], Batch [100/1562], Loss: 0.2726\n",
      "Epoch [5/10], Batch [102/1562], Loss: 0.2766\n",
      "Epoch [5/10], Batch [104/1562], Loss: 0.2901\n",
      "Epoch [5/10], Batch [106/1562], Loss: 0.2940\n",
      "Epoch [5/10], Batch [108/1562], Loss: 0.2595\n",
      "Epoch [5/10], Batch [110/1562], Loss: 0.2647\n",
      "Epoch [5/10], Batch [112/1562], Loss: 0.3462\n",
      "Epoch [5/10], Batch [114/1562], Loss: 0.2906\n",
      "Epoch [5/10], Batch [116/1562], Loss: 0.2565\n",
      "Epoch [5/10], Batch [118/1562], Loss: 0.3110\n",
      "Epoch [5/10], Batch [120/1562], Loss: 0.2853\n",
      "Epoch [5/10], Batch [122/1562], Loss: 0.3400\n",
      "Epoch [5/10], Batch [124/1562], Loss: 0.3105\n",
      "Epoch [5/10], Batch [126/1562], Loss: 0.2698\n",
      "Epoch [5/10], Batch [128/1562], Loss: 0.2529\n",
      "Epoch [5/10], Batch [130/1562], Loss: 0.2940\n",
      "Epoch [5/10], Batch [132/1562], Loss: 0.2981\n",
      "Epoch [5/10], Batch [134/1562], Loss: 0.2974\n",
      "Epoch [5/10], Batch [136/1562], Loss: 0.2507\n",
      "Epoch [5/10], Batch [138/1562], Loss: 0.3178\n",
      "Epoch [5/10], Batch [140/1562], Loss: 0.3036\n",
      "Epoch [5/10], Batch [142/1562], Loss: 0.2810\n",
      "Epoch [5/10], Batch [144/1562], Loss: 0.2573\n",
      "Epoch [5/10], Batch [146/1562], Loss: 0.2765\n",
      "Epoch [5/10], Batch [148/1562], Loss: 0.3028\n",
      "Epoch [5/10], Batch [150/1562], Loss: 0.2680\n",
      "Epoch [5/10], Batch [152/1562], Loss: 0.2832\n",
      "Epoch [5/10], Batch [154/1562], Loss: 0.3003\n",
      "Epoch [5/10], Batch [156/1562], Loss: 0.3149\n",
      "Epoch [5/10], Batch [158/1562], Loss: 0.3309\n",
      "Epoch [5/10], Batch [160/1562], Loss: 0.3350\n",
      "Epoch [5/10], Batch [162/1562], Loss: 0.2788\n",
      "Epoch [5/10], Batch [164/1562], Loss: 0.2688\n",
      "Epoch [5/10], Batch [166/1562], Loss: 0.3137\n",
      "Epoch [5/10], Batch [168/1562], Loss: 0.2678\n",
      "Epoch [5/10], Batch [170/1562], Loss: 0.3040\n",
      "Epoch [5/10], Batch [172/1562], Loss: 0.2499\n",
      "Epoch [5/10], Batch [174/1562], Loss: 0.3179\n",
      "Epoch [5/10], Batch [176/1562], Loss: 0.3597\n",
      "Epoch [5/10], Batch [178/1562], Loss: 0.3025\n",
      "Epoch [5/10], Batch [180/1562], Loss: 0.2751\n",
      "Epoch [5/10], Batch [182/1562], Loss: 0.2566\n",
      "Epoch [5/10], Batch [184/1562], Loss: 0.2768\n",
      "Epoch [5/10], Batch [186/1562], Loss: 0.2877\n",
      "Epoch [5/10], Batch [188/1562], Loss: 0.2758\n",
      "Epoch [5/10], Batch [190/1562], Loss: 0.2727\n",
      "Epoch [5/10], Batch [192/1562], Loss: 0.3105\n",
      "Epoch [5/10], Batch [194/1562], Loss: 0.3177\n",
      "Epoch [5/10], Batch [196/1562], Loss: 0.2979\n",
      "Epoch [5/10], Batch [198/1562], Loss: 0.2740\n",
      "Epoch [5/10], Batch [200/1562], Loss: 0.2692\n",
      "Epoch [5/10], Batch [202/1562], Loss: 0.2719\n",
      "Epoch [5/10], Batch [204/1562], Loss: 0.2949\n",
      "Epoch [5/10], Batch [206/1562], Loss: 0.2711\n",
      "Epoch [5/10], Batch [208/1562], Loss: 0.3036\n",
      "Epoch [5/10], Batch [210/1562], Loss: 0.2620\n",
      "Epoch [5/10], Batch [212/1562], Loss: 0.2676\n",
      "Epoch [5/10], Batch [214/1562], Loss: 0.2646\n",
      "Epoch [5/10], Batch [216/1562], Loss: 0.2863\n",
      "Epoch [5/10], Batch [218/1562], Loss: 0.3116\n",
      "Epoch [5/10], Batch [220/1562], Loss: 0.2870\n",
      "Epoch [5/10], Batch [222/1562], Loss: 0.3003\n",
      "Epoch [5/10], Batch [224/1562], Loss: 0.2670\n",
      "Epoch [5/10], Batch [226/1562], Loss: 0.2815\n",
      "Epoch [5/10], Batch [228/1562], Loss: 0.2467\n",
      "Epoch [5/10], Batch [230/1562], Loss: 0.2671\n",
      "Epoch [5/10], Batch [232/1562], Loss: 0.2688\n",
      "Epoch [5/10], Batch [234/1562], Loss: 0.2728\n",
      "Epoch [5/10], Batch [236/1562], Loss: 0.2993\n",
      "Epoch [5/10], Batch [238/1562], Loss: 0.2816\n",
      "Epoch [5/10], Batch [240/1562], Loss: 0.2852\n",
      "Epoch [5/10], Batch [242/1562], Loss: 0.2895\n",
      "Epoch [5/10], Batch [244/1562], Loss: 0.3062\n",
      "Epoch [5/10], Batch [246/1562], Loss: 0.3071\n",
      "Epoch [5/10], Batch [248/1562], Loss: 0.2884\n",
      "Epoch [5/10], Batch [250/1562], Loss: 0.2728\n",
      "Epoch [5/10], Batch [252/1562], Loss: 0.3137\n",
      "Epoch [5/10], Batch [254/1562], Loss: 0.2580\n",
      "Epoch [5/10], Batch [256/1562], Loss: 0.3058\n",
      "Epoch [5/10], Batch [258/1562], Loss: 0.2452\n",
      "Epoch [5/10], Batch [260/1562], Loss: 0.3130\n",
      "Epoch [5/10], Batch [262/1562], Loss: 0.2909\n",
      "Epoch [5/10], Batch [264/1562], Loss: 0.2878\n",
      "Epoch [5/10], Batch [266/1562], Loss: 0.2706\n",
      "Epoch [5/10], Batch [268/1562], Loss: 0.2780\n",
      "Epoch [5/10], Batch [270/1562], Loss: 0.2794\n",
      "Epoch [5/10], Batch [272/1562], Loss: 0.2842\n",
      "Epoch [5/10], Batch [274/1562], Loss: 0.2822\n",
      "Epoch [5/10], Batch [276/1562], Loss: 0.2714\n",
      "Epoch [5/10], Batch [278/1562], Loss: 0.2997\n",
      "Epoch [5/10], Batch [280/1562], Loss: 0.2818\n",
      "Epoch [5/10], Batch [282/1562], Loss: 0.2817\n",
      "Epoch [5/10], Batch [284/1562], Loss: 0.2633\n",
      "Epoch [5/10], Batch [286/1562], Loss: 0.2981\n",
      "Epoch [5/10], Batch [288/1562], Loss: 0.2763\n",
      "Epoch [5/10], Batch [290/1562], Loss: 0.2985\n",
      "Epoch [5/10], Batch [292/1562], Loss: 0.2800\n",
      "Epoch [5/10], Batch [294/1562], Loss: 0.3068\n",
      "Epoch [5/10], Batch [296/1562], Loss: 0.2630\n",
      "Epoch [5/10], Batch [298/1562], Loss: 0.2788\n",
      "Epoch [5/10], Batch [300/1562], Loss: 0.3325\n",
      "Epoch [5/10], Batch [302/1562], Loss: 0.2743\n",
      "Epoch [5/10], Batch [304/1562], Loss: 0.3104\n",
      "Epoch [5/10], Batch [306/1562], Loss: 0.2823\n",
      "Epoch [5/10], Batch [308/1562], Loss: 0.2660\n",
      "Epoch [5/10], Batch [310/1562], Loss: 0.3201\n",
      "Epoch [5/10], Batch [312/1562], Loss: 0.3332\n",
      "Epoch [5/10], Batch [314/1562], Loss: 0.2648\n",
      "Epoch [5/10], Batch [316/1562], Loss: 0.2475\n",
      "Epoch [5/10], Batch [318/1562], Loss: 0.2759\n",
      "Epoch [5/10], Batch [320/1562], Loss: 0.2929\n",
      "Epoch [5/10], Batch [322/1562], Loss: 0.2735\n",
      "Epoch [5/10], Batch [324/1562], Loss: 0.2685\n",
      "Epoch [5/10], Batch [326/1562], Loss: 0.3110\n",
      "Epoch [5/10], Batch [328/1562], Loss: 0.2631\n",
      "Epoch [5/10], Batch [330/1562], Loss: 0.3077\n",
      "Epoch [5/10], Batch [332/1562], Loss: 0.3089\n",
      "Epoch [5/10], Batch [334/1562], Loss: 0.2805\n",
      "Epoch [5/10], Batch [336/1562], Loss: 0.3259\n",
      "Epoch [5/10], Batch [338/1562], Loss: 0.2998\n",
      "Epoch [5/10], Batch [340/1562], Loss: 0.3078\n",
      "Epoch [5/10], Batch [342/1562], Loss: 0.2866\n",
      "Epoch [5/10], Batch [344/1562], Loss: 0.2837\n",
      "Epoch [5/10], Batch [346/1562], Loss: 0.2518\n",
      "Epoch [5/10], Batch [348/1562], Loss: 0.2675\n",
      "Epoch [5/10], Batch [350/1562], Loss: 0.3253\n",
      "Epoch [5/10], Batch [352/1562], Loss: 0.2975\n",
      "Epoch [5/10], Batch [354/1562], Loss: 0.3066\n",
      "Epoch [5/10], Batch [356/1562], Loss: 0.3237\n",
      "Epoch [5/10], Batch [358/1562], Loss: 0.3327\n",
      "Epoch [5/10], Batch [360/1562], Loss: 0.2705\n",
      "Epoch [5/10], Batch [362/1562], Loss: 0.3041\n",
      "Epoch [5/10], Batch [364/1562], Loss: 0.2817\n",
      "Epoch [5/10], Batch [366/1562], Loss: 0.2641\n",
      "Epoch [5/10], Batch [368/1562], Loss: 0.3325\n",
      "Epoch [5/10], Batch [370/1562], Loss: 0.2640\n",
      "Epoch [5/10], Batch [372/1562], Loss: 0.2878\n",
      "Epoch [5/10], Batch [374/1562], Loss: 0.3257\n",
      "Epoch [5/10], Batch [376/1562], Loss: 0.2759\n",
      "Epoch [5/10], Batch [378/1562], Loss: 0.2794\n",
      "Epoch [5/10], Batch [380/1562], Loss: 0.2750\n",
      "Epoch [5/10], Batch [382/1562], Loss: 0.2914\n",
      "Epoch [5/10], Batch [384/1562], Loss: 0.3227\n",
      "Epoch [5/10], Batch [386/1562], Loss: 0.3519\n",
      "Epoch [5/10], Batch [388/1562], Loss: 0.2965\n",
      "Epoch [5/10], Batch [390/1562], Loss: 0.2867\n",
      "Epoch [5/10], Batch [392/1562], Loss: 0.2453\n",
      "Epoch [5/10], Batch [394/1562], Loss: 0.2658\n",
      "Epoch [5/10], Batch [396/1562], Loss: 0.3120\n",
      "Epoch [5/10], Batch [398/1562], Loss: 0.2598\n",
      "Epoch [5/10], Batch [400/1562], Loss: 0.2842\n",
      "Epoch [5/10], Batch [402/1562], Loss: 0.2809\n",
      "Epoch [5/10], Batch [404/1562], Loss: 0.2580\n",
      "Epoch [5/10], Batch [406/1562], Loss: 0.3071\n",
      "Epoch [5/10], Batch [408/1562], Loss: 0.2561\n",
      "Epoch [5/10], Batch [410/1562], Loss: 0.3003\n",
      "Epoch [5/10], Batch [412/1562], Loss: 0.2977\n",
      "Epoch [5/10], Batch [414/1562], Loss: 0.3009\n",
      "Epoch [5/10], Batch [416/1562], Loss: 0.3095\n",
      "Epoch [5/10], Batch [418/1562], Loss: 0.2971\n",
      "Epoch [5/10], Batch [420/1562], Loss: 0.2975\n",
      "Epoch [5/10], Batch [422/1562], Loss: 0.2454\n",
      "Epoch [5/10], Batch [424/1562], Loss: 0.3217\n",
      "Epoch [5/10], Batch [426/1562], Loss: 0.2883\n",
      "Epoch [5/10], Batch [428/1562], Loss: 0.2974\n",
      "Epoch [5/10], Batch [430/1562], Loss: 0.3026\n",
      "Epoch [5/10], Batch [432/1562], Loss: 0.2794\n",
      "Epoch [5/10], Batch [434/1562], Loss: 0.3039\n",
      "Epoch [5/10], Batch [436/1562], Loss: 0.2579\n",
      "Epoch [5/10], Batch [438/1562], Loss: 0.2534\n",
      "Epoch [5/10], Batch [440/1562], Loss: 0.2921\n",
      "Epoch [5/10], Batch [442/1562], Loss: 0.3039\n",
      "Epoch [5/10], Batch [444/1562], Loss: 0.2995\n",
      "Epoch [5/10], Batch [446/1562], Loss: 0.2754\n",
      "Epoch [5/10], Batch [448/1562], Loss: 0.2843\n",
      "Epoch [5/10], Batch [450/1562], Loss: 0.2827\n",
      "Epoch [5/10], Batch [452/1562], Loss: 0.3137\n",
      "Epoch [5/10], Batch [454/1562], Loss: 0.2580\n",
      "Epoch [5/10], Batch [456/1562], Loss: 0.2706\n",
      "Epoch [5/10], Batch [458/1562], Loss: 0.2885\n",
      "Epoch [5/10], Batch [460/1562], Loss: 0.3361\n",
      "Epoch [5/10], Batch [462/1562], Loss: 0.2991\n",
      "Epoch [5/10], Batch [464/1562], Loss: 0.2965\n",
      "Epoch [5/10], Batch [466/1562], Loss: 0.3183\n",
      "Epoch [5/10], Batch [468/1562], Loss: 0.3139\n",
      "Epoch [5/10], Batch [470/1562], Loss: 0.2906\n",
      "Epoch [5/10], Batch [472/1562], Loss: 0.3141\n",
      "Epoch [5/10], Batch [474/1562], Loss: 0.2995\n",
      "Epoch [5/10], Batch [476/1562], Loss: 0.3329\n",
      "Epoch [5/10], Batch [478/1562], Loss: 0.2831\n",
      "Epoch [5/10], Batch [480/1562], Loss: 0.2770\n",
      "Epoch [5/10], Batch [482/1562], Loss: 0.3305\n",
      "Epoch [5/10], Batch [484/1562], Loss: 0.3012\n",
      "Epoch [5/10], Batch [486/1562], Loss: 0.3000\n",
      "Epoch [5/10], Batch [488/1562], Loss: 0.2972\n",
      "Epoch [5/10], Batch [490/1562], Loss: 0.2943\n",
      "Epoch [5/10], Batch [492/1562], Loss: 0.2995\n",
      "Epoch [5/10], Batch [494/1562], Loss: 0.2847\n",
      "Epoch [5/10], Batch [496/1562], Loss: 0.3322\n",
      "Epoch [5/10], Batch [498/1562], Loss: 0.2780\n",
      "Epoch [5/10], Batch [500/1562], Loss: 0.2988\n",
      "Epoch [5/10], Batch [502/1562], Loss: 0.2856\n",
      "Epoch [5/10], Batch [504/1562], Loss: 0.3046\n",
      "Epoch [5/10], Batch [506/1562], Loss: 0.3069\n",
      "Epoch [5/10], Batch [508/1562], Loss: 0.3046\n",
      "Epoch [5/10], Batch [510/1562], Loss: 0.2948\n",
      "Epoch [5/10], Batch [512/1562], Loss: 0.2627\n",
      "Epoch [5/10], Batch [514/1562], Loss: 0.2943\n",
      "Epoch [5/10], Batch [516/1562], Loss: 0.2952\n",
      "Epoch [5/10], Batch [518/1562], Loss: 0.3027\n",
      "Epoch [5/10], Batch [520/1562], Loss: 0.3068\n",
      "Epoch [5/10], Batch [522/1562], Loss: 0.2994\n",
      "Epoch [5/10], Batch [524/1562], Loss: 0.2971\n",
      "Epoch [5/10], Batch [526/1562], Loss: 0.2997\n",
      "Epoch [5/10], Batch [528/1562], Loss: 0.3133\n",
      "Epoch [5/10], Batch [530/1562], Loss: 0.2754\n",
      "Epoch [5/10], Batch [532/1562], Loss: 0.2822\n",
      "Epoch [5/10], Batch [534/1562], Loss: 0.3203\n",
      "Epoch [5/10], Batch [536/1562], Loss: 0.2937\n",
      "Epoch [5/10], Batch [538/1562], Loss: 0.3003\n",
      "Epoch [5/10], Batch [540/1562], Loss: 0.2303\n",
      "Epoch [5/10], Batch [542/1562], Loss: 0.2856\n",
      "Epoch [5/10], Batch [544/1562], Loss: 0.3503\n",
      "Epoch [5/10], Batch [546/1562], Loss: 0.2625\n",
      "Epoch [5/10], Batch [548/1562], Loss: 0.3137\n",
      "Epoch [5/10], Batch [550/1562], Loss: 0.2651\n",
      "Epoch [5/10], Batch [552/1562], Loss: 0.2634\n",
      "Epoch [5/10], Batch [554/1562], Loss: 0.3117\n",
      "Epoch [5/10], Batch [556/1562], Loss: 0.2847\n",
      "Epoch [5/10], Batch [558/1562], Loss: 0.2805\n",
      "Epoch [5/10], Batch [560/1562], Loss: 0.2664\n",
      "Epoch [5/10], Batch [562/1562], Loss: 0.2988\n",
      "Epoch [5/10], Batch [564/1562], Loss: 0.2966\n",
      "Epoch [5/10], Batch [566/1562], Loss: 0.2921\n",
      "Epoch [5/10], Batch [568/1562], Loss: 0.2603\n",
      "Epoch [5/10], Batch [570/1562], Loss: 0.2798\n",
      "Epoch [5/10], Batch [572/1562], Loss: 0.2976\n",
      "Epoch [5/10], Batch [574/1562], Loss: 0.2988\n",
      "Epoch [5/10], Batch [576/1562], Loss: 0.2741\n",
      "Epoch [5/10], Batch [578/1562], Loss: 0.2637\n",
      "Epoch [5/10], Batch [580/1562], Loss: 0.3115\n",
      "Epoch [5/10], Batch [582/1562], Loss: 0.3080\n",
      "Epoch [5/10], Batch [584/1562], Loss: 0.2792\n",
      "Epoch [5/10], Batch [586/1562], Loss: 0.2716\n",
      "Epoch [5/10], Batch [588/1562], Loss: 0.2435\n",
      "Epoch [5/10], Batch [590/1562], Loss: 0.2802\n",
      "Epoch [5/10], Batch [592/1562], Loss: 0.2825\n",
      "Epoch [5/10], Batch [594/1562], Loss: 0.2908\n",
      "Epoch [5/10], Batch [596/1562], Loss: 0.2575\n",
      "Epoch [5/10], Batch [598/1562], Loss: 0.2797\n",
      "Epoch [5/10], Batch [600/1562], Loss: 0.2922\n",
      "Epoch [5/10], Batch [602/1562], Loss: 0.3078\n",
      "Epoch [5/10], Batch [604/1562], Loss: 0.3022\n",
      "Epoch [5/10], Batch [606/1562], Loss: 0.2962\n",
      "Epoch [5/10], Batch [608/1562], Loss: 0.2856\n",
      "Epoch [5/10], Batch [610/1562], Loss: 0.3485\n",
      "Epoch [5/10], Batch [612/1562], Loss: 0.2671\n",
      "Epoch [5/10], Batch [614/1562], Loss: 0.2822\n",
      "Epoch [5/10], Batch [616/1562], Loss: 0.2701\n",
      "Epoch [5/10], Batch [618/1562], Loss: 0.2983\n",
      "Epoch [5/10], Batch [620/1562], Loss: 0.2750\n",
      "Epoch [5/10], Batch [622/1562], Loss: 0.3172\n",
      "Epoch [5/10], Batch [624/1562], Loss: 0.2835\n",
      "Epoch [5/10], Batch [626/1562], Loss: 0.2848\n",
      "Epoch [5/10], Batch [628/1562], Loss: 0.2878\n",
      "Epoch [5/10], Batch [630/1562], Loss: 0.2788\n",
      "Epoch [5/10], Batch [632/1562], Loss: 0.2726\n",
      "Epoch [5/10], Batch [634/1562], Loss: 0.3185\n",
      "Epoch [5/10], Batch [636/1562], Loss: 0.2695\n",
      "Epoch [5/10], Batch [638/1562], Loss: 0.3251\n",
      "Epoch [5/10], Batch [640/1562], Loss: 0.3011\n",
      "Epoch [5/10], Batch [642/1562], Loss: 0.2742\n",
      "Epoch [5/10], Batch [644/1562], Loss: 0.3017\n",
      "Epoch [5/10], Batch [646/1562], Loss: 0.3096\n",
      "Epoch [5/10], Batch [648/1562], Loss: 0.2957\n",
      "Epoch [5/10], Batch [650/1562], Loss: 0.3028\n",
      "Epoch [5/10], Batch [652/1562], Loss: 0.3245\n",
      "Epoch [5/10], Batch [654/1562], Loss: 0.2380\n",
      "Epoch [5/10], Batch [656/1562], Loss: 0.2744\n",
      "Epoch [5/10], Batch [658/1562], Loss: 0.2916\n",
      "Epoch [5/10], Batch [660/1562], Loss: 0.2822\n",
      "Epoch [5/10], Batch [662/1562], Loss: 0.2952\n",
      "Epoch [5/10], Batch [664/1562], Loss: 0.2927\n",
      "Epoch [5/10], Batch [666/1562], Loss: 0.2853\n",
      "Epoch [5/10], Batch [668/1562], Loss: 0.3138\n",
      "Epoch [5/10], Batch [670/1562], Loss: 0.2405\n",
      "Epoch [5/10], Batch [672/1562], Loss: 0.2999\n",
      "Epoch [5/10], Batch [674/1562], Loss: 0.2613\n",
      "Epoch [5/10], Batch [676/1562], Loss: 0.3078\n",
      "Epoch [5/10], Batch [678/1562], Loss: 0.3090\n",
      "Epoch [5/10], Batch [680/1562], Loss: 0.2563\n",
      "Epoch [5/10], Batch [682/1562], Loss: 0.3832\n",
      "Epoch [5/10], Batch [684/1562], Loss: 0.3014\n",
      "Epoch [5/10], Batch [686/1562], Loss: 0.3110\n",
      "Epoch [5/10], Batch [688/1562], Loss: 0.3251\n",
      "Epoch [5/10], Batch [690/1562], Loss: 0.3239\n",
      "Epoch [5/10], Batch [692/1562], Loss: 0.3119\n",
      "Epoch [5/10], Batch [694/1562], Loss: 0.2683\n",
      "Epoch [5/10], Batch [696/1562], Loss: 0.2761\n",
      "Epoch [5/10], Batch [698/1562], Loss: 0.2914\n",
      "Epoch [5/10], Batch [700/1562], Loss: 0.2918\n",
      "Epoch [5/10], Batch [702/1562], Loss: 0.3257\n",
      "Epoch [5/10], Batch [704/1562], Loss: 0.2415\n",
      "Epoch [5/10], Batch [706/1562], Loss: 0.2898\n",
      "Epoch [5/10], Batch [708/1562], Loss: 0.2780\n",
      "Epoch [5/10], Batch [710/1562], Loss: 0.3095\n",
      "Epoch [5/10], Batch [712/1562], Loss: 0.3089\n",
      "Epoch [5/10], Batch [714/1562], Loss: 0.2899\n",
      "Epoch [5/10], Batch [716/1562], Loss: 0.2470\n",
      "Epoch [5/10], Batch [718/1562], Loss: 0.2761\n",
      "Epoch [5/10], Batch [720/1562], Loss: 0.3140\n",
      "Epoch [5/10], Batch [722/1562], Loss: 0.2817\n",
      "Epoch [5/10], Batch [724/1562], Loss: 0.2801\n",
      "Epoch [5/10], Batch [726/1562], Loss: 0.3282\n",
      "Epoch [5/10], Batch [728/1562], Loss: 0.2899\n",
      "Epoch [5/10], Batch [730/1562], Loss: 0.2880\n",
      "Epoch [5/10], Batch [732/1562], Loss: 0.3095\n",
      "Epoch [5/10], Batch [734/1562], Loss: 0.2905\n",
      "Epoch [5/10], Batch [736/1562], Loss: 0.2814\n",
      "Epoch [5/10], Batch [738/1562], Loss: 0.2726\n",
      "Epoch [5/10], Batch [740/1562], Loss: 0.2408\n",
      "Epoch [5/10], Batch [742/1562], Loss: 0.2816\n",
      "Epoch [5/10], Batch [744/1562], Loss: 0.2915\n",
      "Epoch [5/10], Batch [746/1562], Loss: 0.3284\n",
      "Epoch [5/10], Batch [748/1562], Loss: 0.2960\n",
      "Epoch [5/10], Batch [750/1562], Loss: 0.2690\n",
      "Epoch [5/10], Batch [752/1562], Loss: 0.2493\n",
      "Epoch [5/10], Batch [754/1562], Loss: 0.3296\n",
      "Epoch [5/10], Batch [756/1562], Loss: 0.3058\n",
      "Epoch [5/10], Batch [758/1562], Loss: 0.2925\n",
      "Epoch [5/10], Batch [760/1562], Loss: 0.2473\n",
      "Epoch [5/10], Batch [762/1562], Loss: 0.2616\n",
      "Epoch [5/10], Batch [764/1562], Loss: 0.2590\n",
      "Epoch [5/10], Batch [766/1562], Loss: 0.3114\n",
      "Epoch [5/10], Batch [768/1562], Loss: 0.2816\n",
      "Epoch [5/10], Batch [770/1562], Loss: 0.2749\n",
      "Epoch [5/10], Batch [772/1562], Loss: 0.2829\n",
      "Epoch [5/10], Batch [774/1562], Loss: 0.3061\n",
      "Epoch [5/10], Batch [776/1562], Loss: 0.2568\n",
      "Epoch [5/10], Batch [778/1562], Loss: 0.2982\n",
      "Epoch [5/10], Batch [780/1562], Loss: 0.3070\n",
      "Epoch [5/10], Batch [782/1562], Loss: 0.2770\n",
      "Epoch [5/10], Batch [784/1562], Loss: 0.2909\n",
      "Epoch [5/10], Batch [786/1562], Loss: 0.2522\n",
      "Epoch [5/10], Batch [788/1562], Loss: 0.2883\n",
      "Epoch [5/10], Batch [790/1562], Loss: 0.2684\n",
      "Epoch [5/10], Batch [792/1562], Loss: 0.2343\n",
      "Epoch [5/10], Batch [794/1562], Loss: 0.2813\n",
      "Epoch [5/10], Batch [796/1562], Loss: 0.2994\n",
      "Epoch [5/10], Batch [798/1562], Loss: 0.2730\n",
      "Epoch [5/10], Batch [800/1562], Loss: 0.3196\n",
      "Epoch [5/10], Batch [802/1562], Loss: 0.2924\n",
      "Epoch [5/10], Batch [804/1562], Loss: 0.3123\n",
      "Epoch [5/10], Batch [806/1562], Loss: 0.2440\n",
      "Epoch [5/10], Batch [808/1562], Loss: 0.2828\n",
      "Epoch [5/10], Batch [810/1562], Loss: 0.2617\n",
      "Epoch [5/10], Batch [812/1562], Loss: 0.2776\n",
      "Epoch [5/10], Batch [814/1562], Loss: 0.3231\n",
      "Epoch [5/10], Batch [816/1562], Loss: 0.2818\n",
      "Epoch [5/10], Batch [818/1562], Loss: 0.3409\n",
      "Epoch [5/10], Batch [820/1562], Loss: 0.3142\n",
      "Epoch [5/10], Batch [822/1562], Loss: 0.2737\n",
      "Epoch [5/10], Batch [824/1562], Loss: 0.2848\n",
      "Epoch [5/10], Batch [826/1562], Loss: 0.2648\n",
      "Epoch [5/10], Batch [828/1562], Loss: 0.3158\n",
      "Epoch [5/10], Batch [830/1562], Loss: 0.2643\n",
      "Epoch [5/10], Batch [832/1562], Loss: 0.2967\n",
      "Epoch [5/10], Batch [834/1562], Loss: 0.2837\n",
      "Epoch [5/10], Batch [836/1562], Loss: 0.3100\n",
      "Epoch [5/10], Batch [838/1562], Loss: 0.2883\n",
      "Epoch [5/10], Batch [840/1562], Loss: 0.2662\n",
      "Epoch [5/10], Batch [842/1562], Loss: 0.2663\n",
      "Epoch [5/10], Batch [844/1562], Loss: 0.2859\n",
      "Epoch [5/10], Batch [846/1562], Loss: 0.2993\n",
      "Epoch [5/10], Batch [848/1562], Loss: 0.2933\n",
      "Epoch [5/10], Batch [850/1562], Loss: 0.2989\n",
      "Epoch [5/10], Batch [852/1562], Loss: 0.2951\n",
      "Epoch [5/10], Batch [854/1562], Loss: 0.2831\n",
      "Epoch [5/10], Batch [856/1562], Loss: 0.2419\n",
      "Epoch [5/10], Batch [858/1562], Loss: 0.3038\n",
      "Epoch [5/10], Batch [860/1562], Loss: 0.2986\n",
      "Epoch [5/10], Batch [862/1562], Loss: 0.2853\n",
      "Epoch [5/10], Batch [864/1562], Loss: 0.2762\n",
      "Epoch [5/10], Batch [866/1562], Loss: 0.2957\n",
      "Epoch [5/10], Batch [868/1562], Loss: 0.2977\n",
      "Epoch [5/10], Batch [870/1562], Loss: 0.2699\n",
      "Epoch [5/10], Batch [872/1562], Loss: 0.2624\n",
      "Epoch [5/10], Batch [874/1562], Loss: 0.3004\n",
      "Epoch [5/10], Batch [876/1562], Loss: 0.2735\n",
      "Epoch [5/10], Batch [878/1562], Loss: 0.2950\n",
      "Epoch [5/10], Batch [880/1562], Loss: 0.2540\n",
      "Epoch [5/10], Batch [882/1562], Loss: 0.2583\n",
      "Epoch [5/10], Batch [884/1562], Loss: 0.2832\n",
      "Epoch [5/10], Batch [886/1562], Loss: 0.2847\n",
      "Epoch [5/10], Batch [888/1562], Loss: 0.2964\n",
      "Epoch [5/10], Batch [890/1562], Loss: 0.2614\n",
      "Epoch [5/10], Batch [892/1562], Loss: 0.2530\n",
      "Epoch [5/10], Batch [894/1562], Loss: 0.3115\n",
      "Epoch [5/10], Batch [896/1562], Loss: 0.3389\n",
      "Epoch [5/10], Batch [898/1562], Loss: 0.3095\n",
      "Epoch [5/10], Batch [900/1562], Loss: 0.2679\n",
      "Epoch [5/10], Batch [902/1562], Loss: 0.2989\n",
      "Epoch [5/10], Batch [904/1562], Loss: 0.2947\n",
      "Epoch [5/10], Batch [906/1562], Loss: 0.3018\n",
      "Epoch [5/10], Batch [908/1562], Loss: 0.2624\n",
      "Epoch [5/10], Batch [910/1562], Loss: 0.2808\n",
      "Epoch [5/10], Batch [912/1562], Loss: 0.2953\n",
      "Epoch [5/10], Batch [914/1562], Loss: 0.2778\n",
      "Epoch [5/10], Batch [916/1562], Loss: 0.3285\n",
      "Epoch [5/10], Batch [918/1562], Loss: 0.2952\n",
      "Epoch [5/10], Batch [920/1562], Loss: 0.2665\n",
      "Epoch [5/10], Batch [922/1562], Loss: 0.2832\n",
      "Epoch [5/10], Batch [924/1562], Loss: 0.3353\n",
      "Epoch [5/10], Batch [926/1562], Loss: 0.2953\n",
      "Epoch [5/10], Batch [928/1562], Loss: 0.2958\n",
      "Epoch [5/10], Batch [930/1562], Loss: 0.2757\n",
      "Epoch [5/10], Batch [932/1562], Loss: 0.2672\n",
      "Epoch [5/10], Batch [934/1562], Loss: 0.3373\n",
      "Epoch [5/10], Batch [936/1562], Loss: 0.2651\n",
      "Epoch [5/10], Batch [938/1562], Loss: 0.2572\n",
      "Epoch [5/10], Batch [940/1562], Loss: 0.2770\n",
      "Epoch [5/10], Batch [942/1562], Loss: 0.2957\n",
      "Epoch [5/10], Batch [944/1562], Loss: 0.2795\n",
      "Epoch [5/10], Batch [946/1562], Loss: 0.2684\n",
      "Epoch [5/10], Batch [948/1562], Loss: 0.2826\n",
      "Epoch [5/10], Batch [950/1562], Loss: 0.2689\n",
      "Epoch [5/10], Batch [952/1562], Loss: 0.2673\n",
      "Epoch [5/10], Batch [954/1562], Loss: 0.2871\n",
      "Epoch [5/10], Batch [956/1562], Loss: 0.2702\n",
      "Epoch [5/10], Batch [958/1562], Loss: 0.3014\n",
      "Epoch [5/10], Batch [960/1562], Loss: 0.2682\n",
      "Epoch [5/10], Batch [962/1562], Loss: 0.2853\n",
      "Epoch [5/10], Batch [964/1562], Loss: 0.2791\n",
      "Epoch [5/10], Batch [966/1562], Loss: 0.2938\n",
      "Epoch [5/10], Batch [968/1562], Loss: 0.3054\n",
      "Epoch [5/10], Batch [970/1562], Loss: 0.3317\n",
      "Epoch [5/10], Batch [972/1562], Loss: 0.2925\n",
      "Epoch [5/10], Batch [974/1562], Loss: 0.3138\n",
      "Epoch [5/10], Batch [976/1562], Loss: 0.2841\n",
      "Epoch [5/10], Batch [978/1562], Loss: 0.2687\n",
      "Epoch [5/10], Batch [980/1562], Loss: 0.2512\n",
      "Epoch [5/10], Batch [982/1562], Loss: 0.2650\n",
      "Epoch [5/10], Batch [984/1562], Loss: 0.3037\n",
      "Epoch [5/10], Batch [986/1562], Loss: 0.3055\n",
      "Epoch [5/10], Batch [988/1562], Loss: 0.2470\n",
      "Epoch [5/10], Batch [990/1562], Loss: 0.2565\n",
      "Epoch [5/10], Batch [992/1562], Loss: 0.3108\n",
      "Epoch [5/10], Batch [994/1562], Loss: 0.3007\n",
      "Epoch [5/10], Batch [996/1562], Loss: 0.3202\n",
      "Epoch [5/10], Batch [998/1562], Loss: 0.3182\n",
      "Epoch [5/10], Batch [1000/1562], Loss: 0.2811\n",
      "Epoch [5/10], Batch [1002/1562], Loss: 0.3011\n",
      "Epoch [5/10], Batch [1004/1562], Loss: 0.2661\n",
      "Epoch [5/10], Batch [1006/1562], Loss: 0.2717\n",
      "Epoch [5/10], Batch [1008/1562], Loss: 0.3026\n",
      "Epoch [5/10], Batch [1010/1562], Loss: 0.2315\n",
      "Epoch [5/10], Batch [1012/1562], Loss: 0.2820\n",
      "Epoch [5/10], Batch [1014/1562], Loss: 0.2679\n",
      "Epoch [5/10], Batch [1016/1562], Loss: 0.2752\n",
      "Epoch [5/10], Batch [1018/1562], Loss: 0.2829\n",
      "Epoch [5/10], Batch [1020/1562], Loss: 0.2656\n",
      "Epoch [5/10], Batch [1022/1562], Loss: 0.2416\n",
      "Epoch [5/10], Batch [1024/1562], Loss: 0.2890\n",
      "Epoch [5/10], Batch [1026/1562], Loss: 0.2866\n",
      "Epoch [5/10], Batch [1028/1562], Loss: 0.2763\n",
      "Epoch [5/10], Batch [1030/1562], Loss: 0.2734\n",
      "Epoch [5/10], Batch [1032/1562], Loss: 0.2915\n",
      "Epoch [5/10], Batch [1034/1562], Loss: 0.2318\n",
      "Epoch [5/10], Batch [1036/1562], Loss: 0.2905\n",
      "Epoch [5/10], Batch [1038/1562], Loss: 0.3327\n",
      "Epoch [5/10], Batch [1040/1562], Loss: 0.3192\n",
      "Epoch [5/10], Batch [1042/1562], Loss: 0.2658\n",
      "Epoch [5/10], Batch [1044/1562], Loss: 0.3423\n",
      "Epoch [5/10], Batch [1046/1562], Loss: 0.2854\n",
      "Epoch [5/10], Batch [1048/1562], Loss: 0.2745\n",
      "Epoch [5/10], Batch [1050/1562], Loss: 0.3394\n",
      "Epoch [5/10], Batch [1052/1562], Loss: 0.2990\n",
      "Epoch [5/10], Batch [1054/1562], Loss: 0.2740\n",
      "Epoch [5/10], Batch [1056/1562], Loss: 0.2730\n",
      "Epoch [5/10], Batch [1058/1562], Loss: 0.2719\n",
      "Epoch [5/10], Batch [1060/1562], Loss: 0.2885\n",
      "Epoch [5/10], Batch [1062/1562], Loss: 0.2842\n",
      "Epoch [5/10], Batch [1064/1562], Loss: 0.2736\n",
      "Epoch [5/10], Batch [1066/1562], Loss: 0.2708\n",
      "Epoch [5/10], Batch [1068/1562], Loss: 0.2793\n",
      "Epoch [5/10], Batch [1070/1562], Loss: 0.3279\n",
      "Epoch [5/10], Batch [1072/1562], Loss: 0.2898\n",
      "Epoch [5/10], Batch [1074/1562], Loss: 0.2954\n",
      "Epoch [5/10], Batch [1076/1562], Loss: 0.2546\n",
      "Epoch [5/10], Batch [1078/1562], Loss: 0.2685\n",
      "Epoch [5/10], Batch [1080/1562], Loss: 0.2616\n",
      "Epoch [5/10], Batch [1082/1562], Loss: 0.2525\n",
      "Epoch [5/10], Batch [1084/1562], Loss: 0.2756\n",
      "Epoch [5/10], Batch [1086/1562], Loss: 0.2861\n",
      "Epoch [5/10], Batch [1088/1562], Loss: 0.3114\n",
      "Epoch [5/10], Batch [1090/1562], Loss: 0.2546\n",
      "Epoch [5/10], Batch [1092/1562], Loss: 0.3087\n",
      "Epoch [5/10], Batch [1094/1562], Loss: 0.3524\n",
      "Epoch [5/10], Batch [1096/1562], Loss: 0.2911\n",
      "Epoch [5/10], Batch [1098/1562], Loss: 0.2922\n",
      "Epoch [5/10], Batch [1100/1562], Loss: 0.2417\n",
      "Epoch [5/10], Batch [1102/1562], Loss: 0.2992\n",
      "Epoch [5/10], Batch [1104/1562], Loss: 0.2615\n",
      "Epoch [5/10], Batch [1106/1562], Loss: 0.2592\n",
      "Epoch [5/10], Batch [1108/1562], Loss: 0.3070\n",
      "Epoch [5/10], Batch [1110/1562], Loss: 0.2835\n",
      "Epoch [5/10], Batch [1112/1562], Loss: 0.2725\n",
      "Epoch [5/10], Batch [1114/1562], Loss: 0.3241\n",
      "Epoch [5/10], Batch [1116/1562], Loss: 0.3008\n",
      "Epoch [5/10], Batch [1118/1562], Loss: 0.2809\n",
      "Epoch [5/10], Batch [1120/1562], Loss: 0.3111\n",
      "Epoch [5/10], Batch [1122/1562], Loss: 0.2577\n",
      "Epoch [5/10], Batch [1124/1562], Loss: 0.3243\n",
      "Epoch [5/10], Batch [1126/1562], Loss: 0.2519\n",
      "Epoch [5/10], Batch [1128/1562], Loss: 0.2877\n",
      "Epoch [5/10], Batch [1130/1562], Loss: 0.2992\n",
      "Epoch [5/10], Batch [1132/1562], Loss: 0.2768\n",
      "Epoch [5/10], Batch [1134/1562], Loss: 0.3206\n",
      "Epoch [5/10], Batch [1136/1562], Loss: 0.2809\n",
      "Epoch [5/10], Batch [1138/1562], Loss: 0.2825\n",
      "Epoch [5/10], Batch [1140/1562], Loss: 0.2803\n",
      "Epoch [5/10], Batch [1142/1562], Loss: 0.3077\n",
      "Epoch [5/10], Batch [1144/1562], Loss: 0.2724\n",
      "Epoch [5/10], Batch [1146/1562], Loss: 0.3028\n",
      "Epoch [5/10], Batch [1148/1562], Loss: 0.2687\n",
      "Epoch [5/10], Batch [1150/1562], Loss: 0.3333\n",
      "Epoch [5/10], Batch [1152/1562], Loss: 0.2968\n",
      "Epoch [5/10], Batch [1154/1562], Loss: 0.2735\n",
      "Epoch [5/10], Batch [1156/1562], Loss: 0.3021\n",
      "Epoch [5/10], Batch [1158/1562], Loss: 0.2926\n",
      "Epoch [5/10], Batch [1160/1562], Loss: 0.2262\n",
      "Epoch [5/10], Batch [1162/1562], Loss: 0.2959\n",
      "Epoch [5/10], Batch [1164/1562], Loss: 0.2975\n",
      "Epoch [5/10], Batch [1166/1562], Loss: 0.2911\n",
      "Epoch [5/10], Batch [1168/1562], Loss: 0.2616\n",
      "Epoch [5/10], Batch [1170/1562], Loss: 0.3125\n",
      "Epoch [5/10], Batch [1172/1562], Loss: 0.3009\n",
      "Epoch [5/10], Batch [1174/1562], Loss: 0.3008\n",
      "Epoch [5/10], Batch [1176/1562], Loss: 0.2984\n",
      "Epoch [5/10], Batch [1178/1562], Loss: 0.2872\n",
      "Epoch [5/10], Batch [1180/1562], Loss: 0.2768\n",
      "Epoch [5/10], Batch [1182/1562], Loss: 0.2993\n",
      "Epoch [5/10], Batch [1184/1562], Loss: 0.2622\n",
      "Epoch [5/10], Batch [1186/1562], Loss: 0.2688\n",
      "Epoch [5/10], Batch [1188/1562], Loss: 0.2662\n",
      "Epoch [5/10], Batch [1190/1562], Loss: 0.2949\n",
      "Epoch [5/10], Batch [1192/1562], Loss: 0.2823\n",
      "Epoch [5/10], Batch [1194/1562], Loss: 0.2818\n",
      "Epoch [5/10], Batch [1196/1562], Loss: 0.3149\n",
      "Epoch [5/10], Batch [1198/1562], Loss: 0.3450\n",
      "Epoch [5/10], Batch [1200/1562], Loss: 0.2908\n",
      "Epoch [5/10], Batch [1202/1562], Loss: 0.2627\n",
      "Epoch [5/10], Batch [1204/1562], Loss: 0.2831\n",
      "Epoch [5/10], Batch [1206/1562], Loss: 0.2450\n",
      "Epoch [5/10], Batch [1208/1562], Loss: 0.2807\n",
      "Epoch [5/10], Batch [1210/1562], Loss: 0.2722\n",
      "Epoch [5/10], Batch [1212/1562], Loss: 0.2968\n",
      "Epoch [5/10], Batch [1214/1562], Loss: 0.2885\n",
      "Epoch [5/10], Batch [1216/1562], Loss: 0.2841\n",
      "Epoch [5/10], Batch [1218/1562], Loss: 0.2775\n",
      "Epoch [5/10], Batch [1220/1562], Loss: 0.3186\n",
      "Epoch [5/10], Batch [1222/1562], Loss: 0.2760\n",
      "Epoch [5/10], Batch [1224/1562], Loss: 0.3076\n",
      "Epoch [5/10], Batch [1226/1562], Loss: 0.2969\n",
      "Epoch [5/10], Batch [1228/1562], Loss: 0.2861\n",
      "Epoch [5/10], Batch [1230/1562], Loss: 0.2758\n",
      "Epoch [5/10], Batch [1232/1562], Loss: 0.2572\n",
      "Epoch [5/10], Batch [1234/1562], Loss: 0.3430\n",
      "Epoch [5/10], Batch [1236/1562], Loss: 0.2947\n",
      "Epoch [5/10], Batch [1238/1562], Loss: 0.2847\n",
      "Epoch [5/10], Batch [1240/1562], Loss: 0.2754\n",
      "Epoch [5/10], Batch [1242/1562], Loss: 0.2677\n",
      "Epoch [5/10], Batch [1244/1562], Loss: 0.2892\n",
      "Epoch [5/10], Batch [1246/1562], Loss: 0.2948\n",
      "Epoch [5/10], Batch [1248/1562], Loss: 0.2983\n",
      "Epoch [5/10], Batch [1250/1562], Loss: 0.3191\n",
      "Epoch [5/10], Batch [1252/1562], Loss: 0.2812\n",
      "Epoch [5/10], Batch [1254/1562], Loss: 0.2819\n",
      "Epoch [5/10], Batch [1256/1562], Loss: 0.3130\n",
      "Epoch [5/10], Batch [1258/1562], Loss: 0.2871\n",
      "Epoch [5/10], Batch [1260/1562], Loss: 0.3000\n",
      "Epoch [5/10], Batch [1262/1562], Loss: 0.3036\n",
      "Epoch [5/10], Batch [1264/1562], Loss: 0.2847\n",
      "Epoch [5/10], Batch [1266/1562], Loss: 0.2917\n",
      "Epoch [5/10], Batch [1268/1562], Loss: 0.3094\n",
      "Epoch [5/10], Batch [1270/1562], Loss: 0.2969\n",
      "Epoch [5/10], Batch [1272/1562], Loss: 0.3550\n",
      "Epoch [5/10], Batch [1274/1562], Loss: 0.2999\n",
      "Epoch [5/10], Batch [1276/1562], Loss: 0.2628\n",
      "Epoch [5/10], Batch [1278/1562], Loss: 0.3056\n",
      "Epoch [5/10], Batch [1280/1562], Loss: 0.2627\n",
      "Epoch [5/10], Batch [1282/1562], Loss: 0.2678\n",
      "Epoch [5/10], Batch [1284/1562], Loss: 0.3026\n",
      "Epoch [5/10], Batch [1286/1562], Loss: 0.3178\n",
      "Epoch [5/10], Batch [1288/1562], Loss: 0.2708\n",
      "Epoch [5/10], Batch [1290/1562], Loss: 0.3070\n",
      "Epoch [5/10], Batch [1292/1562], Loss: 0.2889\n",
      "Epoch [5/10], Batch [1294/1562], Loss: 0.2903\n",
      "Epoch [5/10], Batch [1296/1562], Loss: 0.3023\n",
      "Epoch [5/10], Batch [1298/1562], Loss: 0.2941\n",
      "Epoch [5/10], Batch [1300/1562], Loss: 0.2930\n",
      "Epoch [5/10], Batch [1302/1562], Loss: 0.3062\n",
      "Epoch [5/10], Batch [1304/1562], Loss: 0.2875\n",
      "Epoch [5/10], Batch [1306/1562], Loss: 0.2962\n",
      "Epoch [5/10], Batch [1308/1562], Loss: 0.3226\n",
      "Epoch [5/10], Batch [1310/1562], Loss: 0.2978\n",
      "Epoch [5/10], Batch [1312/1562], Loss: 0.2969\n",
      "Epoch [5/10], Batch [1314/1562], Loss: 0.3005\n",
      "Epoch [5/10], Batch [1316/1562], Loss: 0.3010\n",
      "Epoch [5/10], Batch [1318/1562], Loss: 0.2854\n",
      "Epoch [5/10], Batch [1320/1562], Loss: 0.3049\n",
      "Epoch [5/10], Batch [1322/1562], Loss: 0.2697\n",
      "Epoch [5/10], Batch [1324/1562], Loss: 0.2660\n",
      "Epoch [5/10], Batch [1326/1562], Loss: 0.2936\n",
      "Epoch [5/10], Batch [1328/1562], Loss: 0.2908\n",
      "Epoch [5/10], Batch [1330/1562], Loss: 0.3073\n",
      "Epoch [5/10], Batch [1332/1562], Loss: 0.2692\n",
      "Epoch [5/10], Batch [1334/1562], Loss: 0.2735\n",
      "Epoch [5/10], Batch [1336/1562], Loss: 0.3016\n",
      "Epoch [5/10], Batch [1338/1562], Loss: 0.3109\n",
      "Epoch [5/10], Batch [1340/1562], Loss: 0.3239\n",
      "Epoch [5/10], Batch [1342/1562], Loss: 0.2834\n",
      "Epoch [5/10], Batch [1344/1562], Loss: 0.2939\n",
      "Epoch [5/10], Batch [1346/1562], Loss: 0.2828\n",
      "Epoch [5/10], Batch [1348/1562], Loss: 0.3059\n",
      "Epoch [5/10], Batch [1350/1562], Loss: 0.2852\n",
      "Epoch [5/10], Batch [1352/1562], Loss: 0.2780\n",
      "Epoch [5/10], Batch [1354/1562], Loss: 0.2750\n",
      "Epoch [5/10], Batch [1356/1562], Loss: 0.3368\n",
      "Epoch [5/10], Batch [1358/1562], Loss: 0.3022\n",
      "Epoch [5/10], Batch [1360/1562], Loss: 0.2803\n",
      "Epoch [5/10], Batch [1362/1562], Loss: 0.2828\n",
      "Epoch [5/10], Batch [1364/1562], Loss: 0.2906\n",
      "Epoch [5/10], Batch [1366/1562], Loss: 0.2643\n",
      "Epoch [5/10], Batch [1368/1562], Loss: 0.3048\n",
      "Epoch [5/10], Batch [1370/1562], Loss: 0.2832\n",
      "Epoch [5/10], Batch [1372/1562], Loss: 0.3102\n",
      "Epoch [5/10], Batch [1374/1562], Loss: 0.3078\n",
      "Epoch [5/10], Batch [1376/1562], Loss: 0.2855\n",
      "Epoch [5/10], Batch [1378/1562], Loss: 0.2687\n",
      "Epoch [5/10], Batch [1380/1562], Loss: 0.2983\n",
      "Epoch [5/10], Batch [1382/1562], Loss: 0.3282\n",
      "Epoch [5/10], Batch [1384/1562], Loss: 0.2835\n",
      "Epoch [5/10], Batch [1386/1562], Loss: 0.3446\n",
      "Epoch [5/10], Batch [1388/1562], Loss: 0.2194\n",
      "Epoch [5/10], Batch [1390/1562], Loss: 0.2602\n",
      "Epoch [5/10], Batch [1392/1562], Loss: 0.3214\n",
      "Epoch [5/10], Batch [1394/1562], Loss: 0.3069\n",
      "Epoch [5/10], Batch [1396/1562], Loss: 0.2831\n",
      "Epoch [5/10], Batch [1398/1562], Loss: 0.2531\n",
      "Epoch [5/10], Batch [1400/1562], Loss: 0.2678\n",
      "Epoch [5/10], Batch [1402/1562], Loss: 0.2775\n",
      "Epoch [5/10], Batch [1404/1562], Loss: 0.2937\n",
      "Epoch [5/10], Batch [1406/1562], Loss: 0.3313\n",
      "Epoch [5/10], Batch [1408/1562], Loss: 0.2820\n",
      "Epoch [5/10], Batch [1410/1562], Loss: 0.3069\n",
      "Epoch [5/10], Batch [1412/1562], Loss: 0.3066\n",
      "Epoch [5/10], Batch [1414/1562], Loss: 0.2816\n",
      "Epoch [5/10], Batch [1416/1562], Loss: 0.2721\n",
      "Epoch [5/10], Batch [1418/1562], Loss: 0.2675\n",
      "Epoch [5/10], Batch [1420/1562], Loss: 0.3170\n",
      "Epoch [5/10], Batch [1422/1562], Loss: 0.2680\n",
      "Epoch [5/10], Batch [1424/1562], Loss: 0.2682\n",
      "Epoch [5/10], Batch [1426/1562], Loss: 0.2939\n",
      "Epoch [5/10], Batch [1428/1562], Loss: 0.3180\n",
      "Epoch [5/10], Batch [1430/1562], Loss: 0.3098\n",
      "Epoch [5/10], Batch [1432/1562], Loss: 0.3375\n",
      "Epoch [5/10], Batch [1434/1562], Loss: 0.2558\n",
      "Epoch [5/10], Batch [1436/1562], Loss: 0.2919\n",
      "Epoch [5/10], Batch [1438/1562], Loss: 0.2569\n",
      "Epoch [5/10], Batch [1440/1562], Loss: 0.3201\n",
      "Epoch [5/10], Batch [1442/1562], Loss: 0.2874\n",
      "Epoch [5/10], Batch [1444/1562], Loss: 0.2952\n",
      "Epoch [5/10], Batch [1446/1562], Loss: 0.2983\n",
      "Epoch [5/10], Batch [1448/1562], Loss: 0.3286\n",
      "Epoch [5/10], Batch [1450/1562], Loss: 0.2707\n",
      "Epoch [5/10], Batch [1452/1562], Loss: 0.2622\n",
      "Epoch [5/10], Batch [1454/1562], Loss: 0.2330\n",
      "Epoch [5/10], Batch [1456/1562], Loss: 0.2814\n",
      "Epoch [5/10], Batch [1458/1562], Loss: 0.2503\n",
      "Epoch [5/10], Batch [1460/1562], Loss: 0.3129\n",
      "Epoch [5/10], Batch [1462/1562], Loss: 0.2947\n",
      "Epoch [5/10], Batch [1464/1562], Loss: 0.2698\n",
      "Epoch [5/10], Batch [1466/1562], Loss: 0.2944\n",
      "Epoch [5/10], Batch [1468/1562], Loss: 0.3068\n",
      "Epoch [5/10], Batch [1470/1562], Loss: 0.2710\n",
      "Epoch [5/10], Batch [1472/1562], Loss: 0.2730\n",
      "Epoch [5/10], Batch [1474/1562], Loss: 0.2824\n",
      "Epoch [5/10], Batch [1476/1562], Loss: 0.2953\n",
      "Epoch [5/10], Batch [1478/1562], Loss: 0.3214\n",
      "Epoch [5/10], Batch [1480/1562], Loss: 0.3078\n",
      "Epoch [5/10], Batch [1482/1562], Loss: 0.3121\n",
      "Epoch [5/10], Batch [1484/1562], Loss: 0.3247\n",
      "Epoch [5/10], Batch [1486/1562], Loss: 0.3017\n",
      "Epoch [5/10], Batch [1488/1562], Loss: 0.3082\n",
      "Epoch [5/10], Batch [1490/1562], Loss: 0.2643\n",
      "Epoch [5/10], Batch [1492/1562], Loss: 0.2594\n",
      "Epoch [5/10], Batch [1494/1562], Loss: 0.2299\n",
      "Epoch [5/10], Batch [1496/1562], Loss: 0.2693\n",
      "Epoch [5/10], Batch [1498/1562], Loss: 0.2749\n",
      "Epoch [5/10], Batch [1500/1562], Loss: 0.2896\n",
      "Epoch [5/10], Batch [1502/1562], Loss: 0.3004\n",
      "Epoch [5/10], Batch [1504/1562], Loss: 0.2770\n",
      "Epoch [5/10], Batch [1506/1562], Loss: 0.2435\n",
      "Epoch [5/10], Batch [1508/1562], Loss: 0.2818\n",
      "Epoch [5/10], Batch [1510/1562], Loss: 0.2704\n",
      "Epoch [5/10], Batch [1512/1562], Loss: 0.2672\n",
      "Epoch [5/10], Batch [1514/1562], Loss: 0.2913\n",
      "Epoch [5/10], Batch [1516/1562], Loss: 0.3105\n",
      "Epoch [5/10], Batch [1518/1562], Loss: 0.2849\n",
      "Epoch [5/10], Batch [1520/1562], Loss: 0.2787\n",
      "Epoch [5/10], Batch [1522/1562], Loss: 0.2890\n",
      "Epoch [5/10], Batch [1524/1562], Loss: 0.2759\n",
      "Epoch [5/10], Batch [1526/1562], Loss: 0.3241\n",
      "Epoch [5/10], Batch [1528/1562], Loss: 0.3416\n",
      "Epoch [5/10], Batch [1530/1562], Loss: 0.3156\n",
      "Epoch [5/10], Batch [1532/1562], Loss: 0.3095\n",
      "Epoch [5/10], Batch [1534/1562], Loss: 0.2598\n",
      "Epoch [5/10], Batch [1536/1562], Loss: 0.2798\n",
      "Epoch [5/10], Batch [1538/1562], Loss: 0.2520\n",
      "Epoch [5/10], Batch [1540/1562], Loss: 0.3052\n",
      "Epoch [5/10], Batch [1542/1562], Loss: 0.2795\n",
      "Epoch [5/10], Batch [1544/1562], Loss: 0.2720\n",
      "Epoch [5/10], Batch [1546/1562], Loss: 0.2777\n",
      "Epoch [5/10], Batch [1548/1562], Loss: 0.2537\n",
      "Epoch [5/10], Batch [1550/1562], Loss: 0.3032\n",
      "Epoch [5/10], Batch [1552/1562], Loss: 0.3076\n",
      "Epoch [5/10], Batch [1554/1562], Loss: 0.2796\n",
      "Epoch [5/10], Batch [1556/1562], Loss: 0.3192\n",
      "Epoch [5/10], Batch [1558/1562], Loss: 0.2359\n",
      "Epoch [5/10], Batch [1560/1562], Loss: 0.3038\n",
      "Epoch [5/10], Batch [1562/1562], Loss: 0.3170\n",
      "Epoch [5/10] completed. Average Loss: 0.2881\n",
      "Epoch [6/10], Batch [2/1562], Loss: 0.2685\n",
      "Epoch [6/10], Batch [4/1562], Loss: 0.3039\n",
      "Epoch [6/10], Batch [6/1562], Loss: 0.3265\n",
      "Epoch [6/10], Batch [8/1562], Loss: 0.2533\n",
      "Epoch [6/10], Batch [10/1562], Loss: 0.2588\n",
      "Epoch [6/10], Batch [12/1562], Loss: 0.2840\n",
      "Epoch [6/10], Batch [14/1562], Loss: 0.2817\n",
      "Epoch [6/10], Batch [16/1562], Loss: 0.2734\n",
      "Epoch [6/10], Batch [18/1562], Loss: 0.3059\n",
      "Epoch [6/10], Batch [20/1562], Loss: 0.2707\n",
      "Epoch [6/10], Batch [22/1562], Loss: 0.2652\n",
      "Epoch [6/10], Batch [24/1562], Loss: 0.2692\n",
      "Epoch [6/10], Batch [26/1562], Loss: 0.2878\n",
      "Epoch [6/10], Batch [28/1562], Loss: 0.2742\n",
      "Epoch [6/10], Batch [30/1562], Loss: 0.3001\n",
      "Epoch [6/10], Batch [32/1562], Loss: 0.3021\n",
      "Epoch [6/10], Batch [34/1562], Loss: 0.2801\n",
      "Epoch [6/10], Batch [36/1562], Loss: 0.3120\n",
      "Epoch [6/10], Batch [38/1562], Loss: 0.2754\n",
      "Epoch [6/10], Batch [40/1562], Loss: 0.3333\n",
      "Epoch [6/10], Batch [42/1562], Loss: 0.2846\n",
      "Epoch [6/10], Batch [44/1562], Loss: 0.2856\n",
      "Epoch [6/10], Batch [46/1562], Loss: 0.2862\n",
      "Epoch [6/10], Batch [48/1562], Loss: 0.2622\n",
      "Epoch [6/10], Batch [50/1562], Loss: 0.2513\n",
      "Epoch [6/10], Batch [52/1562], Loss: 0.2995\n",
      "Epoch [6/10], Batch [54/1562], Loss: 0.2798\n",
      "Epoch [6/10], Batch [56/1562], Loss: 0.3042\n",
      "Epoch [6/10], Batch [58/1562], Loss: 0.3126\n",
      "Epoch [6/10], Batch [60/1562], Loss: 0.2829\n",
      "Epoch [6/10], Batch [62/1562], Loss: 0.2340\n",
      "Epoch [6/10], Batch [64/1562], Loss: 0.2904\n",
      "Epoch [6/10], Batch [66/1562], Loss: 0.2800\n",
      "Epoch [6/10], Batch [68/1562], Loss: 0.3086\n",
      "Epoch [6/10], Batch [70/1562], Loss: 0.2773\n",
      "Epoch [6/10], Batch [72/1562], Loss: 0.3317\n",
      "Epoch [6/10], Batch [74/1562], Loss: 0.2696\n",
      "Epoch [6/10], Batch [76/1562], Loss: 0.2870\n",
      "Epoch [6/10], Batch [78/1562], Loss: 0.3108\n",
      "Epoch [6/10], Batch [80/1562], Loss: 0.2887\n",
      "Epoch [6/10], Batch [82/1562], Loss: 0.2991\n",
      "Epoch [6/10], Batch [84/1562], Loss: 0.2550\n",
      "Epoch [6/10], Batch [86/1562], Loss: 0.2566\n",
      "Epoch [6/10], Batch [88/1562], Loss: 0.2963\n",
      "Epoch [6/10], Batch [90/1562], Loss: 0.3073\n",
      "Epoch [6/10], Batch [92/1562], Loss: 0.2802\n",
      "Epoch [6/10], Batch [94/1562], Loss: 0.2802\n",
      "Epoch [6/10], Batch [96/1562], Loss: 0.2814\n",
      "Epoch [6/10], Batch [98/1562], Loss: 0.2907\n",
      "Epoch [6/10], Batch [100/1562], Loss: 0.2916\n",
      "Epoch [6/10], Batch [102/1562], Loss: 0.2899\n",
      "Epoch [6/10], Batch [104/1562], Loss: 0.2718\n",
      "Epoch [6/10], Batch [106/1562], Loss: 0.2773\n",
      "Epoch [6/10], Batch [108/1562], Loss: 0.2940\n",
      "Epoch [6/10], Batch [110/1562], Loss: 0.2905\n",
      "Epoch [6/10], Batch [112/1562], Loss: 0.3182\n",
      "Epoch [6/10], Batch [114/1562], Loss: 0.2833\n",
      "Epoch [6/10], Batch [116/1562], Loss: 0.2622\n",
      "Epoch [6/10], Batch [118/1562], Loss: 0.3161\n",
      "Epoch [6/10], Batch [120/1562], Loss: 0.2668\n",
      "Epoch [6/10], Batch [122/1562], Loss: 0.2748\n",
      "Epoch [6/10], Batch [124/1562], Loss: 0.3065\n",
      "Epoch [6/10], Batch [126/1562], Loss: 0.2918\n",
      "Epoch [6/10], Batch [128/1562], Loss: 0.2976\n",
      "Epoch [6/10], Batch [130/1562], Loss: 0.3027\n",
      "Epoch [6/10], Batch [132/1562], Loss: 0.3049\n",
      "Epoch [6/10], Batch [134/1562], Loss: 0.2778\n",
      "Epoch [6/10], Batch [136/1562], Loss: 0.2834\n",
      "Epoch [6/10], Batch [138/1562], Loss: 0.2986\n",
      "Epoch [6/10], Batch [140/1562], Loss: 0.3001\n",
      "Epoch [6/10], Batch [142/1562], Loss: 0.2944\n",
      "Epoch [6/10], Batch [144/1562], Loss: 0.2951\n",
      "Epoch [6/10], Batch [146/1562], Loss: 0.3128\n",
      "Epoch [6/10], Batch [148/1562], Loss: 0.2624\n",
      "Epoch [6/10], Batch [150/1562], Loss: 0.3049\n",
      "Epoch [6/10], Batch [152/1562], Loss: 0.2748\n",
      "Epoch [6/10], Batch [154/1562], Loss: 0.2872\n",
      "Epoch [6/10], Batch [156/1562], Loss: 0.2858\n",
      "Epoch [6/10], Batch [158/1562], Loss: 0.2911\n",
      "Epoch [6/10], Batch [160/1562], Loss: 0.2937\n",
      "Epoch [6/10], Batch [162/1562], Loss: 0.2629\n",
      "Epoch [6/10], Batch [164/1562], Loss: 0.3042\n",
      "Epoch [6/10], Batch [166/1562], Loss: 0.2617\n",
      "Epoch [6/10], Batch [168/1562], Loss: 0.3171\n",
      "Epoch [6/10], Batch [170/1562], Loss: 0.2702\n",
      "Epoch [6/10], Batch [172/1562], Loss: 0.2842\n",
      "Epoch [6/10], Batch [174/1562], Loss: 0.2655\n",
      "Epoch [6/10], Batch [176/1562], Loss: 0.2797\n",
      "Epoch [6/10], Batch [178/1562], Loss: 0.2904\n",
      "Epoch [6/10], Batch [180/1562], Loss: 0.2856\n",
      "Epoch [6/10], Batch [182/1562], Loss: 0.3308\n",
      "Epoch [6/10], Batch [184/1562], Loss: 0.3042\n",
      "Epoch [6/10], Batch [186/1562], Loss: 0.2714\n",
      "Epoch [6/10], Batch [188/1562], Loss: 0.3000\n",
      "Epoch [6/10], Batch [190/1562], Loss: 0.2740\n",
      "Epoch [6/10], Batch [192/1562], Loss: 0.2973\n",
      "Epoch [6/10], Batch [194/1562], Loss: 0.3116\n",
      "Epoch [6/10], Batch [196/1562], Loss: 0.2844\n",
      "Epoch [6/10], Batch [198/1562], Loss: 0.3078\n",
      "Epoch [6/10], Batch [200/1562], Loss: 0.2772\n",
      "Epoch [6/10], Batch [202/1562], Loss: 0.2551\n",
      "Epoch [6/10], Batch [204/1562], Loss: 0.2966\n",
      "Epoch [6/10], Batch [206/1562], Loss: 0.2671\n",
      "Epoch [6/10], Batch [208/1562], Loss: 0.3042\n",
      "Epoch [6/10], Batch [210/1562], Loss: 0.2320\n",
      "Epoch [6/10], Batch [212/1562], Loss: 0.3046\n",
      "Epoch [6/10], Batch [214/1562], Loss: 0.2602\n",
      "Epoch [6/10], Batch [216/1562], Loss: 0.3012\n",
      "Epoch [6/10], Batch [218/1562], Loss: 0.2707\n",
      "Epoch [6/10], Batch [220/1562], Loss: 0.3089\n",
      "Epoch [6/10], Batch [222/1562], Loss: 0.3232\n",
      "Epoch [6/10], Batch [224/1562], Loss: 0.2699\n",
      "Epoch [6/10], Batch [226/1562], Loss: 0.2750\n",
      "Epoch [6/10], Batch [228/1562], Loss: 0.2815\n",
      "Epoch [6/10], Batch [230/1562], Loss: 0.2600\n",
      "Epoch [6/10], Batch [232/1562], Loss: 0.2653\n",
      "Epoch [6/10], Batch [234/1562], Loss: 0.2410\n",
      "Epoch [6/10], Batch [236/1562], Loss: 0.2745\n",
      "Epoch [6/10], Batch [238/1562], Loss: 0.3006\n",
      "Epoch [6/10], Batch [240/1562], Loss: 0.3059\n",
      "Epoch [6/10], Batch [242/1562], Loss: 0.2649\n",
      "Epoch [6/10], Batch [244/1562], Loss: 0.2820\n",
      "Epoch [6/10], Batch [246/1562], Loss: 0.3050\n",
      "Epoch [6/10], Batch [248/1562], Loss: 0.2890\n",
      "Epoch [6/10], Batch [250/1562], Loss: 0.3060\n",
      "Epoch [6/10], Batch [252/1562], Loss: 0.2711\n",
      "Epoch [6/10], Batch [254/1562], Loss: 0.3435\n",
      "Epoch [6/10], Batch [256/1562], Loss: 0.3203\n",
      "Epoch [6/10], Batch [258/1562], Loss: 0.2942\n",
      "Epoch [6/10], Batch [260/1562], Loss: 0.2530\n",
      "Epoch [6/10], Batch [262/1562], Loss: 0.2878\n",
      "Epoch [6/10], Batch [264/1562], Loss: 0.2848\n",
      "Epoch [6/10], Batch [266/1562], Loss: 0.2511\n",
      "Epoch [6/10], Batch [268/1562], Loss: 0.2929\n",
      "Epoch [6/10], Batch [270/1562], Loss: 0.2883\n",
      "Epoch [6/10], Batch [272/1562], Loss: 0.2901\n",
      "Epoch [6/10], Batch [274/1562], Loss: 0.2491\n",
      "Epoch [6/10], Batch [276/1562], Loss: 0.2568\n",
      "Epoch [6/10], Batch [278/1562], Loss: 0.2765\n",
      "Epoch [6/10], Batch [280/1562], Loss: 0.2764\n",
      "Epoch [6/10], Batch [282/1562], Loss: 0.2740\n",
      "Epoch [6/10], Batch [284/1562], Loss: 0.2781\n",
      "Epoch [6/10], Batch [286/1562], Loss: 0.3046\n",
      "Epoch [6/10], Batch [288/1562], Loss: 0.3272\n",
      "Epoch [6/10], Batch [290/1562], Loss: 0.2747\n",
      "Epoch [6/10], Batch [292/1562], Loss: 0.2958\n",
      "Epoch [6/10], Batch [294/1562], Loss: 0.2992\n",
      "Epoch [6/10], Batch [296/1562], Loss: 0.3421\n",
      "Epoch [6/10], Batch [298/1562], Loss: 0.2727\n",
      "Epoch [6/10], Batch [300/1562], Loss: 0.2880\n",
      "Epoch [6/10], Batch [302/1562], Loss: 0.3199\n",
      "Epoch [6/10], Batch [304/1562], Loss: 0.2979\n",
      "Epoch [6/10], Batch [306/1562], Loss: 0.2705\n",
      "Epoch [6/10], Batch [308/1562], Loss: 0.3002\n",
      "Epoch [6/10], Batch [310/1562], Loss: 0.3481\n",
      "Epoch [6/10], Batch [312/1562], Loss: 0.2856\n",
      "Epoch [6/10], Batch [314/1562], Loss: 0.3050\n",
      "Epoch [6/10], Batch [316/1562], Loss: 0.2939\n",
      "Epoch [6/10], Batch [318/1562], Loss: 0.2697\n",
      "Epoch [6/10], Batch [320/1562], Loss: 0.2925\n",
      "Epoch [6/10], Batch [322/1562], Loss: 0.2689\n",
      "Epoch [6/10], Batch [324/1562], Loss: 0.2690\n",
      "Epoch [6/10], Batch [326/1562], Loss: 0.2930\n",
      "Epoch [6/10], Batch [328/1562], Loss: 0.3055\n",
      "Epoch [6/10], Batch [330/1562], Loss: 0.3045\n",
      "Epoch [6/10], Batch [332/1562], Loss: 0.2586\n",
      "Epoch [6/10], Batch [334/1562], Loss: 0.2561\n",
      "Epoch [6/10], Batch [336/1562], Loss: 0.2653\n",
      "Epoch [6/10], Batch [338/1562], Loss: 0.2986\n",
      "Epoch [6/10], Batch [340/1562], Loss: 0.3149\n",
      "Epoch [6/10], Batch [342/1562], Loss: 0.2802\n",
      "Epoch [6/10], Batch [344/1562], Loss: 0.2832\n",
      "Epoch [6/10], Batch [346/1562], Loss: 0.2940\n",
      "Epoch [6/10], Batch [348/1562], Loss: 0.2702\n",
      "Epoch [6/10], Batch [350/1562], Loss: 0.2919\n",
      "Epoch [6/10], Batch [352/1562], Loss: 0.2779\n",
      "Epoch [6/10], Batch [354/1562], Loss: 0.2612\n",
      "Epoch [6/10], Batch [356/1562], Loss: 0.2799\n",
      "Epoch [6/10], Batch [358/1562], Loss: 0.2887\n",
      "Epoch [6/10], Batch [360/1562], Loss: 0.3019\n",
      "Epoch [6/10], Batch [362/1562], Loss: 0.3092\n",
      "Epoch [6/10], Batch [364/1562], Loss: 0.2875\n",
      "Epoch [6/10], Batch [366/1562], Loss: 0.3355\n",
      "Epoch [6/10], Batch [368/1562], Loss: 0.3061\n",
      "Epoch [6/10], Batch [370/1562], Loss: 0.2872\n",
      "Epoch [6/10], Batch [372/1562], Loss: 0.2977\n",
      "Epoch [6/10], Batch [374/1562], Loss: 0.2892\n",
      "Epoch [6/10], Batch [376/1562], Loss: 0.2752\n",
      "Epoch [6/10], Batch [378/1562], Loss: 0.3126\n",
      "Epoch [6/10], Batch [380/1562], Loss: 0.2980\n",
      "Epoch [6/10], Batch [382/1562], Loss: 0.2697\n",
      "Epoch [6/10], Batch [384/1562], Loss: 0.2948\n",
      "Epoch [6/10], Batch [386/1562], Loss: 0.2886\n",
      "Epoch [6/10], Batch [388/1562], Loss: 0.2472\n",
      "Epoch [6/10], Batch [390/1562], Loss: 0.2262\n",
      "Epoch [6/10], Batch [392/1562], Loss: 0.2651\n",
      "Epoch [6/10], Batch [394/1562], Loss: 0.2965\n",
      "Epoch [6/10], Batch [396/1562], Loss: 0.2921\n",
      "Epoch [6/10], Batch [398/1562], Loss: 0.2572\n",
      "Epoch [6/10], Batch [400/1562], Loss: 0.2916\n",
      "Epoch [6/10], Batch [402/1562], Loss: 0.2614\n",
      "Epoch [6/10], Batch [404/1562], Loss: 0.2794\n",
      "Epoch [6/10], Batch [406/1562], Loss: 0.2838\n",
      "Epoch [6/10], Batch [408/1562], Loss: 0.2885\n",
      "Epoch [6/10], Batch [410/1562], Loss: 0.2720\n",
      "Epoch [6/10], Batch [412/1562], Loss: 0.2667\n",
      "Epoch [6/10], Batch [414/1562], Loss: 0.2852\n",
      "Epoch [6/10], Batch [416/1562], Loss: 0.2753\n",
      "Epoch [6/10], Batch [418/1562], Loss: 0.2872\n",
      "Epoch [6/10], Batch [420/1562], Loss: 0.2817\n",
      "Epoch [6/10], Batch [422/1562], Loss: 0.3143\n",
      "Epoch [6/10], Batch [424/1562], Loss: 0.2872\n",
      "Epoch [6/10], Batch [426/1562], Loss: 0.2545\n",
      "Epoch [6/10], Batch [428/1562], Loss: 0.3129\n",
      "Epoch [6/10], Batch [430/1562], Loss: 0.2894\n",
      "Epoch [6/10], Batch [432/1562], Loss: 0.2628\n",
      "Epoch [6/10], Batch [434/1562], Loss: 0.2897\n",
      "Epoch [6/10], Batch [436/1562], Loss: 0.2643\n",
      "Epoch [6/10], Batch [438/1562], Loss: 0.2633\n",
      "Epoch [6/10], Batch [440/1562], Loss: 0.2560\n",
      "Epoch [6/10], Batch [442/1562], Loss: 0.2831\n",
      "Epoch [6/10], Batch [444/1562], Loss: 0.2885\n",
      "Epoch [6/10], Batch [446/1562], Loss: 0.2484\n",
      "Epoch [6/10], Batch [448/1562], Loss: 0.3055\n",
      "Epoch [6/10], Batch [450/1562], Loss: 0.2691\n",
      "Epoch [6/10], Batch [452/1562], Loss: 0.2930\n",
      "Epoch [6/10], Batch [454/1562], Loss: 0.2810\n",
      "Epoch [6/10], Batch [456/1562], Loss: 0.2775\n",
      "Epoch [6/10], Batch [458/1562], Loss: 0.2681\n",
      "Epoch [6/10], Batch [460/1562], Loss: 0.2871\n",
      "Epoch [6/10], Batch [462/1562], Loss: 0.2963\n",
      "Epoch [6/10], Batch [464/1562], Loss: 0.3476\n",
      "Epoch [6/10], Batch [466/1562], Loss: 0.2801\n",
      "Epoch [6/10], Batch [468/1562], Loss: 0.3453\n",
      "Epoch [6/10], Batch [470/1562], Loss: 0.2962\n",
      "Epoch [6/10], Batch [472/1562], Loss: 0.2666\n",
      "Epoch [6/10], Batch [474/1562], Loss: 0.2920\n",
      "Epoch [6/10], Batch [476/1562], Loss: 0.2649\n",
      "Epoch [6/10], Batch [478/1562], Loss: 0.2924\n",
      "Epoch [6/10], Batch [480/1562], Loss: 0.2799\n",
      "Epoch [6/10], Batch [482/1562], Loss: 0.2816\n",
      "Epoch [6/10], Batch [484/1562], Loss: 0.3203\n",
      "Epoch [6/10], Batch [486/1562], Loss: 0.2539\n",
      "Epoch [6/10], Batch [488/1562], Loss: 0.3039\n",
      "Epoch [6/10], Batch [490/1562], Loss: 0.3269\n",
      "Epoch [6/10], Batch [492/1562], Loss: 0.2376\n",
      "Epoch [6/10], Batch [494/1562], Loss: 0.2655\n",
      "Epoch [6/10], Batch [496/1562], Loss: 0.2799\n",
      "Epoch [6/10], Batch [498/1562], Loss: 0.2962\n",
      "Epoch [6/10], Batch [500/1562], Loss: 0.2746\n",
      "Epoch [6/10], Batch [502/1562], Loss: 0.2749\n",
      "Epoch [6/10], Batch [504/1562], Loss: 0.2913\n",
      "Epoch [6/10], Batch [506/1562], Loss: 0.2873\n",
      "Epoch [6/10], Batch [508/1562], Loss: 0.2888\n",
      "Epoch [6/10], Batch [510/1562], Loss: 0.2870\n",
      "Epoch [6/10], Batch [512/1562], Loss: 0.2926\n",
      "Epoch [6/10], Batch [514/1562], Loss: 0.3080\n",
      "Epoch [6/10], Batch [516/1562], Loss: 0.2719\n",
      "Epoch [6/10], Batch [518/1562], Loss: 0.2923\n",
      "Epoch [6/10], Batch [520/1562], Loss: 0.2930\n",
      "Epoch [6/10], Batch [522/1562], Loss: 0.2613\n",
      "Epoch [6/10], Batch [524/1562], Loss: 0.3156\n",
      "Epoch [6/10], Batch [526/1562], Loss: 0.3134\n",
      "Epoch [6/10], Batch [528/1562], Loss: 0.3103\n",
      "Epoch [6/10], Batch [530/1562], Loss: 0.2945\n",
      "Epoch [6/10], Batch [532/1562], Loss: 0.2941\n",
      "Epoch [6/10], Batch [534/1562], Loss: 0.3070\n",
      "Epoch [6/10], Batch [536/1562], Loss: 0.2747\n",
      "Epoch [6/10], Batch [538/1562], Loss: 0.3026\n",
      "Epoch [6/10], Batch [540/1562], Loss: 0.2646\n",
      "Epoch [6/10], Batch [542/1562], Loss: 0.2667\n",
      "Epoch [6/10], Batch [544/1562], Loss: 0.2719\n",
      "Epoch [6/10], Batch [546/1562], Loss: 0.2724\n",
      "Epoch [6/10], Batch [548/1562], Loss: 0.2935\n",
      "Epoch [6/10], Batch [550/1562], Loss: 0.2468\n",
      "Epoch [6/10], Batch [552/1562], Loss: 0.2574\n",
      "Epoch [6/10], Batch [554/1562], Loss: 0.2672\n",
      "Epoch [6/10], Batch [556/1562], Loss: 0.2842\n",
      "Epoch [6/10], Batch [558/1562], Loss: 0.2738\n",
      "Epoch [6/10], Batch [560/1562], Loss: 0.2655\n",
      "Epoch [6/10], Batch [562/1562], Loss: 0.2820\n",
      "Epoch [6/10], Batch [564/1562], Loss: 0.2594\n",
      "Epoch [6/10], Batch [566/1562], Loss: 0.3071\n",
      "Epoch [6/10], Batch [568/1562], Loss: 0.3457\n",
      "Epoch [6/10], Batch [570/1562], Loss: 0.3130\n",
      "Epoch [6/10], Batch [572/1562], Loss: 0.2648\n",
      "Epoch [6/10], Batch [574/1562], Loss: 0.2555\n",
      "Epoch [6/10], Batch [576/1562], Loss: 0.2683\n",
      "Epoch [6/10], Batch [578/1562], Loss: 0.2881\n",
      "Epoch [6/10], Batch [580/1562], Loss: 0.2745\n",
      "Epoch [6/10], Batch [582/1562], Loss: 0.3049\n",
      "Epoch [6/10], Batch [584/1562], Loss: 0.2948\n",
      "Epoch [6/10], Batch [586/1562], Loss: 0.2611\n",
      "Epoch [6/10], Batch [588/1562], Loss: 0.2671\n",
      "Epoch [6/10], Batch [590/1562], Loss: 0.2708\n",
      "Epoch [6/10], Batch [592/1562], Loss: 0.3016\n",
      "Epoch [6/10], Batch [594/1562], Loss: 0.2819\n",
      "Epoch [6/10], Batch [596/1562], Loss: 0.3060\n",
      "Epoch [6/10], Batch [598/1562], Loss: 0.2847\n",
      "Epoch [6/10], Batch [600/1562], Loss: 0.2887\n",
      "Epoch [6/10], Batch [602/1562], Loss: 0.3150\n",
      "Epoch [6/10], Batch [604/1562], Loss: 0.3215\n",
      "Epoch [6/10], Batch [606/1562], Loss: 0.2542\n",
      "Epoch [6/10], Batch [608/1562], Loss: 0.3232\n",
      "Epoch [6/10], Batch [610/1562], Loss: 0.2809\n",
      "Epoch [6/10], Batch [612/1562], Loss: 0.3029\n",
      "Epoch [6/10], Batch [614/1562], Loss: 0.2754\n",
      "Epoch [6/10], Batch [616/1562], Loss: 0.2875\n",
      "Epoch [6/10], Batch [618/1562], Loss: 0.2804\n",
      "Epoch [6/10], Batch [620/1562], Loss: 0.2736\n",
      "Epoch [6/10], Batch [622/1562], Loss: 0.3126\n",
      "Epoch [6/10], Batch [624/1562], Loss: 0.2480\n",
      "Epoch [6/10], Batch [626/1562], Loss: 0.3214\n",
      "Epoch [6/10], Batch [628/1562], Loss: 0.2908\n",
      "Epoch [6/10], Batch [630/1562], Loss: 0.2761\n",
      "Epoch [6/10], Batch [632/1562], Loss: 0.3513\n",
      "Epoch [6/10], Batch [634/1562], Loss: 0.2978\n",
      "Epoch [6/10], Batch [636/1562], Loss: 0.3042\n",
      "Epoch [6/10], Batch [638/1562], Loss: 0.2910\n",
      "Epoch [6/10], Batch [640/1562], Loss: 0.2806\n",
      "Epoch [6/10], Batch [642/1562], Loss: 0.3204\n",
      "Epoch [6/10], Batch [644/1562], Loss: 0.2962\n",
      "Epoch [6/10], Batch [646/1562], Loss: 0.2447\n",
      "Epoch [6/10], Batch [648/1562], Loss: 0.2566\n",
      "Epoch [6/10], Batch [650/1562], Loss: 0.3140\n",
      "Epoch [6/10], Batch [652/1562], Loss: 0.2777\n",
      "Epoch [6/10], Batch [654/1562], Loss: 0.2879\n",
      "Epoch [6/10], Batch [656/1562], Loss: 0.2275\n",
      "Epoch [6/10], Batch [658/1562], Loss: 0.3035\n",
      "Epoch [6/10], Batch [660/1562], Loss: 0.2538\n",
      "Epoch [6/10], Batch [662/1562], Loss: 0.3072\n",
      "Epoch [6/10], Batch [664/1562], Loss: 0.3020\n",
      "Epoch [6/10], Batch [666/1562], Loss: 0.2679\n",
      "Epoch [6/10], Batch [668/1562], Loss: 0.2580\n",
      "Epoch [6/10], Batch [670/1562], Loss: 0.2955\n",
      "Epoch [6/10], Batch [672/1562], Loss: 0.2739\n",
      "Epoch [6/10], Batch [674/1562], Loss: 0.2565\n",
      "Epoch [6/10], Batch [676/1562], Loss: 0.2926\n",
      "Epoch [6/10], Batch [678/1562], Loss: 0.2688\n",
      "Epoch [6/10], Batch [680/1562], Loss: 0.2658\n",
      "Epoch [6/10], Batch [682/1562], Loss: 0.2573\n",
      "Epoch [6/10], Batch [684/1562], Loss: 0.3317\n",
      "Epoch [6/10], Batch [686/1562], Loss: 0.2805\n",
      "Epoch [6/10], Batch [688/1562], Loss: 0.3006\n",
      "Epoch [6/10], Batch [690/1562], Loss: 0.3304\n",
      "Epoch [6/10], Batch [692/1562], Loss: 0.3448\n",
      "Epoch [6/10], Batch [694/1562], Loss: 0.3219\n",
      "Epoch [6/10], Batch [696/1562], Loss: 0.2823\n",
      "Epoch [6/10], Batch [698/1562], Loss: 0.2756\n",
      "Epoch [6/10], Batch [700/1562], Loss: 0.2955\n",
      "Epoch [6/10], Batch [702/1562], Loss: 0.3028\n",
      "Epoch [6/10], Batch [704/1562], Loss: 0.2976\n",
      "Epoch [6/10], Batch [706/1562], Loss: 0.2479\n",
      "Epoch [6/10], Batch [708/1562], Loss: 0.2616\n",
      "Epoch [6/10], Batch [710/1562], Loss: 0.3093\n",
      "Epoch [6/10], Batch [712/1562], Loss: 0.3082\n",
      "Epoch [6/10], Batch [714/1562], Loss: 0.3164\n",
      "Epoch [6/10], Batch [716/1562], Loss: 0.2719\n",
      "Epoch [6/10], Batch [718/1562], Loss: 0.2629\n",
      "Epoch [6/10], Batch [720/1562], Loss: 0.3198\n",
      "Epoch [6/10], Batch [722/1562], Loss: 0.2822\n",
      "Epoch [6/10], Batch [724/1562], Loss: 0.2879\n",
      "Epoch [6/10], Batch [726/1562], Loss: 0.2757\n",
      "Epoch [6/10], Batch [728/1562], Loss: 0.2854\n",
      "Epoch [6/10], Batch [730/1562], Loss: 0.3327\n",
      "Epoch [6/10], Batch [732/1562], Loss: 0.3083\n",
      "Epoch [6/10], Batch [734/1562], Loss: 0.2906\n",
      "Epoch [6/10], Batch [736/1562], Loss: 0.3140\n",
      "Epoch [6/10], Batch [738/1562], Loss: 0.2786\n",
      "Epoch [6/10], Batch [740/1562], Loss: 0.2834\n",
      "Epoch [6/10], Batch [742/1562], Loss: 0.2633\n",
      "Epoch [6/10], Batch [744/1562], Loss: 0.2815\n",
      "Epoch [6/10], Batch [746/1562], Loss: 0.2844\n",
      "Epoch [6/10], Batch [748/1562], Loss: 0.2791\n",
      "Epoch [6/10], Batch [750/1562], Loss: 0.3316\n",
      "Epoch [6/10], Batch [752/1562], Loss: 0.2457\n",
      "Epoch [6/10], Batch [754/1562], Loss: 0.2562\n",
      "Epoch [6/10], Batch [756/1562], Loss: 0.2780\n",
      "Epoch [6/10], Batch [758/1562], Loss: 0.2877\n",
      "Epoch [6/10], Batch [760/1562], Loss: 0.2783\n",
      "Epoch [6/10], Batch [762/1562], Loss: 0.3209\n",
      "Epoch [6/10], Batch [764/1562], Loss: 0.2554\n",
      "Epoch [6/10], Batch [766/1562], Loss: 0.3110\n",
      "Epoch [6/10], Batch [768/1562], Loss: 0.2943\n",
      "Epoch [6/10], Batch [770/1562], Loss: 0.3308\n",
      "Epoch [6/10], Batch [772/1562], Loss: 0.2902\n",
      "Epoch [6/10], Batch [774/1562], Loss: 0.3089\n",
      "Epoch [6/10], Batch [776/1562], Loss: 0.2459\n",
      "Epoch [6/10], Batch [778/1562], Loss: 0.2923\n",
      "Epoch [6/10], Batch [780/1562], Loss: 0.3209\n",
      "Epoch [6/10], Batch [782/1562], Loss: 0.2627\n",
      "Epoch [6/10], Batch [784/1562], Loss: 0.2755\n",
      "Epoch [6/10], Batch [786/1562], Loss: 0.2886\n",
      "Epoch [6/10], Batch [788/1562], Loss: 0.2427\n",
      "Epoch [6/10], Batch [790/1562], Loss: 0.3313\n",
      "Epoch [6/10], Batch [792/1562], Loss: 0.3185\n",
      "Epoch [6/10], Batch [794/1562], Loss: 0.3355\n",
      "Epoch [6/10], Batch [796/1562], Loss: 0.3146\n",
      "Epoch [6/10], Batch [798/1562], Loss: 0.2829\n",
      "Epoch [6/10], Batch [800/1562], Loss: 0.2791\n",
      "Epoch [6/10], Batch [802/1562], Loss: 0.3258\n",
      "Epoch [6/10], Batch [804/1562], Loss: 0.2975\n",
      "Epoch [6/10], Batch [806/1562], Loss: 0.2684\n",
      "Epoch [6/10], Batch [808/1562], Loss: 0.2978\n",
      "Epoch [6/10], Batch [810/1562], Loss: 0.2875\n",
      "Epoch [6/10], Batch [812/1562], Loss: 0.2774\n",
      "Epoch [6/10], Batch [814/1562], Loss: 0.2906\n",
      "Epoch [6/10], Batch [816/1562], Loss: 0.2982\n",
      "Epoch [6/10], Batch [818/1562], Loss: 0.2987\n",
      "Epoch [6/10], Batch [820/1562], Loss: 0.3204\n",
      "Epoch [6/10], Batch [822/1562], Loss: 0.2593\n",
      "Epoch [6/10], Batch [824/1562], Loss: 0.2714\n",
      "Epoch [6/10], Batch [826/1562], Loss: 0.3189\n",
      "Epoch [6/10], Batch [828/1562], Loss: 0.2961\n",
      "Epoch [6/10], Batch [830/1562], Loss: 0.2810\n",
      "Epoch [6/10], Batch [832/1562], Loss: 0.2537\n",
      "Epoch [6/10], Batch [834/1562], Loss: 0.2806\n",
      "Epoch [6/10], Batch [836/1562], Loss: 0.2968\n",
      "Epoch [6/10], Batch [838/1562], Loss: 0.2681\n",
      "Epoch [6/10], Batch [840/1562], Loss: 0.3151\n",
      "Epoch [6/10], Batch [842/1562], Loss: 0.3227\n",
      "Epoch [6/10], Batch [844/1562], Loss: 0.2727\n",
      "Epoch [6/10], Batch [846/1562], Loss: 0.3201\n",
      "Epoch [6/10], Batch [848/1562], Loss: 0.2970\n",
      "Epoch [6/10], Batch [850/1562], Loss: 0.3032\n",
      "Epoch [6/10], Batch [852/1562], Loss: 0.2438\n",
      "Epoch [6/10], Batch [854/1562], Loss: 0.2936\n",
      "Epoch [6/10], Batch [856/1562], Loss: 0.3157\n",
      "Epoch [6/10], Batch [858/1562], Loss: 0.2410\n",
      "Epoch [6/10], Batch [860/1562], Loss: 0.2711\n",
      "Epoch [6/10], Batch [862/1562], Loss: 0.2644\n",
      "Epoch [6/10], Batch [864/1562], Loss: 0.2732\n",
      "Epoch [6/10], Batch [866/1562], Loss: 0.2810\n",
      "Epoch [6/10], Batch [868/1562], Loss: 0.2609\n",
      "Epoch [6/10], Batch [870/1562], Loss: 0.2827\n",
      "Epoch [6/10], Batch [872/1562], Loss: 0.2890\n",
      "Epoch [6/10], Batch [874/1562], Loss: 0.3329\n",
      "Epoch [6/10], Batch [876/1562], Loss: 0.2990\n",
      "Epoch [6/10], Batch [878/1562], Loss: 0.3111\n",
      "Epoch [6/10], Batch [880/1562], Loss: 0.3269\n",
      "Epoch [6/10], Batch [882/1562], Loss: 0.2629\n",
      "Epoch [6/10], Batch [884/1562], Loss: 0.2532\n",
      "Epoch [6/10], Batch [886/1562], Loss: 0.2495\n",
      "Epoch [6/10], Batch [888/1562], Loss: 0.2865\n",
      "Epoch [6/10], Batch [890/1562], Loss: 0.2618\n",
      "Epoch [6/10], Batch [892/1562], Loss: 0.3180\n",
      "Epoch [6/10], Batch [894/1562], Loss: 0.2610\n",
      "Epoch [6/10], Batch [896/1562], Loss: 0.2840\n",
      "Epoch [6/10], Batch [898/1562], Loss: 0.2962\n",
      "Epoch [6/10], Batch [900/1562], Loss: 0.3088\n",
      "Epoch [6/10], Batch [902/1562], Loss: 0.3294\n",
      "Epoch [6/10], Batch [904/1562], Loss: 0.2864\n",
      "Epoch [6/10], Batch [906/1562], Loss: 0.2824\n",
      "Epoch [6/10], Batch [908/1562], Loss: 0.3076\n",
      "Epoch [6/10], Batch [910/1562], Loss: 0.2992\n",
      "Epoch [6/10], Batch [912/1562], Loss: 0.3250\n",
      "Epoch [6/10], Batch [914/1562], Loss: 0.3164\n",
      "Epoch [6/10], Batch [916/1562], Loss: 0.2736\n",
      "Epoch [6/10], Batch [918/1562], Loss: 0.3066\n",
      "Epoch [6/10], Batch [920/1562], Loss: 0.3100\n",
      "Epoch [6/10], Batch [922/1562], Loss: 0.2680\n",
      "Epoch [6/10], Batch [924/1562], Loss: 0.2608\n",
      "Epoch [6/10], Batch [926/1562], Loss: 0.2631\n",
      "Epoch [6/10], Batch [928/1562], Loss: 0.2911\n",
      "Epoch [6/10], Batch [930/1562], Loss: 0.2465\n",
      "Epoch [6/10], Batch [932/1562], Loss: 0.3168\n",
      "Epoch [6/10], Batch [934/1562], Loss: 0.2906\n",
      "Epoch [6/10], Batch [936/1562], Loss: 0.2985\n",
      "Epoch [6/10], Batch [938/1562], Loss: 0.2743\n",
      "Epoch [6/10], Batch [940/1562], Loss: 0.2820\n",
      "Epoch [6/10], Batch [942/1562], Loss: 0.2867\n",
      "Epoch [6/10], Batch [944/1562], Loss: 0.2624\n",
      "Epoch [6/10], Batch [946/1562], Loss: 0.2809\n",
      "Epoch [6/10], Batch [948/1562], Loss: 0.3112\n",
      "Epoch [6/10], Batch [950/1562], Loss: 0.3230\n",
      "Epoch [6/10], Batch [952/1562], Loss: 0.2625\n",
      "Epoch [6/10], Batch [954/1562], Loss: 0.3222\n",
      "Epoch [6/10], Batch [956/1562], Loss: 0.3139\n",
      "Epoch [6/10], Batch [958/1562], Loss: 0.3101\n",
      "Epoch [6/10], Batch [960/1562], Loss: 0.3002\n",
      "Epoch [6/10], Batch [962/1562], Loss: 0.2912\n",
      "Epoch [6/10], Batch [964/1562], Loss: 0.3296\n",
      "Epoch [6/10], Batch [966/1562], Loss: 0.2757\n",
      "Epoch [6/10], Batch [968/1562], Loss: 0.2641\n",
      "Epoch [6/10], Batch [970/1562], Loss: 0.2981\n",
      "Epoch [6/10], Batch [972/1562], Loss: 0.2723\n",
      "Epoch [6/10], Batch [974/1562], Loss: 0.2837\n",
      "Epoch [6/10], Batch [976/1562], Loss: 0.2237\n",
      "Epoch [6/10], Batch [978/1562], Loss: 0.3063\n",
      "Epoch [6/10], Batch [980/1562], Loss: 0.2926\n",
      "Epoch [6/10], Batch [982/1562], Loss: 0.2954\n",
      "Epoch [6/10], Batch [984/1562], Loss: 0.2968\n",
      "Epoch [6/10], Batch [986/1562], Loss: 0.3216\n",
      "Epoch [6/10], Batch [988/1562], Loss: 0.3235\n",
      "Epoch [6/10], Batch [990/1562], Loss: 0.2619\n",
      "Epoch [6/10], Batch [992/1562], Loss: 0.2813\n",
      "Epoch [6/10], Batch [994/1562], Loss: 0.2742\n",
      "Epoch [6/10], Batch [996/1562], Loss: 0.3060\n",
      "Epoch [6/10], Batch [998/1562], Loss: 0.2486\n",
      "Epoch [6/10], Batch [1000/1562], Loss: 0.3250\n",
      "Epoch [6/10], Batch [1002/1562], Loss: 0.3736\n",
      "Epoch [6/10], Batch [1004/1562], Loss: 0.3125\n",
      "Epoch [6/10], Batch [1006/1562], Loss: 0.2716\n",
      "Epoch [6/10], Batch [1008/1562], Loss: 0.2815\n",
      "Epoch [6/10], Batch [1010/1562], Loss: 0.2795\n",
      "Epoch [6/10], Batch [1012/1562], Loss: 0.3039\n",
      "Epoch [6/10], Batch [1014/1562], Loss: 0.2895\n",
      "Epoch [6/10], Batch [1016/1562], Loss: 0.2918\n",
      "Epoch [6/10], Batch [1018/1562], Loss: 0.2888\n",
      "Epoch [6/10], Batch [1020/1562], Loss: 0.2836\n",
      "Epoch [6/10], Batch [1022/1562], Loss: 0.3235\n",
      "Epoch [6/10], Batch [1024/1562], Loss: 0.2474\n",
      "Epoch [6/10], Batch [1026/1562], Loss: 0.3038\n",
      "Epoch [6/10], Batch [1028/1562], Loss: 0.3058\n",
      "Epoch [6/10], Batch [1030/1562], Loss: 0.2649\n",
      "Epoch [6/10], Batch [1032/1562], Loss: 0.2848\n",
      "Epoch [6/10], Batch [1034/1562], Loss: 0.2559\n",
      "Epoch [6/10], Batch [1036/1562], Loss: 0.2831\n",
      "Epoch [6/10], Batch [1038/1562], Loss: 0.3179\n",
      "Epoch [6/10], Batch [1040/1562], Loss: 0.2854\n",
      "Epoch [6/10], Batch [1042/1562], Loss: 0.3044\n",
      "Epoch [6/10], Batch [1044/1562], Loss: 0.2605\n",
      "Epoch [6/10], Batch [1046/1562], Loss: 0.2632\n",
      "Epoch [6/10], Batch [1048/1562], Loss: 0.2785\n",
      "Epoch [6/10], Batch [1050/1562], Loss: 0.2618\n",
      "Epoch [6/10], Batch [1052/1562], Loss: 0.2815\n",
      "Epoch [6/10], Batch [1054/1562], Loss: 0.2980\n",
      "Epoch [6/10], Batch [1056/1562], Loss: 0.2657\n",
      "Epoch [6/10], Batch [1058/1562], Loss: 0.3078\n",
      "Epoch [6/10], Batch [1060/1562], Loss: 0.3129\n",
      "Epoch [6/10], Batch [1062/1562], Loss: 0.2443\n",
      "Epoch [6/10], Batch [1064/1562], Loss: 0.3177\n",
      "Epoch [6/10], Batch [1066/1562], Loss: 0.2710\n",
      "Epoch [6/10], Batch [1068/1562], Loss: 0.3096\n",
      "Epoch [6/10], Batch [1070/1562], Loss: 0.3093\n",
      "Epoch [6/10], Batch [1072/1562], Loss: 0.2758\n",
      "Epoch [6/10], Batch [1074/1562], Loss: 0.2964\n",
      "Epoch [6/10], Batch [1076/1562], Loss: 0.2728\n",
      "Epoch [6/10], Batch [1078/1562], Loss: 0.3245\n",
      "Epoch [6/10], Batch [1080/1562], Loss: 0.2849\n",
      "Epoch [6/10], Batch [1082/1562], Loss: 0.3094\n",
      "Epoch [6/10], Batch [1084/1562], Loss: 0.2537\n",
      "Epoch [6/10], Batch [1086/1562], Loss: 0.3198\n",
      "Epoch [6/10], Batch [1088/1562], Loss: 0.2909\n",
      "Epoch [6/10], Batch [1090/1562], Loss: 0.3167\n",
      "Epoch [6/10], Batch [1092/1562], Loss: 0.2811\n",
      "Epoch [6/10], Batch [1094/1562], Loss: 0.2528\n",
      "Epoch [6/10], Batch [1096/1562], Loss: 0.2931\n",
      "Epoch [6/10], Batch [1098/1562], Loss: 0.2903\n",
      "Epoch [6/10], Batch [1100/1562], Loss: 0.2774\n",
      "Epoch [6/10], Batch [1102/1562], Loss: 0.3239\n",
      "Epoch [6/10], Batch [1104/1562], Loss: 0.2882\n",
      "Epoch [6/10], Batch [1106/1562], Loss: 0.2926\n",
      "Epoch [6/10], Batch [1108/1562], Loss: 0.2799\n",
      "Epoch [6/10], Batch [1110/1562], Loss: 0.2747\n",
      "Epoch [6/10], Batch [1112/1562], Loss: 0.2862\n",
      "Epoch [6/10], Batch [1114/1562], Loss: 0.2875\n",
      "Epoch [6/10], Batch [1116/1562], Loss: 0.2937\n",
      "Epoch [6/10], Batch [1118/1562], Loss: 0.2625\n",
      "Epoch [6/10], Batch [1120/1562], Loss: 0.3006\n",
      "Epoch [6/10], Batch [1122/1562], Loss: 0.2731\n",
      "Epoch [6/10], Batch [1124/1562], Loss: 0.2782\n",
      "Epoch [6/10], Batch [1126/1562], Loss: 0.2593\n",
      "Epoch [6/10], Batch [1128/1562], Loss: 0.2788\n",
      "Epoch [6/10], Batch [1130/1562], Loss: 0.2866\n",
      "Epoch [6/10], Batch [1132/1562], Loss: 0.3060\n",
      "Epoch [6/10], Batch [1134/1562], Loss: 0.3328\n",
      "Epoch [6/10], Batch [1136/1562], Loss: 0.3081\n",
      "Epoch [6/10], Batch [1138/1562], Loss: 0.2720\n",
      "Epoch [6/10], Batch [1140/1562], Loss: 0.2818\n",
      "Epoch [6/10], Batch [1142/1562], Loss: 0.2799\n",
      "Epoch [6/10], Batch [1144/1562], Loss: 0.2886\n",
      "Epoch [6/10], Batch [1146/1562], Loss: 0.2880\n",
      "Epoch [6/10], Batch [1148/1562], Loss: 0.2971\n",
      "Epoch [6/10], Batch [1150/1562], Loss: 0.2899\n",
      "Epoch [6/10], Batch [1152/1562], Loss: 0.3183\n",
      "Epoch [6/10], Batch [1154/1562], Loss: 0.2607\n",
      "Epoch [6/10], Batch [1156/1562], Loss: 0.2657\n",
      "Epoch [6/10], Batch [1158/1562], Loss: 0.2688\n",
      "Epoch [6/10], Batch [1160/1562], Loss: 0.3136\n",
      "Epoch [6/10], Batch [1162/1562], Loss: 0.2496\n",
      "Epoch [6/10], Batch [1164/1562], Loss: 0.2651\n",
      "Epoch [6/10], Batch [1166/1562], Loss: 0.3118\n",
      "Epoch [6/10], Batch [1168/1562], Loss: 0.2964\n",
      "Epoch [6/10], Batch [1170/1562], Loss: 0.2943\n",
      "Epoch [6/10], Batch [1172/1562], Loss: 0.3244\n",
      "Epoch [6/10], Batch [1174/1562], Loss: 0.2864\n",
      "Epoch [6/10], Batch [1176/1562], Loss: 0.2899\n",
      "Epoch [6/10], Batch [1178/1562], Loss: 0.2809\n",
      "Epoch [6/10], Batch [1180/1562], Loss: 0.3004\n",
      "Epoch [6/10], Batch [1182/1562], Loss: 0.2889\n",
      "Epoch [6/10], Batch [1184/1562], Loss: 0.3072\n",
      "Epoch [6/10], Batch [1186/1562], Loss: 0.3036\n",
      "Epoch [6/10], Batch [1188/1562], Loss: 0.2570\n",
      "Epoch [6/10], Batch [1190/1562], Loss: 0.2859\n",
      "Epoch [6/10], Batch [1192/1562], Loss: 0.2846\n",
      "Epoch [6/10], Batch [1194/1562], Loss: 0.2984\n",
      "Epoch [6/10], Batch [1196/1562], Loss: 0.2314\n",
      "Epoch [6/10], Batch [1198/1562], Loss: 0.2559\n",
      "Epoch [6/10], Batch [1200/1562], Loss: 0.2689\n",
      "Epoch [6/10], Batch [1202/1562], Loss: 0.3008\n",
      "Epoch [6/10], Batch [1204/1562], Loss: 0.2816\n",
      "Epoch [6/10], Batch [1206/1562], Loss: 0.2663\n",
      "Epoch [6/10], Batch [1208/1562], Loss: 0.2979\n",
      "Epoch [6/10], Batch [1210/1562], Loss: 0.2882\n",
      "Epoch [6/10], Batch [1212/1562], Loss: 0.2971\n",
      "Epoch [6/10], Batch [1214/1562], Loss: 0.2941\n",
      "Epoch [6/10], Batch [1216/1562], Loss: 0.3100\n",
      "Epoch [6/10], Batch [1218/1562], Loss: 0.3261\n",
      "Epoch [6/10], Batch [1220/1562], Loss: 0.2704\n",
      "Epoch [6/10], Batch [1222/1562], Loss: 0.2671\n",
      "Epoch [6/10], Batch [1224/1562], Loss: 0.3157\n",
      "Epoch [6/10], Batch [1226/1562], Loss: 0.2720\n",
      "Epoch [6/10], Batch [1228/1562], Loss: 0.2578\n",
      "Epoch [6/10], Batch [1230/1562], Loss: 0.2576\n",
      "Epoch [6/10], Batch [1232/1562], Loss: 0.3011\n",
      "Epoch [6/10], Batch [1234/1562], Loss: 0.2871\n",
      "Epoch [6/10], Batch [1236/1562], Loss: 0.2839\n",
      "Epoch [6/10], Batch [1238/1562], Loss: 0.2406\n",
      "Epoch [6/10], Batch [1240/1562], Loss: 0.3058\n",
      "Epoch [6/10], Batch [1242/1562], Loss: 0.3230\n",
      "Epoch [6/10], Batch [1244/1562], Loss: 0.3160\n",
      "Epoch [6/10], Batch [1246/1562], Loss: 0.2795\n",
      "Epoch [6/10], Batch [1248/1562], Loss: 0.2641\n",
      "Epoch [6/10], Batch [1250/1562], Loss: 0.2565\n",
      "Epoch [6/10], Batch [1252/1562], Loss: 0.3010\n",
      "Epoch [6/10], Batch [1254/1562], Loss: 0.2820\n",
      "Epoch [6/10], Batch [1256/1562], Loss: 0.2849\n",
      "Epoch [6/10], Batch [1258/1562], Loss: 0.2844\n",
      "Epoch [6/10], Batch [1260/1562], Loss: 0.2921\n",
      "Epoch [6/10], Batch [1262/1562], Loss: 0.3168\n",
      "Epoch [6/10], Batch [1264/1562], Loss: 0.2972\n",
      "Epoch [6/10], Batch [1266/1562], Loss: 0.2975\n",
      "Epoch [6/10], Batch [1268/1562], Loss: 0.3010\n",
      "Epoch [6/10], Batch [1270/1562], Loss: 0.2481\n",
      "Epoch [6/10], Batch [1272/1562], Loss: 0.3010\n",
      "Epoch [6/10], Batch [1274/1562], Loss: 0.3202\n",
      "Epoch [6/10], Batch [1276/1562], Loss: 0.2627\n",
      "Epoch [6/10], Batch [1278/1562], Loss: 0.3089\n",
      "Epoch [6/10], Batch [1280/1562], Loss: 0.2656\n",
      "Epoch [6/10], Batch [1282/1562], Loss: 0.2734\n",
      "Epoch [6/10], Batch [1284/1562], Loss: 0.2471\n",
      "Epoch [6/10], Batch [1286/1562], Loss: 0.2877\n",
      "Epoch [6/10], Batch [1288/1562], Loss: 0.3481\n",
      "Epoch [6/10], Batch [1290/1562], Loss: 0.2687\n",
      "Epoch [6/10], Batch [1292/1562], Loss: 0.3097\n",
      "Epoch [6/10], Batch [1294/1562], Loss: 0.3017\n",
      "Epoch [6/10], Batch [1296/1562], Loss: 0.3266\n",
      "Epoch [6/10], Batch [1298/1562], Loss: 0.2866\n",
      "Epoch [6/10], Batch [1300/1562], Loss: 0.3121\n",
      "Epoch [6/10], Batch [1302/1562], Loss: 0.2788\n",
      "Epoch [6/10], Batch [1304/1562], Loss: 0.2727\n",
      "Epoch [6/10], Batch [1306/1562], Loss: 0.2994\n",
      "Epoch [6/10], Batch [1308/1562], Loss: 0.2916\n",
      "Epoch [6/10], Batch [1310/1562], Loss: 0.2346\n",
      "Epoch [6/10], Batch [1312/1562], Loss: 0.2895\n",
      "Epoch [6/10], Batch [1314/1562], Loss: 0.2652\n",
      "Epoch [6/10], Batch [1316/1562], Loss: 0.2936\n",
      "Epoch [6/10], Batch [1318/1562], Loss: 0.3109\n",
      "Epoch [6/10], Batch [1320/1562], Loss: 0.2652\n",
      "Epoch [6/10], Batch [1322/1562], Loss: 0.2892\n",
      "Epoch [6/10], Batch [1324/1562], Loss: 0.3030\n",
      "Epoch [6/10], Batch [1326/1562], Loss: 0.2983\n",
      "Epoch [6/10], Batch [1328/1562], Loss: 0.2850\n",
      "Epoch [6/10], Batch [1330/1562], Loss: 0.3095\n",
      "Epoch [6/10], Batch [1332/1562], Loss: 0.2884\n",
      "Epoch [6/10], Batch [1334/1562], Loss: 0.2792\n",
      "Epoch [6/10], Batch [1336/1562], Loss: 0.2725\n",
      "Epoch [6/10], Batch [1338/1562], Loss: 0.2651\n",
      "Epoch [6/10], Batch [1340/1562], Loss: 0.2986\n",
      "Epoch [6/10], Batch [1342/1562], Loss: 0.2676\n",
      "Epoch [6/10], Batch [1344/1562], Loss: 0.2975\n",
      "Epoch [6/10], Batch [1346/1562], Loss: 0.2811\n",
      "Epoch [6/10], Batch [1348/1562], Loss: 0.2703\n",
      "Epoch [6/10], Batch [1350/1562], Loss: 0.3136\n",
      "Epoch [6/10], Batch [1352/1562], Loss: 0.2939\n",
      "Epoch [6/10], Batch [1354/1562], Loss: 0.2818\n",
      "Epoch [6/10], Batch [1356/1562], Loss: 0.2468\n",
      "Epoch [6/10], Batch [1358/1562], Loss: 0.3381\n",
      "Epoch [6/10], Batch [1360/1562], Loss: 0.2916\n",
      "Epoch [6/10], Batch [1362/1562], Loss: 0.2899\n",
      "Epoch [6/10], Batch [1364/1562], Loss: 0.2851\n",
      "Epoch [6/10], Batch [1366/1562], Loss: 0.3269\n",
      "Epoch [6/10], Batch [1368/1562], Loss: 0.2804\n",
      "Epoch [6/10], Batch [1370/1562], Loss: 0.2864\n",
      "Epoch [6/10], Batch [1372/1562], Loss: 0.2969\n",
      "Epoch [6/10], Batch [1374/1562], Loss: 0.2725\n",
      "Epoch [6/10], Batch [1376/1562], Loss: 0.3051\n",
      "Epoch [6/10], Batch [1378/1562], Loss: 0.2845\n",
      "Epoch [6/10], Batch [1380/1562], Loss: 0.2886\n",
      "Epoch [6/10], Batch [1382/1562], Loss: 0.3259\n",
      "Epoch [6/10], Batch [1384/1562], Loss: 0.2725\n",
      "Epoch [6/10], Batch [1386/1562], Loss: 0.2616\n",
      "Epoch [6/10], Batch [1388/1562], Loss: 0.2490\n",
      "Epoch [6/10], Batch [1390/1562], Loss: 0.2922\n",
      "Epoch [6/10], Batch [1392/1562], Loss: 0.3044\n",
      "Epoch [6/10], Batch [1394/1562], Loss: 0.2504\n",
      "Epoch [6/10], Batch [1396/1562], Loss: 0.2698\n",
      "Epoch [6/10], Batch [1398/1562], Loss: 0.3401\n",
      "Epoch [6/10], Batch [1400/1562], Loss: 0.3466\n",
      "Epoch [6/10], Batch [1402/1562], Loss: 0.3027\n",
      "Epoch [6/10], Batch [1404/1562], Loss: 0.2770\n",
      "Epoch [6/10], Batch [1406/1562], Loss: 0.2657\n",
      "Epoch [6/10], Batch [1408/1562], Loss: 0.2670\n",
      "Epoch [6/10], Batch [1410/1562], Loss: 0.2853\n",
      "Epoch [6/10], Batch [1412/1562], Loss: 0.2969\n",
      "Epoch [6/10], Batch [1414/1562], Loss: 0.2962\n",
      "Epoch [6/10], Batch [1416/1562], Loss: 0.3247\n",
      "Epoch [6/10], Batch [1418/1562], Loss: 0.2769\n",
      "Epoch [6/10], Batch [1420/1562], Loss: 0.2906\n",
      "Epoch [6/10], Batch [1422/1562], Loss: 0.3035\n",
      "Epoch [6/10], Batch [1424/1562], Loss: 0.2975\n",
      "Epoch [6/10], Batch [1426/1562], Loss: 0.2853\n",
      "Epoch [6/10], Batch [1428/1562], Loss: 0.2877\n",
      "Epoch [6/10], Batch [1430/1562], Loss: 0.2479\n",
      "Epoch [6/10], Batch [1432/1562], Loss: 0.2901\n",
      "Epoch [6/10], Batch [1434/1562], Loss: 0.2665\n",
      "Epoch [6/10], Batch [1436/1562], Loss: 0.3028\n",
      "Epoch [6/10], Batch [1438/1562], Loss: 0.3121\n",
      "Epoch [6/10], Batch [1440/1562], Loss: 0.2851\n",
      "Epoch [6/10], Batch [1442/1562], Loss: 0.2583\n",
      "Epoch [6/10], Batch [1444/1562], Loss: 0.2618\n",
      "Epoch [6/10], Batch [1446/1562], Loss: 0.2896\n",
      "Epoch [6/10], Batch [1448/1562], Loss: 0.2761\n",
      "Epoch [6/10], Batch [1450/1562], Loss: 0.2529\n",
      "Epoch [6/10], Batch [1452/1562], Loss: 0.2693\n",
      "Epoch [6/10], Batch [1454/1562], Loss: 0.2835\n",
      "Epoch [6/10], Batch [1456/1562], Loss: 0.2785\n",
      "Epoch [6/10], Batch [1458/1562], Loss: 0.2874\n",
      "Epoch [6/10], Batch [1460/1562], Loss: 0.2631\n",
      "Epoch [6/10], Batch [1462/1562], Loss: 0.2974\n",
      "Epoch [6/10], Batch [1464/1562], Loss: 0.2854\n",
      "Epoch [6/10], Batch [1466/1562], Loss: 0.2887\n",
      "Epoch [6/10], Batch [1468/1562], Loss: 0.3380\n",
      "Epoch [6/10], Batch [1470/1562], Loss: 0.3035\n",
      "Epoch [6/10], Batch [1472/1562], Loss: 0.2747\n",
      "Epoch [6/10], Batch [1474/1562], Loss: 0.2831\n",
      "Epoch [6/10], Batch [1476/1562], Loss: 0.3555\n",
      "Epoch [6/10], Batch [1478/1562], Loss: 0.2850\n",
      "Epoch [6/10], Batch [1480/1562], Loss: 0.3054\n",
      "Epoch [6/10], Batch [1482/1562], Loss: 0.3138\n",
      "Epoch [6/10], Batch [1484/1562], Loss: 0.2760\n",
      "Epoch [6/10], Batch [1486/1562], Loss: 0.3040\n",
      "Epoch [6/10], Batch [1488/1562], Loss: 0.2761\n",
      "Epoch [6/10], Batch [1490/1562], Loss: 0.2590\n",
      "Epoch [6/10], Batch [1492/1562], Loss: 0.2884\n",
      "Epoch [6/10], Batch [1494/1562], Loss: 0.3039\n",
      "Epoch [6/10], Batch [1496/1562], Loss: 0.2751\n",
      "Epoch [6/10], Batch [1498/1562], Loss: 0.2691\n",
      "Epoch [6/10], Batch [1500/1562], Loss: 0.2846\n",
      "Epoch [6/10], Batch [1502/1562], Loss: 0.2961\n",
      "Epoch [6/10], Batch [1504/1562], Loss: 0.2922\n",
      "Epoch [6/10], Batch [1506/1562], Loss: 0.2789\n",
      "Epoch [6/10], Batch [1508/1562], Loss: 0.2791\n",
      "Epoch [6/10], Batch [1510/1562], Loss: 0.3021\n",
      "Epoch [6/10], Batch [1512/1562], Loss: 0.3107\n",
      "Epoch [6/10], Batch [1514/1562], Loss: 0.2682\n",
      "Epoch [6/10], Batch [1516/1562], Loss: 0.3058\n",
      "Epoch [6/10], Batch [1518/1562], Loss: 0.3075\n",
      "Epoch [6/10], Batch [1520/1562], Loss: 0.2755\n",
      "Epoch [6/10], Batch [1522/1562], Loss: 0.2867\n",
      "Epoch [6/10], Batch [1524/1562], Loss: 0.2540\n",
      "Epoch [6/10], Batch [1526/1562], Loss: 0.2698\n",
      "Epoch [6/10], Batch [1528/1562], Loss: 0.2425\n",
      "Epoch [6/10], Batch [1530/1562], Loss: 0.2781\n",
      "Epoch [6/10], Batch [1532/1562], Loss: 0.2658\n",
      "Epoch [6/10], Batch [1534/1562], Loss: 0.2902\n",
      "Epoch [6/10], Batch [1536/1562], Loss: 0.3057\n",
      "Epoch [6/10], Batch [1538/1562], Loss: 0.3079\n",
      "Epoch [6/10], Batch [1540/1562], Loss: 0.3297\n",
      "Epoch [6/10], Batch [1542/1562], Loss: 0.3160\n",
      "Epoch [6/10], Batch [1544/1562], Loss: 0.3033\n",
      "Epoch [6/10], Batch [1546/1562], Loss: 0.2746\n",
      "Epoch [6/10], Batch [1548/1562], Loss: 0.2862\n",
      "Epoch [6/10], Batch [1550/1562], Loss: 0.2802\n",
      "Epoch [6/10], Batch [1552/1562], Loss: 0.2558\n",
      "Epoch [6/10], Batch [1554/1562], Loss: 0.2875\n",
      "Epoch [6/10], Batch [1556/1562], Loss: 0.2864\n",
      "Epoch [6/10], Batch [1558/1562], Loss: 0.2991\n",
      "Epoch [6/10], Batch [1560/1562], Loss: 0.2763\n",
      "Epoch [6/10], Batch [1562/1562], Loss: 0.2947\n",
      "Epoch [6/10] completed. Average Loss: 0.2868\n",
      "Epoch [7/10], Batch [2/1562], Loss: 0.2609\n",
      "Epoch [7/10], Batch [4/1562], Loss: 0.3103\n",
      "Epoch [7/10], Batch [6/1562], Loss: 0.2648\n",
      "Epoch [7/10], Batch [8/1562], Loss: 0.2912\n",
      "Epoch [7/10], Batch [10/1562], Loss: 0.2615\n",
      "Epoch [7/10], Batch [12/1562], Loss: 0.3013\n",
      "Epoch [7/10], Batch [14/1562], Loss: 0.3068\n",
      "Epoch [7/10], Batch [16/1562], Loss: 0.3201\n",
      "Epoch [7/10], Batch [18/1562], Loss: 0.3200\n",
      "Epoch [7/10], Batch [20/1562], Loss: 0.2849\n",
      "Epoch [7/10], Batch [22/1562], Loss: 0.2606\n",
      "Epoch [7/10], Batch [24/1562], Loss: 0.2638\n",
      "Epoch [7/10], Batch [26/1562], Loss: 0.2546\n",
      "Epoch [7/10], Batch [28/1562], Loss: 0.2729\n",
      "Epoch [7/10], Batch [30/1562], Loss: 0.2956\n",
      "Epoch [7/10], Batch [32/1562], Loss: 0.2981\n",
      "Epoch [7/10], Batch [34/1562], Loss: 0.3241\n",
      "Epoch [7/10], Batch [36/1562], Loss: 0.2587\n",
      "Epoch [7/10], Batch [38/1562], Loss: 0.2800\n",
      "Epoch [7/10], Batch [40/1562], Loss: 0.2805\n",
      "Epoch [7/10], Batch [42/1562], Loss: 0.2978\n",
      "Epoch [7/10], Batch [44/1562], Loss: 0.3208\n",
      "Epoch [7/10], Batch [46/1562], Loss: 0.2398\n",
      "Epoch [7/10], Batch [48/1562], Loss: 0.3293\n",
      "Epoch [7/10], Batch [50/1562], Loss: 0.3007\n",
      "Epoch [7/10], Batch [52/1562], Loss: 0.2788\n",
      "Epoch [7/10], Batch [54/1562], Loss: 0.2411\n",
      "Epoch [7/10], Batch [56/1562], Loss: 0.2836\n",
      "Epoch [7/10], Batch [58/1562], Loss: 0.2880\n",
      "Epoch [7/10], Batch [60/1562], Loss: 0.2815\n",
      "Epoch [7/10], Batch [62/1562], Loss: 0.2381\n",
      "Epoch [7/10], Batch [64/1562], Loss: 0.3058\n",
      "Epoch [7/10], Batch [66/1562], Loss: 0.2753\n",
      "Epoch [7/10], Batch [68/1562], Loss: 0.2503\n",
      "Epoch [7/10], Batch [70/1562], Loss: 0.2732\n",
      "Epoch [7/10], Batch [72/1562], Loss: 0.3235\n",
      "Epoch [7/10], Batch [74/1562], Loss: 0.2766\n",
      "Epoch [7/10], Batch [76/1562], Loss: 0.2935\n",
      "Epoch [7/10], Batch [78/1562], Loss: 0.2619\n",
      "Epoch [7/10], Batch [80/1562], Loss: 0.2577\n",
      "Epoch [7/10], Batch [82/1562], Loss: 0.2584\n",
      "Epoch [7/10], Batch [84/1562], Loss: 0.2939\n",
      "Epoch [7/10], Batch [86/1562], Loss: 0.2914\n",
      "Epoch [7/10], Batch [88/1562], Loss: 0.2822\n",
      "Epoch [7/10], Batch [90/1562], Loss: 0.2705\n",
      "Epoch [7/10], Batch [92/1562], Loss: 0.3083\n",
      "Epoch [7/10], Batch [94/1562], Loss: 0.2746\n",
      "Epoch [7/10], Batch [96/1562], Loss: 0.2747\n",
      "Epoch [7/10], Batch [98/1562], Loss: 0.2796\n",
      "Epoch [7/10], Batch [100/1562], Loss: 0.2441\n",
      "Epoch [7/10], Batch [102/1562], Loss: 0.2903\n",
      "Epoch [7/10], Batch [104/1562], Loss: 0.2699\n",
      "Epoch [7/10], Batch [106/1562], Loss: 0.2996\n",
      "Epoch [7/10], Batch [108/1562], Loss: 0.2521\n",
      "Epoch [7/10], Batch [110/1562], Loss: 0.2438\n",
      "Epoch [7/10], Batch [112/1562], Loss: 0.3162\n",
      "Epoch [7/10], Batch [114/1562], Loss: 0.2704\n",
      "Epoch [7/10], Batch [116/1562], Loss: 0.2969\n",
      "Epoch [7/10], Batch [118/1562], Loss: 0.2904\n",
      "Epoch [7/10], Batch [120/1562], Loss: 0.3098\n",
      "Epoch [7/10], Batch [122/1562], Loss: 0.2644\n",
      "Epoch [7/10], Batch [124/1562], Loss: 0.2805\n",
      "Epoch [7/10], Batch [126/1562], Loss: 0.2612\n",
      "Epoch [7/10], Batch [128/1562], Loss: 0.2817\n",
      "Epoch [7/10], Batch [130/1562], Loss: 0.2672\n",
      "Epoch [7/10], Batch [132/1562], Loss: 0.2835\n",
      "Epoch [7/10], Batch [134/1562], Loss: 0.2837\n",
      "Epoch [7/10], Batch [136/1562], Loss: 0.2900\n",
      "Epoch [7/10], Batch [138/1562], Loss: 0.2596\n",
      "Epoch [7/10], Batch [140/1562], Loss: 0.2631\n",
      "Epoch [7/10], Batch [142/1562], Loss: 0.2764\n",
      "Epoch [7/10], Batch [144/1562], Loss: 0.2792\n",
      "Epoch [7/10], Batch [146/1562], Loss: 0.3071\n",
      "Epoch [7/10], Batch [148/1562], Loss: 0.2965\n",
      "Epoch [7/10], Batch [150/1562], Loss: 0.2576\n",
      "Epoch [7/10], Batch [152/1562], Loss: 0.2540\n",
      "Epoch [7/10], Batch [154/1562], Loss: 0.3002\n",
      "Epoch [7/10], Batch [156/1562], Loss: 0.2806\n",
      "Epoch [7/10], Batch [158/1562], Loss: 0.2257\n",
      "Epoch [7/10], Batch [160/1562], Loss: 0.3253\n",
      "Epoch [7/10], Batch [162/1562], Loss: 0.3177\n",
      "Epoch [7/10], Batch [164/1562], Loss: 0.2764\n",
      "Epoch [7/10], Batch [166/1562], Loss: 0.3032\n",
      "Epoch [7/10], Batch [168/1562], Loss: 0.3132\n",
      "Epoch [7/10], Batch [170/1562], Loss: 0.2872\n",
      "Epoch [7/10], Batch [172/1562], Loss: 0.3163\n",
      "Epoch [7/10], Batch [174/1562], Loss: 0.2684\n",
      "Epoch [7/10], Batch [176/1562], Loss: 0.2708\n",
      "Epoch [7/10], Batch [178/1562], Loss: 0.2985\n",
      "Epoch [7/10], Batch [180/1562], Loss: 0.3135\n",
      "Epoch [7/10], Batch [182/1562], Loss: 0.2628\n",
      "Epoch [7/10], Batch [184/1562], Loss: 0.2935\n",
      "Epoch [7/10], Batch [186/1562], Loss: 0.2850\n",
      "Epoch [7/10], Batch [188/1562], Loss: 0.2799\n",
      "Epoch [7/10], Batch [190/1562], Loss: 0.2442\n",
      "Epoch [7/10], Batch [192/1562], Loss: 0.2695\n",
      "Epoch [7/10], Batch [194/1562], Loss: 0.3059\n",
      "Epoch [7/10], Batch [196/1562], Loss: 0.2810\n",
      "Epoch [7/10], Batch [198/1562], Loss: 0.2559\n",
      "Epoch [7/10], Batch [200/1562], Loss: 0.3077\n",
      "Epoch [7/10], Batch [202/1562], Loss: 0.2528\n",
      "Epoch [7/10], Batch [204/1562], Loss: 0.2379\n",
      "Epoch [7/10], Batch [206/1562], Loss: 0.2770\n",
      "Epoch [7/10], Batch [208/1562], Loss: 0.2842\n",
      "Epoch [7/10], Batch [210/1562], Loss: 0.2803\n",
      "Epoch [7/10], Batch [212/1562], Loss: 0.2748\n",
      "Epoch [7/10], Batch [214/1562], Loss: 0.2723\n",
      "Epoch [7/10], Batch [216/1562], Loss: 0.3070\n",
      "Epoch [7/10], Batch [218/1562], Loss: 0.2582\n",
      "Epoch [7/10], Batch [220/1562], Loss: 0.2769\n",
      "Epoch [7/10], Batch [222/1562], Loss: 0.2672\n",
      "Epoch [7/10], Batch [224/1562], Loss: 0.3077\n",
      "Epoch [7/10], Batch [226/1562], Loss: 0.2404\n",
      "Epoch [7/10], Batch [228/1562], Loss: 0.2314\n",
      "Epoch [7/10], Batch [230/1562], Loss: 0.3128\n",
      "Epoch [7/10], Batch [232/1562], Loss: 0.2805\n",
      "Epoch [7/10], Batch [234/1562], Loss: 0.2671\n",
      "Epoch [7/10], Batch [236/1562], Loss: 0.2842\n",
      "Epoch [7/10], Batch [238/1562], Loss: 0.2895\n",
      "Epoch [7/10], Batch [240/1562], Loss: 0.2963\n",
      "Epoch [7/10], Batch [242/1562], Loss: 0.3368\n",
      "Epoch [7/10], Batch [244/1562], Loss: 0.2939\n",
      "Epoch [7/10], Batch [246/1562], Loss: 0.3030\n",
      "Epoch [7/10], Batch [248/1562], Loss: 0.2744\n",
      "Epoch [7/10], Batch [250/1562], Loss: 0.3277\n",
      "Epoch [7/10], Batch [252/1562], Loss: 0.2851\n",
      "Epoch [7/10], Batch [254/1562], Loss: 0.2722\n",
      "Epoch [7/10], Batch [256/1562], Loss: 0.3759\n",
      "Epoch [7/10], Batch [258/1562], Loss: 0.3219\n",
      "Epoch [7/10], Batch [260/1562], Loss: 0.3167\n",
      "Epoch [7/10], Batch [262/1562], Loss: 0.2734\n",
      "Epoch [7/10], Batch [264/1562], Loss: 0.2595\n",
      "Epoch [7/10], Batch [266/1562], Loss: 0.2698\n",
      "Epoch [7/10], Batch [268/1562], Loss: 0.3063\n",
      "Epoch [7/10], Batch [270/1562], Loss: 0.3040\n",
      "Epoch [7/10], Batch [272/1562], Loss: 0.3143\n",
      "Epoch [7/10], Batch [274/1562], Loss: 0.2874\n",
      "Epoch [7/10], Batch [276/1562], Loss: 0.2609\n",
      "Epoch [7/10], Batch [278/1562], Loss: 0.3054\n",
      "Epoch [7/10], Batch [280/1562], Loss: 0.2794\n",
      "Epoch [7/10], Batch [282/1562], Loss: 0.3291\n",
      "Epoch [7/10], Batch [284/1562], Loss: 0.2906\n",
      "Epoch [7/10], Batch [286/1562], Loss: 0.2968\n",
      "Epoch [7/10], Batch [288/1562], Loss: 0.2836\n",
      "Epoch [7/10], Batch [290/1562], Loss: 0.2687\n",
      "Epoch [7/10], Batch [292/1562], Loss: 0.2976\n",
      "Epoch [7/10], Batch [294/1562], Loss: 0.2750\n",
      "Epoch [7/10], Batch [296/1562], Loss: 0.2587\n",
      "Epoch [7/10], Batch [298/1562], Loss: 0.2757\n",
      "Epoch [7/10], Batch [300/1562], Loss: 0.2601\n",
      "Epoch [7/10], Batch [302/1562], Loss: 0.2646\n",
      "Epoch [7/10], Batch [304/1562], Loss: 0.2692\n",
      "Epoch [7/10], Batch [306/1562], Loss: 0.2725\n",
      "Epoch [7/10], Batch [308/1562], Loss: 0.2665\n",
      "Epoch [7/10], Batch [310/1562], Loss: 0.2636\n",
      "Epoch [7/10], Batch [312/1562], Loss: 0.2387\n",
      "Epoch [7/10], Batch [314/1562], Loss: 0.3524\n",
      "Epoch [7/10], Batch [316/1562], Loss: 0.2917\n",
      "Epoch [7/10], Batch [318/1562], Loss: 0.2670\n",
      "Epoch [7/10], Batch [320/1562], Loss: 0.2980\n",
      "Epoch [7/10], Batch [322/1562], Loss: 0.2774\n",
      "Epoch [7/10], Batch [324/1562], Loss: 0.2501\n",
      "Epoch [7/10], Batch [326/1562], Loss: 0.2820\n",
      "Epoch [7/10], Batch [328/1562], Loss: 0.2884\n",
      "Epoch [7/10], Batch [330/1562], Loss: 0.3105\n",
      "Epoch [7/10], Batch [332/1562], Loss: 0.3155\n",
      "Epoch [7/10], Batch [334/1562], Loss: 0.3012\n",
      "Epoch [7/10], Batch [336/1562], Loss: 0.2821\n",
      "Epoch [7/10], Batch [338/1562], Loss: 0.2921\n",
      "Epoch [7/10], Batch [340/1562], Loss: 0.3057\n",
      "Epoch [7/10], Batch [342/1562], Loss: 0.3348\n",
      "Epoch [7/10], Batch [344/1562], Loss: 0.2764\n",
      "Epoch [7/10], Batch [346/1562], Loss: 0.3199\n",
      "Epoch [7/10], Batch [348/1562], Loss: 0.2646\n",
      "Epoch [7/10], Batch [350/1562], Loss: 0.2859\n",
      "Epoch [7/10], Batch [352/1562], Loss: 0.2936\n",
      "Epoch [7/10], Batch [354/1562], Loss: 0.2490\n",
      "Epoch [7/10], Batch [356/1562], Loss: 0.2898\n",
      "Epoch [7/10], Batch [358/1562], Loss: 0.2616\n",
      "Epoch [7/10], Batch [360/1562], Loss: 0.3020\n",
      "Epoch [7/10], Batch [362/1562], Loss: 0.2870\n",
      "Epoch [7/10], Batch [364/1562], Loss: 0.2777\n",
      "Epoch [7/10], Batch [366/1562], Loss: 0.2653\n",
      "Epoch [7/10], Batch [368/1562], Loss: 0.2543\n",
      "Epoch [7/10], Batch [370/1562], Loss: 0.2651\n",
      "Epoch [7/10], Batch [372/1562], Loss: 0.3281\n",
      "Epoch [7/10], Batch [374/1562], Loss: 0.2643\n",
      "Epoch [7/10], Batch [376/1562], Loss: 0.3079\n",
      "Epoch [7/10], Batch [378/1562], Loss: 0.2962\n",
      "Epoch [7/10], Batch [380/1562], Loss: 0.2934\n",
      "Epoch [7/10], Batch [382/1562], Loss: 0.3176\n",
      "Epoch [7/10], Batch [384/1562], Loss: 0.2787\n",
      "Epoch [7/10], Batch [386/1562], Loss: 0.2954\n",
      "Epoch [7/10], Batch [388/1562], Loss: 0.2430\n",
      "Epoch [7/10], Batch [390/1562], Loss: 0.2881\n",
      "Epoch [7/10], Batch [392/1562], Loss: 0.2937\n",
      "Epoch [7/10], Batch [394/1562], Loss: 0.2705\n",
      "Epoch [7/10], Batch [396/1562], Loss: 0.2535\n",
      "Epoch [7/10], Batch [398/1562], Loss: 0.2860\n",
      "Epoch [7/10], Batch [400/1562], Loss: 0.2576\n",
      "Epoch [7/10], Batch [402/1562], Loss: 0.3037\n",
      "Epoch [7/10], Batch [404/1562], Loss: 0.3016\n",
      "Epoch [7/10], Batch [406/1562], Loss: 0.2622\n",
      "Epoch [7/10], Batch [408/1562], Loss: 0.3055\n",
      "Epoch [7/10], Batch [410/1562], Loss: 0.2923\n",
      "Epoch [7/10], Batch [412/1562], Loss: 0.2688\n",
      "Epoch [7/10], Batch [414/1562], Loss: 0.2652\n",
      "Epoch [7/10], Batch [416/1562], Loss: 0.2985\n",
      "Epoch [7/10], Batch [418/1562], Loss: 0.3030\n",
      "Epoch [7/10], Batch [420/1562], Loss: 0.2922\n",
      "Epoch [7/10], Batch [422/1562], Loss: 0.2845\n",
      "Epoch [7/10], Batch [424/1562], Loss: 0.3170\n",
      "Epoch [7/10], Batch [426/1562], Loss: 0.3096\n",
      "Epoch [7/10], Batch [428/1562], Loss: 0.3192\n",
      "Epoch [7/10], Batch [430/1562], Loss: 0.3222\n",
      "Epoch [7/10], Batch [432/1562], Loss: 0.2535\n",
      "Epoch [7/10], Batch [434/1562], Loss: 0.2722\n",
      "Epoch [7/10], Batch [436/1562], Loss: 0.2827\n",
      "Epoch [7/10], Batch [438/1562], Loss: 0.2946\n",
      "Epoch [7/10], Batch [440/1562], Loss: 0.2615\n",
      "Epoch [7/10], Batch [442/1562], Loss: 0.2955\n",
      "Epoch [7/10], Batch [444/1562], Loss: 0.2784\n",
      "Epoch [7/10], Batch [446/1562], Loss: 0.2944\n",
      "Epoch [7/10], Batch [448/1562], Loss: 0.2246\n",
      "Epoch [7/10], Batch [450/1562], Loss: 0.3203\n",
      "Epoch [7/10], Batch [452/1562], Loss: 0.2927\n",
      "Epoch [7/10], Batch [454/1562], Loss: 0.2882\n",
      "Epoch [7/10], Batch [456/1562], Loss: 0.2793\n",
      "Epoch [7/10], Batch [458/1562], Loss: 0.2606\n",
      "Epoch [7/10], Batch [460/1562], Loss: 0.2741\n",
      "Epoch [7/10], Batch [462/1562], Loss: 0.3287\n",
      "Epoch [7/10], Batch [464/1562], Loss: 0.2965\n",
      "Epoch [7/10], Batch [466/1562], Loss: 0.2837\n",
      "Epoch [7/10], Batch [468/1562], Loss: 0.2865\n",
      "Epoch [7/10], Batch [470/1562], Loss: 0.3109\n",
      "Epoch [7/10], Batch [472/1562], Loss: 0.2877\n",
      "Epoch [7/10], Batch [474/1562], Loss: 0.2675\n",
      "Epoch [7/10], Batch [476/1562], Loss: 0.2577\n",
      "Epoch [7/10], Batch [478/1562], Loss: 0.2573\n",
      "Epoch [7/10], Batch [480/1562], Loss: 0.2923\n",
      "Epoch [7/10], Batch [482/1562], Loss: 0.2504\n",
      "Epoch [7/10], Batch [484/1562], Loss: 0.3011\n",
      "Epoch [7/10], Batch [486/1562], Loss: 0.2689\n",
      "Epoch [7/10], Batch [488/1562], Loss: 0.2976\n",
      "Epoch [7/10], Batch [490/1562], Loss: 0.3147\n",
      "Epoch [7/10], Batch [492/1562], Loss: 0.2712\n",
      "Epoch [7/10], Batch [494/1562], Loss: 0.3329\n",
      "Epoch [7/10], Batch [496/1562], Loss: 0.2892\n",
      "Epoch [7/10], Batch [498/1562], Loss: 0.2706\n",
      "Epoch [7/10], Batch [500/1562], Loss: 0.3020\n",
      "Epoch [7/10], Batch [502/1562], Loss: 0.2978\n",
      "Epoch [7/10], Batch [504/1562], Loss: 0.3226\n",
      "Epoch [7/10], Batch [506/1562], Loss: 0.2639\n",
      "Epoch [7/10], Batch [508/1562], Loss: 0.2427\n",
      "Epoch [7/10], Batch [510/1562], Loss: 0.2881\n",
      "Epoch [7/10], Batch [512/1562], Loss: 0.3169\n",
      "Epoch [7/10], Batch [514/1562], Loss: 0.2894\n",
      "Epoch [7/10], Batch [516/1562], Loss: 0.2769\n",
      "Epoch [7/10], Batch [518/1562], Loss: 0.2712\n",
      "Epoch [7/10], Batch [520/1562], Loss: 0.3127\n",
      "Epoch [7/10], Batch [522/1562], Loss: 0.2729\n",
      "Epoch [7/10], Batch [524/1562], Loss: 0.3159\n",
      "Epoch [7/10], Batch [526/1562], Loss: 0.2961\n",
      "Epoch [7/10], Batch [528/1562], Loss: 0.2602\n",
      "Epoch [7/10], Batch [530/1562], Loss: 0.2825\n",
      "Epoch [7/10], Batch [532/1562], Loss: 0.2922\n",
      "Epoch [7/10], Batch [534/1562], Loss: 0.2775\n",
      "Epoch [7/10], Batch [536/1562], Loss: 0.2662\n",
      "Epoch [7/10], Batch [538/1562], Loss: 0.2557\n",
      "Epoch [7/10], Batch [540/1562], Loss: 0.2759\n",
      "Epoch [7/10], Batch [542/1562], Loss: 0.2391\n",
      "Epoch [7/10], Batch [544/1562], Loss: 0.2794\n",
      "Epoch [7/10], Batch [546/1562], Loss: 0.3133\n",
      "Epoch [7/10], Batch [548/1562], Loss: 0.2893\n",
      "Epoch [7/10], Batch [550/1562], Loss: 0.2652\n",
      "Epoch [7/10], Batch [552/1562], Loss: 0.3135\n",
      "Epoch [7/10], Batch [554/1562], Loss: 0.2870\n",
      "Epoch [7/10], Batch [556/1562], Loss: 0.2950\n",
      "Epoch [7/10], Batch [558/1562], Loss: 0.2858\n",
      "Epoch [7/10], Batch [560/1562], Loss: 0.2638\n",
      "Epoch [7/10], Batch [562/1562], Loss: 0.2717\n",
      "Epoch [7/10], Batch [564/1562], Loss: 0.2831\n",
      "Epoch [7/10], Batch [566/1562], Loss: 0.3132\n",
      "Epoch [7/10], Batch [568/1562], Loss: 0.2645\n",
      "Epoch [7/10], Batch [570/1562], Loss: 0.2807\n",
      "Epoch [7/10], Batch [572/1562], Loss: 0.2930\n",
      "Epoch [7/10], Batch [574/1562], Loss: 0.2764\n",
      "Epoch [7/10], Batch [576/1562], Loss: 0.2609\n",
      "Epoch [7/10], Batch [578/1562], Loss: 0.2587\n",
      "Epoch [7/10], Batch [580/1562], Loss: 0.2996\n",
      "Epoch [7/10], Batch [582/1562], Loss: 0.3124\n",
      "Epoch [7/10], Batch [584/1562], Loss: 0.2566\n",
      "Epoch [7/10], Batch [586/1562], Loss: 0.2751\n",
      "Epoch [7/10], Batch [588/1562], Loss: 0.3375\n",
      "Epoch [7/10], Batch [590/1562], Loss: 0.3102\n",
      "Epoch [7/10], Batch [592/1562], Loss: 0.3070\n",
      "Epoch [7/10], Batch [594/1562], Loss: 0.2842\n",
      "Epoch [7/10], Batch [596/1562], Loss: 0.2949\n",
      "Epoch [7/10], Batch [598/1562], Loss: 0.2976\n",
      "Epoch [7/10], Batch [600/1562], Loss: 0.3869\n",
      "Epoch [7/10], Batch [602/1562], Loss: 0.2844\n",
      "Epoch [7/10], Batch [604/1562], Loss: 0.2897\n",
      "Epoch [7/10], Batch [606/1562], Loss: 0.2939\n",
      "Epoch [7/10], Batch [608/1562], Loss: 0.3221\n",
      "Epoch [7/10], Batch [610/1562], Loss: 0.3069\n",
      "Epoch [7/10], Batch [612/1562], Loss: 0.2668\n",
      "Epoch [7/10], Batch [614/1562], Loss: 0.2509\n",
      "Epoch [7/10], Batch [616/1562], Loss: 0.3298\n",
      "Epoch [7/10], Batch [618/1562], Loss: 0.2626\n",
      "Epoch [7/10], Batch [620/1562], Loss: 0.3153\n",
      "Epoch [7/10], Batch [622/1562], Loss: 0.2849\n",
      "Epoch [7/10], Batch [624/1562], Loss: 0.3017\n",
      "Epoch [7/10], Batch [626/1562], Loss: 0.2702\n",
      "Epoch [7/10], Batch [628/1562], Loss: 0.3042\n",
      "Epoch [7/10], Batch [630/1562], Loss: 0.2848\n",
      "Epoch [7/10], Batch [632/1562], Loss: 0.2316\n",
      "Epoch [7/10], Batch [634/1562], Loss: 0.2971\n",
      "Epoch [7/10], Batch [636/1562], Loss: 0.3157\n",
      "Epoch [7/10], Batch [638/1562], Loss: 0.2706\n",
      "Epoch [7/10], Batch [640/1562], Loss: 0.2900\n",
      "Epoch [7/10], Batch [642/1562], Loss: 0.2714\n",
      "Epoch [7/10], Batch [644/1562], Loss: 0.2481\n",
      "Epoch [7/10], Batch [646/1562], Loss: 0.3052\n",
      "Epoch [7/10], Batch [648/1562], Loss: 0.2668\n",
      "Epoch [7/10], Batch [650/1562], Loss: 0.3039\n",
      "Epoch [7/10], Batch [652/1562], Loss: 0.2668\n",
      "Epoch [7/10], Batch [654/1562], Loss: 0.3130\n",
      "Epoch [7/10], Batch [656/1562], Loss: 0.2477\n",
      "Epoch [7/10], Batch [658/1562], Loss: 0.2607\n",
      "Epoch [7/10], Batch [660/1562], Loss: 0.2989\n",
      "Epoch [7/10], Batch [662/1562], Loss: 0.2770\n",
      "Epoch [7/10], Batch [664/1562], Loss: 0.3070\n",
      "Epoch [7/10], Batch [666/1562], Loss: 0.2906\n",
      "Epoch [7/10], Batch [668/1562], Loss: 0.2594\n",
      "Epoch [7/10], Batch [670/1562], Loss: 0.3019\n",
      "Epoch [7/10], Batch [672/1562], Loss: 0.2771\n",
      "Epoch [7/10], Batch [674/1562], Loss: 0.2319\n",
      "Epoch [7/10], Batch [676/1562], Loss: 0.2667\n",
      "Epoch [7/10], Batch [678/1562], Loss: 0.2780\n",
      "Epoch [7/10], Batch [680/1562], Loss: 0.2708\n",
      "Epoch [7/10], Batch [682/1562], Loss: 0.2765\n",
      "Epoch [7/10], Batch [684/1562], Loss: 0.2550\n",
      "Epoch [7/10], Batch [686/1562], Loss: 0.3012\n",
      "Epoch [7/10], Batch [688/1562], Loss: 0.2745\n",
      "Epoch [7/10], Batch [690/1562], Loss: 0.2818\n",
      "Epoch [7/10], Batch [692/1562], Loss: 0.2909\n",
      "Epoch [7/10], Batch [694/1562], Loss: 0.2606\n",
      "Epoch [7/10], Batch [696/1562], Loss: 0.2431\n",
      "Epoch [7/10], Batch [698/1562], Loss: 0.2809\n",
      "Epoch [7/10], Batch [700/1562], Loss: 0.2877\n",
      "Epoch [7/10], Batch [702/1562], Loss: 0.2529\n",
      "Epoch [7/10], Batch [704/1562], Loss: 0.2629\n",
      "Epoch [7/10], Batch [706/1562], Loss: 0.2642\n",
      "Epoch [7/10], Batch [708/1562], Loss: 0.2824\n",
      "Epoch [7/10], Batch [710/1562], Loss: 0.2902\n",
      "Epoch [7/10], Batch [712/1562], Loss: 0.3006\n",
      "Epoch [7/10], Batch [714/1562], Loss: 0.2688\n",
      "Epoch [7/10], Batch [716/1562], Loss: 0.2865\n",
      "Epoch [7/10], Batch [718/1562], Loss: 0.2746\n",
      "Epoch [7/10], Batch [720/1562], Loss: 0.2973\n",
      "Epoch [7/10], Batch [722/1562], Loss: 0.2846\n",
      "Epoch [7/10], Batch [724/1562], Loss: 0.2769\n",
      "Epoch [7/10], Batch [726/1562], Loss: 0.2614\n",
      "Epoch [7/10], Batch [728/1562], Loss: 0.3103\n",
      "Epoch [7/10], Batch [730/1562], Loss: 0.2625\n",
      "Epoch [7/10], Batch [732/1562], Loss: 0.2790\n",
      "Epoch [7/10], Batch [734/1562], Loss: 0.2565\n",
      "Epoch [7/10], Batch [736/1562], Loss: 0.2786\n",
      "Epoch [7/10], Batch [738/1562], Loss: 0.2696\n",
      "Epoch [7/10], Batch [740/1562], Loss: 0.2798\n",
      "Epoch [7/10], Batch [742/1562], Loss: 0.2691\n",
      "Epoch [7/10], Batch [744/1562], Loss: 0.3180\n",
      "Epoch [7/10], Batch [746/1562], Loss: 0.2822\n",
      "Epoch [7/10], Batch [748/1562], Loss: 0.2787\n",
      "Epoch [7/10], Batch [750/1562], Loss: 0.3101\n",
      "Epoch [7/10], Batch [752/1562], Loss: 0.3034\n",
      "Epoch [7/10], Batch [754/1562], Loss: 0.2594\n",
      "Epoch [7/10], Batch [756/1562], Loss: 0.2935\n",
      "Epoch [7/10], Batch [758/1562], Loss: 0.3144\n",
      "Epoch [7/10], Batch [760/1562], Loss: 0.3037\n",
      "Epoch [7/10], Batch [762/1562], Loss: 0.2964\n",
      "Epoch [7/10], Batch [764/1562], Loss: 0.3043\n",
      "Epoch [7/10], Batch [766/1562], Loss: 0.2716\n",
      "Epoch [7/10], Batch [768/1562], Loss: 0.3062\n",
      "Epoch [7/10], Batch [770/1562], Loss: 0.2974\n",
      "Epoch [7/10], Batch [772/1562], Loss: 0.2921\n",
      "Epoch [7/10], Batch [774/1562], Loss: 0.2880\n",
      "Epoch [7/10], Batch [776/1562], Loss: 0.2681\n",
      "Epoch [7/10], Batch [778/1562], Loss: 0.3048\n",
      "Epoch [7/10], Batch [780/1562], Loss: 0.2649\n",
      "Epoch [7/10], Batch [782/1562], Loss: 0.2406\n",
      "Epoch [7/10], Batch [784/1562], Loss: 0.2646\n",
      "Epoch [7/10], Batch [786/1562], Loss: 0.2981\n",
      "Epoch [7/10], Batch [788/1562], Loss: 0.3249\n",
      "Epoch [7/10], Batch [790/1562], Loss: 0.2639\n",
      "Epoch [7/10], Batch [792/1562], Loss: 0.3007\n",
      "Epoch [7/10], Batch [794/1562], Loss: 0.2818\n",
      "Epoch [7/10], Batch [796/1562], Loss: 0.3108\n",
      "Epoch [7/10], Batch [798/1562], Loss: 0.3100\n",
      "Epoch [7/10], Batch [800/1562], Loss: 0.3252\n",
      "Epoch [7/10], Batch [802/1562], Loss: 0.2594\n",
      "Epoch [7/10], Batch [804/1562], Loss: 0.2640\n",
      "Epoch [7/10], Batch [806/1562], Loss: 0.2820\n",
      "Epoch [7/10], Batch [808/1562], Loss: 0.2485\n",
      "Epoch [7/10], Batch [810/1562], Loss: 0.3042\n",
      "Epoch [7/10], Batch [812/1562], Loss: 0.2823\n",
      "Epoch [7/10], Batch [814/1562], Loss: 0.2965\n",
      "Epoch [7/10], Batch [816/1562], Loss: 0.2885\n",
      "Epoch [7/10], Batch [818/1562], Loss: 0.2819\n",
      "Epoch [7/10], Batch [820/1562], Loss: 0.3104\n",
      "Epoch [7/10], Batch [822/1562], Loss: 0.2892\n",
      "Epoch [7/10], Batch [824/1562], Loss: 0.2876\n",
      "Epoch [7/10], Batch [826/1562], Loss: 0.3113\n",
      "Epoch [7/10], Batch [828/1562], Loss: 0.3246\n",
      "Epoch [7/10], Batch [830/1562], Loss: 0.3075\n",
      "Epoch [7/10], Batch [832/1562], Loss: 0.2849\n",
      "Epoch [7/10], Batch [834/1562], Loss: 0.2973\n",
      "Epoch [7/10], Batch [836/1562], Loss: 0.2962\n",
      "Epoch [7/10], Batch [838/1562], Loss: 0.2783\n",
      "Epoch [7/10], Batch [840/1562], Loss: 0.2738\n",
      "Epoch [7/10], Batch [842/1562], Loss: 0.2863\n",
      "Epoch [7/10], Batch [844/1562], Loss: 0.2590\n",
      "Epoch [7/10], Batch [846/1562], Loss: 0.2773\n",
      "Epoch [7/10], Batch [848/1562], Loss: 0.3014\n",
      "Epoch [7/10], Batch [850/1562], Loss: 0.2631\n",
      "Epoch [7/10], Batch [852/1562], Loss: 0.3417\n",
      "Epoch [7/10], Batch [854/1562], Loss: 0.2774\n",
      "Epoch [7/10], Batch [856/1562], Loss: 0.2581\n",
      "Epoch [7/10], Batch [858/1562], Loss: 0.2757\n",
      "Epoch [7/10], Batch [860/1562], Loss: 0.3025\n",
      "Epoch [7/10], Batch [862/1562], Loss: 0.3013\n",
      "Epoch [7/10], Batch [864/1562], Loss: 0.2813\n",
      "Epoch [7/10], Batch [866/1562], Loss: 0.2822\n",
      "Epoch [7/10], Batch [868/1562], Loss: 0.2800\n",
      "Epoch [7/10], Batch [870/1562], Loss: 0.2903\n",
      "Epoch [7/10], Batch [872/1562], Loss: 0.2823\n",
      "Epoch [7/10], Batch [874/1562], Loss: 0.2933\n",
      "Epoch [7/10], Batch [876/1562], Loss: 0.2705\n",
      "Epoch [7/10], Batch [878/1562], Loss: 0.2716\n",
      "Epoch [7/10], Batch [880/1562], Loss: 0.2987\n",
      "Epoch [7/10], Batch [882/1562], Loss: 0.3052\n",
      "Epoch [7/10], Batch [884/1562], Loss: 0.2744\n",
      "Epoch [7/10], Batch [886/1562], Loss: 0.2841\n",
      "Epoch [7/10], Batch [888/1562], Loss: 0.2836\n",
      "Epoch [7/10], Batch [890/1562], Loss: 0.2651\n",
      "Epoch [7/10], Batch [892/1562], Loss: 0.3033\n",
      "Epoch [7/10], Batch [894/1562], Loss: 0.2555\n",
      "Epoch [7/10], Batch [896/1562], Loss: 0.3130\n",
      "Epoch [7/10], Batch [898/1562], Loss: 0.2681\n",
      "Epoch [7/10], Batch [900/1562], Loss: 0.2765\n",
      "Epoch [7/10], Batch [902/1562], Loss: 0.2990\n",
      "Epoch [7/10], Batch [904/1562], Loss: 0.3253\n",
      "Epoch [7/10], Batch [906/1562], Loss: 0.2898\n",
      "Epoch [7/10], Batch [908/1562], Loss: 0.2876\n",
      "Epoch [7/10], Batch [910/1562], Loss: 0.2869\n",
      "Epoch [7/10], Batch [912/1562], Loss: 0.2631\n",
      "Epoch [7/10], Batch [914/1562], Loss: 0.2660\n",
      "Epoch [7/10], Batch [916/1562], Loss: 0.2666\n",
      "Epoch [7/10], Batch [918/1562], Loss: 0.2694\n",
      "Epoch [7/10], Batch [920/1562], Loss: 0.2909\n",
      "Epoch [7/10], Batch [922/1562], Loss: 0.2661\n",
      "Epoch [7/10], Batch [924/1562], Loss: 0.2443\n",
      "Epoch [7/10], Batch [926/1562], Loss: 0.2936\n",
      "Epoch [7/10], Batch [928/1562], Loss: 0.2731\n",
      "Epoch [7/10], Batch [930/1562], Loss: 0.2825\n",
      "Epoch [7/10], Batch [932/1562], Loss: 0.2813\n",
      "Epoch [7/10], Batch [934/1562], Loss: 0.3088\n",
      "Epoch [7/10], Batch [936/1562], Loss: 0.2812\n",
      "Epoch [7/10], Batch [938/1562], Loss: 0.2623\n",
      "Epoch [7/10], Batch [940/1562], Loss: 0.2981\n",
      "Epoch [7/10], Batch [942/1562], Loss: 0.2636\n",
      "Epoch [7/10], Batch [944/1562], Loss: 0.2901\n",
      "Epoch [7/10], Batch [946/1562], Loss: 0.2902\n",
      "Epoch [7/10], Batch [948/1562], Loss: 0.3287\n",
      "Epoch [7/10], Batch [950/1562], Loss: 0.2823\n",
      "Epoch [7/10], Batch [952/1562], Loss: 0.2357\n",
      "Epoch [7/10], Batch [954/1562], Loss: 0.3156\n",
      "Epoch [7/10], Batch [956/1562], Loss: 0.2778\n",
      "Epoch [7/10], Batch [958/1562], Loss: 0.2767\n",
      "Epoch [7/10], Batch [960/1562], Loss: 0.2450\n",
      "Epoch [7/10], Batch [962/1562], Loss: 0.3309\n",
      "Epoch [7/10], Batch [964/1562], Loss: 0.2893\n",
      "Epoch [7/10], Batch [966/1562], Loss: 0.2801\n",
      "Epoch [7/10], Batch [968/1562], Loss: 0.2884\n",
      "Epoch [7/10], Batch [970/1562], Loss: 0.2553\n",
      "Epoch [7/10], Batch [972/1562], Loss: 0.2364\n",
      "Epoch [7/10], Batch [974/1562], Loss: 0.2340\n",
      "Epoch [7/10], Batch [976/1562], Loss: 0.2350\n",
      "Epoch [7/10], Batch [978/1562], Loss: 0.2824\n",
      "Epoch [7/10], Batch [980/1562], Loss: 0.2835\n",
      "Epoch [7/10], Batch [982/1562], Loss: 0.2788\n",
      "Epoch [7/10], Batch [984/1562], Loss: 0.2768\n",
      "Epoch [7/10], Batch [986/1562], Loss: 0.2580\n",
      "Epoch [7/10], Batch [988/1562], Loss: 0.2398\n",
      "Epoch [7/10], Batch [990/1562], Loss: 0.2261\n",
      "Epoch [7/10], Batch [992/1562], Loss: 0.3236\n",
      "Epoch [7/10], Batch [994/1562], Loss: 0.2730\n",
      "Epoch [7/10], Batch [996/1562], Loss: 0.2829\n",
      "Epoch [7/10], Batch [998/1562], Loss: 0.2658\n",
      "Epoch [7/10], Batch [1000/1562], Loss: 0.3210\n",
      "Epoch [7/10], Batch [1002/1562], Loss: 0.2785\n",
      "Epoch [7/10], Batch [1004/1562], Loss: 0.3554\n",
      "Epoch [7/10], Batch [1006/1562], Loss: 0.3046\n",
      "Epoch [7/10], Batch [1008/1562], Loss: 0.2710\n",
      "Epoch [7/10], Batch [1010/1562], Loss: 0.2407\n",
      "Epoch [7/10], Batch [1012/1562], Loss: 0.3168\n",
      "Epoch [7/10], Batch [1014/1562], Loss: 0.3002\n",
      "Epoch [7/10], Batch [1016/1562], Loss: 0.2992\n",
      "Epoch [7/10], Batch [1018/1562], Loss: 0.2934\n",
      "Epoch [7/10], Batch [1020/1562], Loss: 0.2745\n",
      "Epoch [7/10], Batch [1022/1562], Loss: 0.2818\n",
      "Epoch [7/10], Batch [1024/1562], Loss: 0.2859\n",
      "Epoch [7/10], Batch [1026/1562], Loss: 0.2672\n",
      "Epoch [7/10], Batch [1028/1562], Loss: 0.2928\n",
      "Epoch [7/10], Batch [1030/1562], Loss: 0.2924\n",
      "Epoch [7/10], Batch [1032/1562], Loss: 0.2863\n",
      "Epoch [7/10], Batch [1034/1562], Loss: 0.2772\n",
      "Epoch [7/10], Batch [1036/1562], Loss: 0.2787\n",
      "Epoch [7/10], Batch [1038/1562], Loss: 0.2651\n",
      "Epoch [7/10], Batch [1040/1562], Loss: 0.3281\n",
      "Epoch [7/10], Batch [1042/1562], Loss: 0.2849\n",
      "Epoch [7/10], Batch [1044/1562], Loss: 0.2656\n",
      "Epoch [7/10], Batch [1046/1562], Loss: 0.2477\n",
      "Epoch [7/10], Batch [1048/1562], Loss: 0.2535\n",
      "Epoch [7/10], Batch [1050/1562], Loss: 0.2484\n",
      "Epoch [7/10], Batch [1052/1562], Loss: 0.2611\n",
      "Epoch [7/10], Batch [1054/1562], Loss: 0.2965\n",
      "Epoch [7/10], Batch [1056/1562], Loss: 0.2639\n",
      "Epoch [7/10], Batch [1058/1562], Loss: 0.2539\n",
      "Epoch [7/10], Batch [1060/1562], Loss: 0.2549\n",
      "Epoch [7/10], Batch [1062/1562], Loss: 0.2450\n",
      "Epoch [7/10], Batch [1064/1562], Loss: 0.2971\n",
      "Epoch [7/10], Batch [1066/1562], Loss: 0.2863\n",
      "Epoch [7/10], Batch [1068/1562], Loss: 0.2538\n",
      "Epoch [7/10], Batch [1070/1562], Loss: 0.2579\n",
      "Epoch [7/10], Batch [1072/1562], Loss: 0.2542\n",
      "Epoch [7/10], Batch [1074/1562], Loss: 0.2380\n",
      "Epoch [7/10], Batch [1076/1562], Loss: 0.2827\n",
      "Epoch [7/10], Batch [1078/1562], Loss: 0.2853\n",
      "Epoch [7/10], Batch [1080/1562], Loss: 0.2589\n",
      "Epoch [7/10], Batch [1082/1562], Loss: 0.3144\n",
      "Epoch [7/10], Batch [1084/1562], Loss: 0.2484\n",
      "Epoch [7/10], Batch [1086/1562], Loss: 0.2985\n",
      "Epoch [7/10], Batch [1088/1562], Loss: 0.2543\n",
      "Epoch [7/10], Batch [1090/1562], Loss: 0.3077\n",
      "Epoch [7/10], Batch [1092/1562], Loss: 0.3061\n",
      "Epoch [7/10], Batch [1094/1562], Loss: 0.3179\n",
      "Epoch [7/10], Batch [1096/1562], Loss: 0.2720\n",
      "Epoch [7/10], Batch [1098/1562], Loss: 0.2639\n",
      "Epoch [7/10], Batch [1100/1562], Loss: 0.3311\n",
      "Epoch [7/10], Batch [1102/1562], Loss: 0.2975\n",
      "Epoch [7/10], Batch [1104/1562], Loss: 0.2698\n",
      "Epoch [7/10], Batch [1106/1562], Loss: 0.2938\n",
      "Epoch [7/10], Batch [1108/1562], Loss: 0.2714\n",
      "Epoch [7/10], Batch [1110/1562], Loss: 0.2503\n",
      "Epoch [7/10], Batch [1112/1562], Loss: 0.2903\n",
      "Epoch [7/10], Batch [1114/1562], Loss: 0.2600\n",
      "Epoch [7/10], Batch [1116/1562], Loss: 0.2909\n",
      "Epoch [7/10], Batch [1118/1562], Loss: 0.2682\n",
      "Epoch [7/10], Batch [1120/1562], Loss: 0.3126\n",
      "Epoch [7/10], Batch [1122/1562], Loss: 0.2853\n",
      "Epoch [7/10], Batch [1124/1562], Loss: 0.2552\n",
      "Epoch [7/10], Batch [1126/1562], Loss: 0.3107\n",
      "Epoch [7/10], Batch [1128/1562], Loss: 0.2832\n",
      "Epoch [7/10], Batch [1130/1562], Loss: 0.2757\n",
      "Epoch [7/10], Batch [1132/1562], Loss: 0.3081\n",
      "Epoch [7/10], Batch [1134/1562], Loss: 0.2833\n",
      "Epoch [7/10], Batch [1136/1562], Loss: 0.2478\n",
      "Epoch [7/10], Batch [1138/1562], Loss: 0.2941\n",
      "Epoch [7/10], Batch [1140/1562], Loss: 0.2577\n",
      "Epoch [7/10], Batch [1142/1562], Loss: 0.2743\n",
      "Epoch [7/10], Batch [1144/1562], Loss: 0.2989\n",
      "Epoch [7/10], Batch [1146/1562], Loss: 0.3129\n",
      "Epoch [7/10], Batch [1148/1562], Loss: 0.2975\n",
      "Epoch [7/10], Batch [1150/1562], Loss: 0.3006\n",
      "Epoch [7/10], Batch [1152/1562], Loss: 0.3146\n",
      "Epoch [7/10], Batch [1154/1562], Loss: 0.3168\n",
      "Epoch [7/10], Batch [1156/1562], Loss: 0.2718\n",
      "Epoch [7/10], Batch [1158/1562], Loss: 0.2878\n",
      "Epoch [7/10], Batch [1160/1562], Loss: 0.2720\n",
      "Epoch [7/10], Batch [1162/1562], Loss: 0.2501\n",
      "Epoch [7/10], Batch [1164/1562], Loss: 0.3416\n",
      "Epoch [7/10], Batch [1166/1562], Loss: 0.2660\n",
      "Epoch [7/10], Batch [1168/1562], Loss: 0.2816\n",
      "Epoch [7/10], Batch [1170/1562], Loss: 0.2427\n",
      "Epoch [7/10], Batch [1172/1562], Loss: 0.3027\n",
      "Epoch [7/10], Batch [1174/1562], Loss: 0.2803\n",
      "Epoch [7/10], Batch [1176/1562], Loss: 0.3091\n",
      "Epoch [7/10], Batch [1178/1562], Loss: 0.2910\n",
      "Epoch [7/10], Batch [1180/1562], Loss: 0.2742\n",
      "Epoch [7/10], Batch [1182/1562], Loss: 0.3121\n",
      "Epoch [7/10], Batch [1184/1562], Loss: 0.2693\n",
      "Epoch [7/10], Batch [1186/1562], Loss: 0.3310\n",
      "Epoch [7/10], Batch [1188/1562], Loss: 0.2982\n",
      "Epoch [7/10], Batch [1190/1562], Loss: 0.3039\n",
      "Epoch [7/10], Batch [1192/1562], Loss: 0.2771\n",
      "Epoch [7/10], Batch [1194/1562], Loss: 0.2976\n",
      "Epoch [7/10], Batch [1196/1562], Loss: 0.3085\n",
      "Epoch [7/10], Batch [1198/1562], Loss: 0.2574\n",
      "Epoch [7/10], Batch [1200/1562], Loss: 0.2980\n",
      "Epoch [7/10], Batch [1202/1562], Loss: 0.2602\n",
      "Epoch [7/10], Batch [1204/1562], Loss: 0.2750\n",
      "Epoch [7/10], Batch [1206/1562], Loss: 0.2994\n",
      "Epoch [7/10], Batch [1208/1562], Loss: 0.2906\n",
      "Epoch [7/10], Batch [1210/1562], Loss: 0.2606\n",
      "Epoch [7/10], Batch [1212/1562], Loss: 0.3043\n",
      "Epoch [7/10], Batch [1214/1562], Loss: 0.3202\n",
      "Epoch [7/10], Batch [1216/1562], Loss: 0.2850\n",
      "Epoch [7/10], Batch [1218/1562], Loss: 0.2682\n",
      "Epoch [7/10], Batch [1220/1562], Loss: 0.2867\n",
      "Epoch [7/10], Batch [1222/1562], Loss: 0.2830\n",
      "Epoch [7/10], Batch [1224/1562], Loss: 0.2964\n",
      "Epoch [7/10], Batch [1226/1562], Loss: 0.2781\n",
      "Epoch [7/10], Batch [1228/1562], Loss: 0.2611\n",
      "Epoch [7/10], Batch [1230/1562], Loss: 0.2723\n",
      "Epoch [7/10], Batch [1232/1562], Loss: 0.2827\n",
      "Epoch [7/10], Batch [1234/1562], Loss: 0.2884\n",
      "Epoch [7/10], Batch [1236/1562], Loss: 0.3110\n",
      "Epoch [7/10], Batch [1238/1562], Loss: 0.3045\n",
      "Epoch [7/10], Batch [1240/1562], Loss: 0.2715\n",
      "Epoch [7/10], Batch [1242/1562], Loss: 0.2883\n",
      "Epoch [7/10], Batch [1244/1562], Loss: 0.2944\n",
      "Epoch [7/10], Batch [1246/1562], Loss: 0.2944\n",
      "Epoch [7/10], Batch [1248/1562], Loss: 0.2799\n",
      "Epoch [7/10], Batch [1250/1562], Loss: 0.2878\n",
      "Epoch [7/10], Batch [1252/1562], Loss: 0.2788\n",
      "Epoch [7/10], Batch [1254/1562], Loss: 0.2990\n",
      "Epoch [7/10], Batch [1256/1562], Loss: 0.3098\n",
      "Epoch [7/10], Batch [1258/1562], Loss: 0.2652\n",
      "Epoch [7/10], Batch [1260/1562], Loss: 0.3230\n",
      "Epoch [7/10], Batch [1262/1562], Loss: 0.2827\n",
      "Epoch [7/10], Batch [1264/1562], Loss: 0.2911\n",
      "Epoch [7/10], Batch [1266/1562], Loss: 0.3316\n",
      "Epoch [7/10], Batch [1268/1562], Loss: 0.2980\n",
      "Epoch [7/10], Batch [1270/1562], Loss: 0.2907\n",
      "Epoch [7/10], Batch [1272/1562], Loss: 0.3007\n",
      "Epoch [7/10], Batch [1274/1562], Loss: 0.2801\n",
      "Epoch [7/10], Batch [1276/1562], Loss: 0.2975\n",
      "Epoch [7/10], Batch [1278/1562], Loss: 0.2459\n",
      "Epoch [7/10], Batch [1280/1562], Loss: 0.3184\n",
      "Epoch [7/10], Batch [1282/1562], Loss: 0.3043\n",
      "Epoch [7/10], Batch [1284/1562], Loss: 0.2959\n",
      "Epoch [7/10], Batch [1286/1562], Loss: 0.2815\n",
      "Epoch [7/10], Batch [1288/1562], Loss: 0.3100\n",
      "Epoch [7/10], Batch [1290/1562], Loss: 0.2513\n",
      "Epoch [7/10], Batch [1292/1562], Loss: 0.2886\n",
      "Epoch [7/10], Batch [1294/1562], Loss: 0.2777\n",
      "Epoch [7/10], Batch [1296/1562], Loss: 0.3134\n",
      "Epoch [7/10], Batch [1298/1562], Loss: 0.2880\n",
      "Epoch [7/10], Batch [1300/1562], Loss: 0.2965\n",
      "Epoch [7/10], Batch [1302/1562], Loss: 0.3019\n",
      "Epoch [7/10], Batch [1304/1562], Loss: 0.2874\n",
      "Epoch [7/10], Batch [1306/1562], Loss: 0.2845\n",
      "Epoch [7/10], Batch [1308/1562], Loss: 0.3113\n",
      "Epoch [7/10], Batch [1310/1562], Loss: 0.2641\n",
      "Epoch [7/10], Batch [1312/1562], Loss: 0.2951\n",
      "Epoch [7/10], Batch [1314/1562], Loss: 0.2967\n",
      "Epoch [7/10], Batch [1316/1562], Loss: 0.2765\n",
      "Epoch [7/10], Batch [1318/1562], Loss: 0.2448\n",
      "Epoch [7/10], Batch [1320/1562], Loss: 0.2602\n",
      "Epoch [7/10], Batch [1322/1562], Loss: 0.3199\n",
      "Epoch [7/10], Batch [1324/1562], Loss: 0.2930\n",
      "Epoch [7/10], Batch [1326/1562], Loss: 0.2695\n",
      "Epoch [7/10], Batch [1328/1562], Loss: 0.3121\n",
      "Epoch [7/10], Batch [1330/1562], Loss: 0.2723\n",
      "Epoch [7/10], Batch [1332/1562], Loss: 0.2700\n",
      "Epoch [7/10], Batch [1334/1562], Loss: 0.3239\n",
      "Epoch [7/10], Batch [1336/1562], Loss: 0.2934\n",
      "Epoch [7/10], Batch [1338/1562], Loss: 0.3015\n",
      "Epoch [7/10], Batch [1340/1562], Loss: 0.2621\n",
      "Epoch [7/10], Batch [1342/1562], Loss: 0.2997\n",
      "Epoch [7/10], Batch [1344/1562], Loss: 0.2751\n",
      "Epoch [7/10], Batch [1346/1562], Loss: 0.2864\n",
      "Epoch [7/10], Batch [1348/1562], Loss: 0.2790\n",
      "Epoch [7/10], Batch [1350/1562], Loss: 0.3251\n",
      "Epoch [7/10], Batch [1352/1562], Loss: 0.2701\n",
      "Epoch [7/10], Batch [1354/1562], Loss: 0.2465\n",
      "Epoch [7/10], Batch [1356/1562], Loss: 0.2911\n",
      "Epoch [7/10], Batch [1358/1562], Loss: 0.3100\n",
      "Epoch [7/10], Batch [1360/1562], Loss: 0.2804\n",
      "Epoch [7/10], Batch [1362/1562], Loss: 0.2672\n",
      "Epoch [7/10], Batch [1364/1562], Loss: 0.2781\n",
      "Epoch [7/10], Batch [1366/1562], Loss: 0.3057\n",
      "Epoch [7/10], Batch [1368/1562], Loss: 0.2837\n",
      "Epoch [7/10], Batch [1370/1562], Loss: 0.2843\n",
      "Epoch [7/10], Batch [1372/1562], Loss: 0.2634\n",
      "Epoch [7/10], Batch [1374/1562], Loss: 0.2714\n",
      "Epoch [7/10], Batch [1376/1562], Loss: 0.3018\n",
      "Epoch [7/10], Batch [1378/1562], Loss: 0.2738\n",
      "Epoch [7/10], Batch [1380/1562], Loss: 0.3179\n",
      "Epoch [7/10], Batch [1382/1562], Loss: 0.2849\n",
      "Epoch [7/10], Batch [1384/1562], Loss: 0.2312\n",
      "Epoch [7/10], Batch [1386/1562], Loss: 0.2608\n",
      "Epoch [7/10], Batch [1388/1562], Loss: 0.3178\n",
      "Epoch [7/10], Batch [1390/1562], Loss: 0.3172\n",
      "Epoch [7/10], Batch [1392/1562], Loss: 0.3243\n",
      "Epoch [7/10], Batch [1394/1562], Loss: 0.3080\n",
      "Epoch [7/10], Batch [1396/1562], Loss: 0.2799\n",
      "Epoch [7/10], Batch [1398/1562], Loss: 0.2517\n",
      "Epoch [7/10], Batch [1400/1562], Loss: 0.3038\n",
      "Epoch [7/10], Batch [1402/1562], Loss: 0.2744\n",
      "Epoch [7/10], Batch [1404/1562], Loss: 0.2608\n",
      "Epoch [7/10], Batch [1406/1562], Loss: 0.2877\n",
      "Epoch [7/10], Batch [1408/1562], Loss: 0.2980\n",
      "Epoch [7/10], Batch [1410/1562], Loss: 0.2881\n",
      "Epoch [7/10], Batch [1412/1562], Loss: 0.2578\n",
      "Epoch [7/10], Batch [1414/1562], Loss: 0.2733\n",
      "Epoch [7/10], Batch [1416/1562], Loss: 0.2601\n",
      "Epoch [7/10], Batch [1418/1562], Loss: 0.2611\n",
      "Epoch [7/10], Batch [1420/1562], Loss: 0.3151\n",
      "Epoch [7/10], Batch [1422/1562], Loss: 0.3320\n",
      "Epoch [7/10], Batch [1424/1562], Loss: 0.2959\n",
      "Epoch [7/10], Batch [1426/1562], Loss: 0.2849\n",
      "Epoch [7/10], Batch [1428/1562], Loss: 0.3336\n",
      "Epoch [7/10], Batch [1430/1562], Loss: 0.2901\n",
      "Epoch [7/10], Batch [1432/1562], Loss: 0.3022\n",
      "Epoch [7/10], Batch [1434/1562], Loss: 0.2627\n",
      "Epoch [7/10], Batch [1436/1562], Loss: 0.3268\n",
      "Epoch [7/10], Batch [1438/1562], Loss: 0.2740\n",
      "Epoch [7/10], Batch [1440/1562], Loss: 0.3137\n",
      "Epoch [7/10], Batch [1442/1562], Loss: 0.2469\n",
      "Epoch [7/10], Batch [1444/1562], Loss: 0.2734\n",
      "Epoch [7/10], Batch [1446/1562], Loss: 0.2831\n",
      "Epoch [7/10], Batch [1448/1562], Loss: 0.2647\n",
      "Epoch [7/10], Batch [1450/1562], Loss: 0.2583\n",
      "Epoch [7/10], Batch [1452/1562], Loss: 0.2972\n",
      "Epoch [7/10], Batch [1454/1562], Loss: 0.3241\n",
      "Epoch [7/10], Batch [1456/1562], Loss: 0.2904\n",
      "Epoch [7/10], Batch [1458/1562], Loss: 0.3322\n",
      "Epoch [7/10], Batch [1460/1562], Loss: 0.3264\n",
      "Epoch [7/10], Batch [1462/1562], Loss: 0.2937\n",
      "Epoch [7/10], Batch [1464/1562], Loss: 0.3064\n",
      "Epoch [7/10], Batch [1466/1562], Loss: 0.3420\n",
      "Epoch [7/10], Batch [1468/1562], Loss: 0.2805\n",
      "Epoch [7/10], Batch [1470/1562], Loss: 0.2651\n",
      "Epoch [7/10], Batch [1472/1562], Loss: 0.3547\n",
      "Epoch [7/10], Batch [1474/1562], Loss: 0.3024\n",
      "Epoch [7/10], Batch [1476/1562], Loss: 0.2793\n",
      "Epoch [7/10], Batch [1478/1562], Loss: 0.3141\n",
      "Epoch [7/10], Batch [1480/1562], Loss: 0.2826\n",
      "Epoch [7/10], Batch [1482/1562], Loss: 0.2547\n",
      "Epoch [7/10], Batch [1484/1562], Loss: 0.2782\n",
      "Epoch [7/10], Batch [1486/1562], Loss: 0.2887\n",
      "Epoch [7/10], Batch [1488/1562], Loss: 0.3013\n",
      "Epoch [7/10], Batch [1490/1562], Loss: 0.2910\n",
      "Epoch [7/10], Batch [1492/1562], Loss: 0.2660\n",
      "Epoch [7/10], Batch [1494/1562], Loss: 0.2957\n",
      "Epoch [7/10], Batch [1496/1562], Loss: 0.2758\n",
      "Epoch [7/10], Batch [1498/1562], Loss: 0.2514\n",
      "Epoch [7/10], Batch [1500/1562], Loss: 0.2775\n",
      "Epoch [7/10], Batch [1502/1562], Loss: 0.2608\n",
      "Epoch [7/10], Batch [1504/1562], Loss: 0.2842\n",
      "Epoch [7/10], Batch [1506/1562], Loss: 0.2739\n",
      "Epoch [7/10], Batch [1508/1562], Loss: 0.2905\n",
      "Epoch [7/10], Batch [1510/1562], Loss: 0.2732\n",
      "Epoch [7/10], Batch [1512/1562], Loss: 0.2586\n",
      "Epoch [7/10], Batch [1514/1562], Loss: 0.2966\n",
      "Epoch [7/10], Batch [1516/1562], Loss: 0.2543\n",
      "Epoch [7/10], Batch [1518/1562], Loss: 0.2970\n",
      "Epoch [7/10], Batch [1520/1562], Loss: 0.2816\n",
      "Epoch [7/10], Batch [1522/1562], Loss: 0.2841\n",
      "Epoch [7/10], Batch [1524/1562], Loss: 0.3012\n",
      "Epoch [7/10], Batch [1526/1562], Loss: 0.2642\n",
      "Epoch [7/10], Batch [1528/1562], Loss: 0.2664\n",
      "Epoch [7/10], Batch [1530/1562], Loss: 0.3239\n",
      "Epoch [7/10], Batch [1532/1562], Loss: 0.3365\n",
      "Epoch [7/10], Batch [1534/1562], Loss: 0.2908\n",
      "Epoch [7/10], Batch [1536/1562], Loss: 0.2880\n",
      "Epoch [7/10], Batch [1538/1562], Loss: 0.2816\n",
      "Epoch [7/10], Batch [1540/1562], Loss: 0.3029\n",
      "Epoch [7/10], Batch [1542/1562], Loss: 0.3030\n",
      "Epoch [7/10], Batch [1544/1562], Loss: 0.2689\n",
      "Epoch [7/10], Batch [1546/1562], Loss: 0.2970\n",
      "Epoch [7/10], Batch [1548/1562], Loss: 0.2620\n",
      "Epoch [7/10], Batch [1550/1562], Loss: 0.3397\n",
      "Epoch [7/10], Batch [1552/1562], Loss: 0.2894\n",
      "Epoch [7/10], Batch [1554/1562], Loss: 0.3212\n",
      "Epoch [7/10], Batch [1556/1562], Loss: 0.3130\n",
      "Epoch [7/10], Batch [1558/1562], Loss: 0.2380\n",
      "Epoch [7/10], Batch [1560/1562], Loss: 0.2913\n",
      "Epoch [7/10], Batch [1562/1562], Loss: 0.2812\n",
      "Epoch [7/10] completed. Average Loss: 0.2863\n",
      "Epoch [8/10], Batch [2/1562], Loss: 0.3199\n",
      "Epoch [8/10], Batch [4/1562], Loss: 0.2722\n",
      "Epoch [8/10], Batch [6/1562], Loss: 0.2367\n",
      "Epoch [8/10], Batch [8/1562], Loss: 0.2864\n",
      "Epoch [8/10], Batch [10/1562], Loss: 0.3087\n",
      "Epoch [8/10], Batch [12/1562], Loss: 0.2834\n",
      "Epoch [8/10], Batch [14/1562], Loss: 0.3064\n",
      "Epoch [8/10], Batch [16/1562], Loss: 0.2961\n",
      "Epoch [8/10], Batch [18/1562], Loss: 0.2647\n",
      "Epoch [8/10], Batch [20/1562], Loss: 0.3236\n",
      "Epoch [8/10], Batch [22/1562], Loss: 0.2579\n",
      "Epoch [8/10], Batch [24/1562], Loss: 0.2926\n",
      "Epoch [8/10], Batch [26/1562], Loss: 0.2873\n",
      "Epoch [8/10], Batch [28/1562], Loss: 0.3287\n",
      "Epoch [8/10], Batch [30/1562], Loss: 0.2748\n",
      "Epoch [8/10], Batch [32/1562], Loss: 0.2912\n",
      "Epoch [8/10], Batch [34/1562], Loss: 0.3137\n",
      "Epoch [8/10], Batch [36/1562], Loss: 0.2724\n",
      "Epoch [8/10], Batch [38/1562], Loss: 0.2823\n",
      "Epoch [8/10], Batch [40/1562], Loss: 0.3174\n",
      "Epoch [8/10], Batch [42/1562], Loss: 0.2892\n",
      "Epoch [8/10], Batch [44/1562], Loss: 0.2828\n",
      "Epoch [8/10], Batch [46/1562], Loss: 0.2767\n",
      "Epoch [8/10], Batch [48/1562], Loss: 0.3521\n",
      "Epoch [8/10], Batch [50/1562], Loss: 0.3013\n",
      "Epoch [8/10], Batch [52/1562], Loss: 0.3020\n",
      "Epoch [8/10], Batch [54/1562], Loss: 0.2643\n",
      "Epoch [8/10], Batch [56/1562], Loss: 0.3028\n",
      "Epoch [8/10], Batch [58/1562], Loss: 0.2999\n",
      "Epoch [8/10], Batch [60/1562], Loss: 0.2673\n",
      "Epoch [8/10], Batch [62/1562], Loss: 0.2785\n",
      "Epoch [8/10], Batch [64/1562], Loss: 0.2775\n",
      "Epoch [8/10], Batch [66/1562], Loss: 0.2968\n",
      "Epoch [8/10], Batch [68/1562], Loss: 0.2940\n",
      "Epoch [8/10], Batch [70/1562], Loss: 0.2314\n",
      "Epoch [8/10], Batch [72/1562], Loss: 0.2815\n",
      "Epoch [8/10], Batch [74/1562], Loss: 0.2995\n",
      "Epoch [8/10], Batch [76/1562], Loss: 0.2760\n",
      "Epoch [8/10], Batch [78/1562], Loss: 0.3120\n",
      "Epoch [8/10], Batch [80/1562], Loss: 0.3015\n",
      "Epoch [8/10], Batch [82/1562], Loss: 0.3194\n",
      "Epoch [8/10], Batch [84/1562], Loss: 0.2845\n",
      "Epoch [8/10], Batch [86/1562], Loss: 0.2316\n",
      "Epoch [8/10], Batch [88/1562], Loss: 0.3124\n",
      "Epoch [8/10], Batch [90/1562], Loss: 0.3304\n",
      "Epoch [8/10], Batch [92/1562], Loss: 0.3044\n",
      "Epoch [8/10], Batch [94/1562], Loss: 0.2744\n",
      "Epoch [8/10], Batch [96/1562], Loss: 0.2905\n",
      "Epoch [8/10], Batch [98/1562], Loss: 0.3302\n",
      "Epoch [8/10], Batch [100/1562], Loss: 0.2853\n",
      "Epoch [8/10], Batch [102/1562], Loss: 0.2686\n",
      "Epoch [8/10], Batch [104/1562], Loss: 0.2759\n",
      "Epoch [8/10], Batch [106/1562], Loss: 0.2787\n",
      "Epoch [8/10], Batch [108/1562], Loss: 0.2794\n",
      "Epoch [8/10], Batch [110/1562], Loss: 0.2464\n",
      "Epoch [8/10], Batch [112/1562], Loss: 0.2691\n",
      "Epoch [8/10], Batch [114/1562], Loss: 0.3095\n",
      "Epoch [8/10], Batch [116/1562], Loss: 0.2591\n",
      "Epoch [8/10], Batch [118/1562], Loss: 0.2878\n",
      "Epoch [8/10], Batch [120/1562], Loss: 0.2900\n",
      "Epoch [8/10], Batch [122/1562], Loss: 0.2797\n",
      "Epoch [8/10], Batch [124/1562], Loss: 0.3032\n",
      "Epoch [8/10], Batch [126/1562], Loss: 0.2755\n",
      "Epoch [8/10], Batch [128/1562], Loss: 0.2827\n",
      "Epoch [8/10], Batch [130/1562], Loss: 0.3086\n",
      "Epoch [8/10], Batch [132/1562], Loss: 0.3259\n",
      "Epoch [8/10], Batch [134/1562], Loss: 0.2983\n",
      "Epoch [8/10], Batch [136/1562], Loss: 0.2913\n",
      "Epoch [8/10], Batch [138/1562], Loss: 0.3053\n",
      "Epoch [8/10], Batch [140/1562], Loss: 0.2443\n",
      "Epoch [8/10], Batch [142/1562], Loss: 0.2906\n",
      "Epoch [8/10], Batch [144/1562], Loss: 0.3485\n",
      "Epoch [8/10], Batch [146/1562], Loss: 0.3047\n",
      "Epoch [8/10], Batch [148/1562], Loss: 0.2961\n",
      "Epoch [8/10], Batch [150/1562], Loss: 0.3100\n",
      "Epoch [8/10], Batch [152/1562], Loss: 0.2567\n",
      "Epoch [8/10], Batch [154/1562], Loss: 0.2680\n",
      "Epoch [8/10], Batch [156/1562], Loss: 0.2302\n",
      "Epoch [8/10], Batch [158/1562], Loss: 0.3242\n",
      "Epoch [8/10], Batch [160/1562], Loss: 0.2529\n",
      "Epoch [8/10], Batch [162/1562], Loss: 0.2897\n",
      "Epoch [8/10], Batch [164/1562], Loss: 0.2721\n",
      "Epoch [8/10], Batch [166/1562], Loss: 0.2996\n",
      "Epoch [8/10], Batch [168/1562], Loss: 0.3072\n",
      "Epoch [8/10], Batch [170/1562], Loss: 0.3242\n",
      "Epoch [8/10], Batch [172/1562], Loss: 0.2793\n",
      "Epoch [8/10], Batch [174/1562], Loss: 0.3461\n",
      "Epoch [8/10], Batch [176/1562], Loss: 0.2599\n",
      "Epoch [8/10], Batch [178/1562], Loss: 0.3185\n",
      "Epoch [8/10], Batch [180/1562], Loss: 0.3035\n",
      "Epoch [8/10], Batch [182/1562], Loss: 0.2924\n",
      "Epoch [8/10], Batch [184/1562], Loss: 0.3225\n",
      "Epoch [8/10], Batch [186/1562], Loss: 0.2632\n",
      "Epoch [8/10], Batch [188/1562], Loss: 0.2930\n",
      "Epoch [8/10], Batch [190/1562], Loss: 0.2732\n",
      "Epoch [8/10], Batch [192/1562], Loss: 0.3120\n",
      "Epoch [8/10], Batch [194/1562], Loss: 0.2605\n",
      "Epoch [8/10], Batch [196/1562], Loss: 0.2623\n",
      "Epoch [8/10], Batch [198/1562], Loss: 0.3179\n",
      "Epoch [8/10], Batch [200/1562], Loss: 0.3064\n",
      "Epoch [8/10], Batch [202/1562], Loss: 0.3009\n",
      "Epoch [8/10], Batch [204/1562], Loss: 0.3271\n",
      "Epoch [8/10], Batch [206/1562], Loss: 0.3210\n",
      "Epoch [8/10], Batch [208/1562], Loss: 0.3398\n",
      "Epoch [8/10], Batch [210/1562], Loss: 0.2945\n",
      "Epoch [8/10], Batch [212/1562], Loss: 0.2727\n",
      "Epoch [8/10], Batch [214/1562], Loss: 0.3233\n",
      "Epoch [8/10], Batch [216/1562], Loss: 0.2970\n",
      "Epoch [8/10], Batch [218/1562], Loss: 0.2983\n",
      "Epoch [8/10], Batch [220/1562], Loss: 0.2915\n",
      "Epoch [8/10], Batch [222/1562], Loss: 0.3178\n",
      "Epoch [8/10], Batch [224/1562], Loss: 0.2882\n",
      "Epoch [8/10], Batch [226/1562], Loss: 0.2673\n",
      "Epoch [8/10], Batch [228/1562], Loss: 0.3125\n",
      "Epoch [8/10], Batch [230/1562], Loss: 0.2877\n",
      "Epoch [8/10], Batch [232/1562], Loss: 0.3102\n",
      "Epoch [8/10], Batch [234/1562], Loss: 0.2679\n",
      "Epoch [8/10], Batch [236/1562], Loss: 0.2695\n",
      "Epoch [8/10], Batch [238/1562], Loss: 0.2827\n",
      "Epoch [8/10], Batch [240/1562], Loss: 0.3215\n",
      "Epoch [8/10], Batch [242/1562], Loss: 0.3063\n",
      "Epoch [8/10], Batch [244/1562], Loss: 0.2656\n",
      "Epoch [8/10], Batch [246/1562], Loss: 0.2618\n",
      "Epoch [8/10], Batch [248/1562], Loss: 0.2751\n",
      "Epoch [8/10], Batch [250/1562], Loss: 0.2917\n",
      "Epoch [8/10], Batch [252/1562], Loss: 0.2972\n",
      "Epoch [8/10], Batch [254/1562], Loss: 0.2977\n",
      "Epoch [8/10], Batch [256/1562], Loss: 0.2829\n",
      "Epoch [8/10], Batch [258/1562], Loss: 0.2531\n",
      "Epoch [8/10], Batch [260/1562], Loss: 0.2873\n",
      "Epoch [8/10], Batch [262/1562], Loss: 0.2797\n",
      "Epoch [8/10], Batch [264/1562], Loss: 0.2751\n",
      "Epoch [8/10], Batch [266/1562], Loss: 0.2591\n",
      "Epoch [8/10], Batch [268/1562], Loss: 0.2687\n",
      "Epoch [8/10], Batch [270/1562], Loss: 0.2857\n",
      "Epoch [8/10], Batch [272/1562], Loss: 0.2752\n",
      "Epoch [8/10], Batch [274/1562], Loss: 0.3295\n",
      "Epoch [8/10], Batch [276/1562], Loss: 0.2690\n",
      "Epoch [8/10], Batch [278/1562], Loss: 0.3125\n",
      "Epoch [8/10], Batch [280/1562], Loss: 0.3008\n",
      "Epoch [8/10], Batch [282/1562], Loss: 0.2481\n",
      "Epoch [8/10], Batch [284/1562], Loss: 0.3006\n",
      "Epoch [8/10], Batch [286/1562], Loss: 0.2474\n",
      "Epoch [8/10], Batch [288/1562], Loss: 0.3250\n",
      "Epoch [8/10], Batch [290/1562], Loss: 0.2844\n",
      "Epoch [8/10], Batch [292/1562], Loss: 0.2682\n",
      "Epoch [8/10], Batch [294/1562], Loss: 0.2889\n",
      "Epoch [8/10], Batch [296/1562], Loss: 0.2678\n",
      "Epoch [8/10], Batch [298/1562], Loss: 0.2848\n",
      "Epoch [8/10], Batch [300/1562], Loss: 0.2887\n",
      "Epoch [8/10], Batch [302/1562], Loss: 0.2765\n",
      "Epoch [8/10], Batch [304/1562], Loss: 0.2978\n",
      "Epoch [8/10], Batch [306/1562], Loss: 0.2847\n",
      "Epoch [8/10], Batch [308/1562], Loss: 0.2664\n",
      "Epoch [8/10], Batch [310/1562], Loss: 0.2945\n",
      "Epoch [8/10], Batch [312/1562], Loss: 0.3073\n",
      "Epoch [8/10], Batch [314/1562], Loss: 0.3116\n",
      "Epoch [8/10], Batch [316/1562], Loss: 0.2916\n",
      "Epoch [8/10], Batch [318/1562], Loss: 0.2669\n",
      "Epoch [8/10], Batch [320/1562], Loss: 0.2932\n",
      "Epoch [8/10], Batch [322/1562], Loss: 0.2766\n",
      "Epoch [8/10], Batch [324/1562], Loss: 0.2807\n",
      "Epoch [8/10], Batch [326/1562], Loss: 0.2450\n",
      "Epoch [8/10], Batch [328/1562], Loss: 0.2815\n",
      "Epoch [8/10], Batch [330/1562], Loss: 0.2693\n",
      "Epoch [8/10], Batch [332/1562], Loss: 0.3392\n",
      "Epoch [8/10], Batch [334/1562], Loss: 0.2965\n",
      "Epoch [8/10], Batch [336/1562], Loss: 0.3024\n",
      "Epoch [8/10], Batch [338/1562], Loss: 0.3466\n",
      "Epoch [8/10], Batch [340/1562], Loss: 0.2622\n",
      "Epoch [8/10], Batch [342/1562], Loss: 0.2790\n",
      "Epoch [8/10], Batch [344/1562], Loss: 0.2625\n",
      "Epoch [8/10], Batch [346/1562], Loss: 0.2696\n",
      "Epoch [8/10], Batch [348/1562], Loss: 0.2608\n",
      "Epoch [8/10], Batch [350/1562], Loss: 0.2680\n",
      "Epoch [8/10], Batch [352/1562], Loss: 0.2740\n",
      "Epoch [8/10], Batch [354/1562], Loss: 0.2550\n",
      "Epoch [8/10], Batch [356/1562], Loss: 0.2564\n",
      "Epoch [8/10], Batch [358/1562], Loss: 0.2498\n",
      "Epoch [8/10], Batch [360/1562], Loss: 0.2608\n",
      "Epoch [8/10], Batch [362/1562], Loss: 0.3057\n",
      "Epoch [8/10], Batch [364/1562], Loss: 0.2721\n",
      "Epoch [8/10], Batch [366/1562], Loss: 0.2990\n",
      "Epoch [8/10], Batch [368/1562], Loss: 0.2784\n",
      "Epoch [8/10], Batch [370/1562], Loss: 0.2862\n",
      "Epoch [8/10], Batch [372/1562], Loss: 0.2704\n",
      "Epoch [8/10], Batch [374/1562], Loss: 0.2798\n",
      "Epoch [8/10], Batch [376/1562], Loss: 0.2586\n",
      "Epoch [8/10], Batch [378/1562], Loss: 0.2999\n",
      "Epoch [8/10], Batch [380/1562], Loss: 0.3404\n",
      "Epoch [8/10], Batch [382/1562], Loss: 0.2565\n",
      "Epoch [8/10], Batch [384/1562], Loss: 0.3066\n",
      "Epoch [8/10], Batch [386/1562], Loss: 0.3266\n",
      "Epoch [8/10], Batch [388/1562], Loss: 0.3119\n",
      "Epoch [8/10], Batch [390/1562], Loss: 0.3127\n",
      "Epoch [8/10], Batch [392/1562], Loss: 0.2877\n",
      "Epoch [8/10], Batch [394/1562], Loss: 0.2697\n",
      "Epoch [8/10], Batch [396/1562], Loss: 0.3136\n",
      "Epoch [8/10], Batch [398/1562], Loss: 0.2330\n",
      "Epoch [8/10], Batch [400/1562], Loss: 0.3069\n",
      "Epoch [8/10], Batch [402/1562], Loss: 0.2802\n",
      "Epoch [8/10], Batch [404/1562], Loss: 0.3374\n",
      "Epoch [8/10], Batch [406/1562], Loss: 0.2504\n",
      "Epoch [8/10], Batch [408/1562], Loss: 0.2861\n",
      "Epoch [8/10], Batch [410/1562], Loss: 0.2838\n",
      "Epoch [8/10], Batch [412/1562], Loss: 0.3066\n",
      "Epoch [8/10], Batch [414/1562], Loss: 0.2765\n",
      "Epoch [8/10], Batch [416/1562], Loss: 0.2638\n",
      "Epoch [8/10], Batch [418/1562], Loss: 0.3012\n",
      "Epoch [8/10], Batch [420/1562], Loss: 0.2947\n",
      "Epoch [8/10], Batch [422/1562], Loss: 0.2868\n",
      "Epoch [8/10], Batch [424/1562], Loss: 0.2545\n",
      "Epoch [8/10], Batch [426/1562], Loss: 0.3016\n",
      "Epoch [8/10], Batch [428/1562], Loss: 0.2620\n",
      "Epoch [8/10], Batch [430/1562], Loss: 0.3080\n",
      "Epoch [8/10], Batch [432/1562], Loss: 0.2866\n",
      "Epoch [8/10], Batch [434/1562], Loss: 0.2922\n",
      "Epoch [8/10], Batch [436/1562], Loss: 0.3160\n",
      "Epoch [8/10], Batch [438/1562], Loss: 0.3303\n",
      "Epoch [8/10], Batch [440/1562], Loss: 0.3044\n",
      "Epoch [8/10], Batch [442/1562], Loss: 0.3139\n",
      "Epoch [8/10], Batch [444/1562], Loss: 0.3053\n",
      "Epoch [8/10], Batch [446/1562], Loss: 0.2757\n",
      "Epoch [8/10], Batch [448/1562], Loss: 0.2514\n",
      "Epoch [8/10], Batch [450/1562], Loss: 0.2650\n",
      "Epoch [8/10], Batch [452/1562], Loss: 0.2403\n",
      "Epoch [8/10], Batch [454/1562], Loss: 0.2842\n",
      "Epoch [8/10], Batch [456/1562], Loss: 0.2885\n",
      "Epoch [8/10], Batch [458/1562], Loss: 0.2954\n",
      "Epoch [8/10], Batch [460/1562], Loss: 0.2775\n",
      "Epoch [8/10], Batch [462/1562], Loss: 0.2839\n",
      "Epoch [8/10], Batch [464/1562], Loss: 0.2812\n",
      "Epoch [8/10], Batch [466/1562], Loss: 0.2943\n",
      "Epoch [8/10], Batch [468/1562], Loss: 0.2784\n",
      "Epoch [8/10], Batch [470/1562], Loss: 0.3062\n",
      "Epoch [8/10], Batch [472/1562], Loss: 0.2837\n",
      "Epoch [8/10], Batch [474/1562], Loss: 0.2686\n",
      "Epoch [8/10], Batch [476/1562], Loss: 0.3008\n",
      "Epoch [8/10], Batch [478/1562], Loss: 0.2487\n",
      "Epoch [8/10], Batch [480/1562], Loss: 0.2500\n",
      "Epoch [8/10], Batch [482/1562], Loss: 0.2923\n",
      "Epoch [8/10], Batch [484/1562], Loss: 0.2703\n",
      "Epoch [8/10], Batch [486/1562], Loss: 0.3148\n",
      "Epoch [8/10], Batch [488/1562], Loss: 0.2988\n",
      "Epoch [8/10], Batch [490/1562], Loss: 0.3091\n",
      "Epoch [8/10], Batch [492/1562], Loss: 0.2800\n",
      "Epoch [8/10], Batch [494/1562], Loss: 0.2296\n",
      "Epoch [8/10], Batch [496/1562], Loss: 0.2936\n",
      "Epoch [8/10], Batch [498/1562], Loss: 0.3369\n",
      "Epoch [8/10], Batch [500/1562], Loss: 0.2666\n",
      "Epoch [8/10], Batch [502/1562], Loss: 0.3092\n",
      "Epoch [8/10], Batch [504/1562], Loss: 0.2906\n",
      "Epoch [8/10], Batch [506/1562], Loss: 0.2822\n",
      "Epoch [8/10], Batch [508/1562], Loss: 0.2822\n",
      "Epoch [8/10], Batch [510/1562], Loss: 0.2743\n",
      "Epoch [8/10], Batch [512/1562], Loss: 0.3109\n",
      "Epoch [8/10], Batch [514/1562], Loss: 0.2266\n",
      "Epoch [8/10], Batch [516/1562], Loss: 0.3061\n",
      "Epoch [8/10], Batch [518/1562], Loss: 0.3182\n",
      "Epoch [8/10], Batch [520/1562], Loss: 0.3102\n",
      "Epoch [8/10], Batch [522/1562], Loss: 0.2494\n",
      "Epoch [8/10], Batch [524/1562], Loss: 0.2809\n",
      "Epoch [8/10], Batch [526/1562], Loss: 0.2854\n",
      "Epoch [8/10], Batch [528/1562], Loss: 0.3186\n",
      "Epoch [8/10], Batch [530/1562], Loss: 0.3179\n",
      "Epoch [8/10], Batch [532/1562], Loss: 0.2759\n",
      "Epoch [8/10], Batch [534/1562], Loss: 0.2800\n",
      "Epoch [8/10], Batch [536/1562], Loss: 0.2662\n",
      "Epoch [8/10], Batch [538/1562], Loss: 0.2317\n",
      "Epoch [8/10], Batch [540/1562], Loss: 0.2912\n",
      "Epoch [8/10], Batch [542/1562], Loss: 0.2723\n",
      "Epoch [8/10], Batch [544/1562], Loss: 0.2743\n",
      "Epoch [8/10], Batch [546/1562], Loss: 0.2811\n",
      "Epoch [8/10], Batch [548/1562], Loss: 0.2750\n",
      "Epoch [8/10], Batch [550/1562], Loss: 0.2989\n",
      "Epoch [8/10], Batch [552/1562], Loss: 0.2634\n",
      "Epoch [8/10], Batch [554/1562], Loss: 0.2701\n",
      "Epoch [8/10], Batch [556/1562], Loss: 0.2574\n",
      "Epoch [8/10], Batch [558/1562], Loss: 0.3002\n",
      "Epoch [8/10], Batch [560/1562], Loss: 0.3042\n",
      "Epoch [8/10], Batch [562/1562], Loss: 0.2876\n",
      "Epoch [8/10], Batch [564/1562], Loss: 0.3271\n",
      "Epoch [8/10], Batch [566/1562], Loss: 0.3093\n",
      "Epoch [8/10], Batch [568/1562], Loss: 0.2954\n",
      "Epoch [8/10], Batch [570/1562], Loss: 0.3315\n",
      "Epoch [8/10], Batch [572/1562], Loss: 0.2822\n",
      "Epoch [8/10], Batch [574/1562], Loss: 0.2891\n",
      "Epoch [8/10], Batch [576/1562], Loss: 0.2877\n",
      "Epoch [8/10], Batch [578/1562], Loss: 0.2551\n",
      "Epoch [8/10], Batch [580/1562], Loss: 0.2567\n",
      "Epoch [8/10], Batch [582/1562], Loss: 0.2534\n",
      "Epoch [8/10], Batch [584/1562], Loss: 0.2503\n",
      "Epoch [8/10], Batch [586/1562], Loss: 0.3207\n",
      "Epoch [8/10], Batch [588/1562], Loss: 0.2628\n",
      "Epoch [8/10], Batch [590/1562], Loss: 0.2888\n",
      "Epoch [8/10], Batch [592/1562], Loss: 0.3154\n",
      "Epoch [8/10], Batch [594/1562], Loss: 0.2481\n",
      "Epoch [8/10], Batch [596/1562], Loss: 0.2599\n",
      "Epoch [8/10], Batch [598/1562], Loss: 0.2638\n",
      "Epoch [8/10], Batch [600/1562], Loss: 0.2861\n",
      "Epoch [8/10], Batch [602/1562], Loss: 0.2546\n",
      "Epoch [8/10], Batch [604/1562], Loss: 0.2953\n",
      "Epoch [8/10], Batch [606/1562], Loss: 0.3019\n",
      "Epoch [8/10], Batch [608/1562], Loss: 0.3038\n",
      "Epoch [8/10], Batch [610/1562], Loss: 0.2807\n",
      "Epoch [8/10], Batch [612/1562], Loss: 0.2745\n",
      "Epoch [8/10], Batch [614/1562], Loss: 0.3143\n",
      "Epoch [8/10], Batch [616/1562], Loss: 0.2640\n",
      "Epoch [8/10], Batch [618/1562], Loss: 0.2768\n",
      "Epoch [8/10], Batch [620/1562], Loss: 0.3045\n",
      "Epoch [8/10], Batch [622/1562], Loss: 0.2989\n",
      "Epoch [8/10], Batch [624/1562], Loss: 0.2776\n",
      "Epoch [8/10], Batch [626/1562], Loss: 0.2939\n",
      "Epoch [8/10], Batch [628/1562], Loss: 0.2930\n",
      "Epoch [8/10], Batch [630/1562], Loss: 0.2667\n",
      "Epoch [8/10], Batch [632/1562], Loss: 0.2824\n",
      "Epoch [8/10], Batch [634/1562], Loss: 0.2911\n",
      "Epoch [8/10], Batch [636/1562], Loss: 0.2618\n",
      "Epoch [8/10], Batch [638/1562], Loss: 0.3131\n",
      "Epoch [8/10], Batch [640/1562], Loss: 0.2894\n",
      "Epoch [8/10], Batch [642/1562], Loss: 0.2632\n",
      "Epoch [8/10], Batch [644/1562], Loss: 0.3093\n",
      "Epoch [8/10], Batch [646/1562], Loss: 0.2801\n",
      "Epoch [8/10], Batch [648/1562], Loss: 0.3165\n",
      "Epoch [8/10], Batch [650/1562], Loss: 0.3578\n",
      "Epoch [8/10], Batch [652/1562], Loss: 0.3215\n",
      "Epoch [8/10], Batch [654/1562], Loss: 0.3062\n",
      "Epoch [8/10], Batch [656/1562], Loss: 0.3143\n",
      "Epoch [8/10], Batch [658/1562], Loss: 0.2662\n",
      "Epoch [8/10], Batch [660/1562], Loss: 0.3010\n",
      "Epoch [8/10], Batch [662/1562], Loss: 0.2694\n",
      "Epoch [8/10], Batch [664/1562], Loss: 0.2919\n",
      "Epoch [8/10], Batch [666/1562], Loss: 0.3053\n",
      "Epoch [8/10], Batch [668/1562], Loss: 0.2696\n",
      "Epoch [8/10], Batch [670/1562], Loss: 0.2955\n",
      "Epoch [8/10], Batch [672/1562], Loss: 0.3012\n",
      "Epoch [8/10], Batch [674/1562], Loss: 0.2627\n",
      "Epoch [8/10], Batch [676/1562], Loss: 0.2738\n",
      "Epoch [8/10], Batch [678/1562], Loss: 0.2765\n",
      "Epoch [8/10], Batch [680/1562], Loss: 0.3031\n",
      "Epoch [8/10], Batch [682/1562], Loss: 0.2758\n",
      "Epoch [8/10], Batch [684/1562], Loss: 0.3025\n",
      "Epoch [8/10], Batch [686/1562], Loss: 0.2852\n",
      "Epoch [8/10], Batch [688/1562], Loss: 0.2649\n",
      "Epoch [8/10], Batch [690/1562], Loss: 0.2903\n",
      "Epoch [8/10], Batch [692/1562], Loss: 0.2566\n",
      "Epoch [8/10], Batch [694/1562], Loss: 0.3146\n",
      "Epoch [8/10], Batch [696/1562], Loss: 0.2697\n",
      "Epoch [8/10], Batch [698/1562], Loss: 0.2607\n",
      "Epoch [8/10], Batch [700/1562], Loss: 0.2566\n",
      "Epoch [8/10], Batch [702/1562], Loss: 0.3072\n",
      "Epoch [8/10], Batch [704/1562], Loss: 0.3206\n",
      "Epoch [8/10], Batch [706/1562], Loss: 0.2701\n",
      "Epoch [8/10], Batch [708/1562], Loss: 0.3387\n",
      "Epoch [8/10], Batch [710/1562], Loss: 0.3003\n",
      "Epoch [8/10], Batch [712/1562], Loss: 0.2758\n",
      "Epoch [8/10], Batch [714/1562], Loss: 0.3117\n",
      "Epoch [8/10], Batch [716/1562], Loss: 0.3247\n",
      "Epoch [8/10], Batch [718/1562], Loss: 0.3093\n",
      "Epoch [8/10], Batch [720/1562], Loss: 0.3100\n",
      "Epoch [8/10], Batch [722/1562], Loss: 0.2807\n",
      "Epoch [8/10], Batch [724/1562], Loss: 0.2876\n",
      "Epoch [8/10], Batch [726/1562], Loss: 0.2953\n",
      "Epoch [8/10], Batch [728/1562], Loss: 0.3258\n",
      "Epoch [8/10], Batch [730/1562], Loss: 0.2726\n",
      "Epoch [8/10], Batch [732/1562], Loss: 0.2811\n",
      "Epoch [8/10], Batch [734/1562], Loss: 0.2766\n",
      "Epoch [8/10], Batch [736/1562], Loss: 0.2713\n",
      "Epoch [8/10], Batch [738/1562], Loss: 0.2337\n",
      "Epoch [8/10], Batch [740/1562], Loss: 0.2778\n",
      "Epoch [8/10], Batch [742/1562], Loss: 0.3013\n",
      "Epoch [8/10], Batch [744/1562], Loss: 0.2285\n",
      "Epoch [8/10], Batch [746/1562], Loss: 0.2875\n",
      "Epoch [8/10], Batch [748/1562], Loss: 0.3087\n",
      "Epoch [8/10], Batch [750/1562], Loss: 0.3131\n",
      "Epoch [8/10], Batch [752/1562], Loss: 0.2874\n",
      "Epoch [8/10], Batch [754/1562], Loss: 0.2517\n",
      "Epoch [8/10], Batch [756/1562], Loss: 0.3175\n",
      "Epoch [8/10], Batch [758/1562], Loss: 0.2947\n",
      "Epoch [8/10], Batch [760/1562], Loss: 0.2682\n",
      "Epoch [8/10], Batch [762/1562], Loss: 0.2778\n",
      "Epoch [8/10], Batch [764/1562], Loss: 0.2884\n",
      "Epoch [8/10], Batch [766/1562], Loss: 0.2467\n",
      "Epoch [8/10], Batch [768/1562], Loss: 0.2881\n",
      "Epoch [8/10], Batch [770/1562], Loss: 0.3150\n",
      "Epoch [8/10], Batch [772/1562], Loss: 0.2943\n",
      "Epoch [8/10], Batch [774/1562], Loss: 0.2973\n",
      "Epoch [8/10], Batch [776/1562], Loss: 0.3022\n",
      "Epoch [8/10], Batch [778/1562], Loss: 0.2741\n",
      "Epoch [8/10], Batch [780/1562], Loss: 0.2929\n",
      "Epoch [8/10], Batch [782/1562], Loss: 0.2941\n",
      "Epoch [8/10], Batch [784/1562], Loss: 0.2836\n",
      "Epoch [8/10], Batch [786/1562], Loss: 0.2680\n",
      "Epoch [8/10], Batch [788/1562], Loss: 0.2972\n",
      "Epoch [8/10], Batch [790/1562], Loss: 0.2832\n",
      "Epoch [8/10], Batch [792/1562], Loss: 0.3165\n",
      "Epoch [8/10], Batch [794/1562], Loss: 0.3004\n",
      "Epoch [8/10], Batch [796/1562], Loss: 0.2803\n",
      "Epoch [8/10], Batch [798/1562], Loss: 0.3336\n",
      "Epoch [8/10], Batch [800/1562], Loss: 0.2817\n",
      "Epoch [8/10], Batch [802/1562], Loss: 0.2757\n",
      "Epoch [8/10], Batch [804/1562], Loss: 0.2781\n",
      "Epoch [8/10], Batch [806/1562], Loss: 0.2991\n",
      "Epoch [8/10], Batch [808/1562], Loss: 0.2702\n",
      "Epoch [8/10], Batch [810/1562], Loss: 0.2665\n",
      "Epoch [8/10], Batch [812/1562], Loss: 0.3103\n",
      "Epoch [8/10], Batch [814/1562], Loss: 0.2857\n",
      "Epoch [8/10], Batch [816/1562], Loss: 0.2836\n",
      "Epoch [8/10], Batch [818/1562], Loss: 0.2865\n",
      "Epoch [8/10], Batch [820/1562], Loss: 0.2722\n",
      "Epoch [8/10], Batch [822/1562], Loss: 0.2764\n",
      "Epoch [8/10], Batch [824/1562], Loss: 0.2935\n",
      "Epoch [8/10], Batch [826/1562], Loss: 0.3214\n",
      "Epoch [8/10], Batch [828/1562], Loss: 0.2744\n",
      "Epoch [8/10], Batch [830/1562], Loss: 0.2712\n",
      "Epoch [8/10], Batch [832/1562], Loss: 0.3169\n",
      "Epoch [8/10], Batch [834/1562], Loss: 0.3201\n",
      "Epoch [8/10], Batch [836/1562], Loss: 0.3108\n",
      "Epoch [8/10], Batch [838/1562], Loss: 0.3223\n",
      "Epoch [8/10], Batch [840/1562], Loss: 0.2850\n",
      "Epoch [8/10], Batch [842/1562], Loss: 0.2843\n",
      "Epoch [8/10], Batch [844/1562], Loss: 0.2647\n",
      "Epoch [8/10], Batch [846/1562], Loss: 0.2847\n",
      "Epoch [8/10], Batch [848/1562], Loss: 0.2855\n",
      "Epoch [8/10], Batch [850/1562], Loss: 0.2754\n",
      "Epoch [8/10], Batch [852/1562], Loss: 0.3381\n",
      "Epoch [8/10], Batch [854/1562], Loss: 0.3354\n",
      "Epoch [8/10], Batch [856/1562], Loss: 0.3019\n",
      "Epoch [8/10], Batch [858/1562], Loss: 0.2819\n",
      "Epoch [8/10], Batch [860/1562], Loss: 0.2570\n",
      "Epoch [8/10], Batch [862/1562], Loss: 0.2854\n",
      "Epoch [8/10], Batch [864/1562], Loss: 0.2773\n",
      "Epoch [8/10], Batch [866/1562], Loss: 0.2825\n",
      "Epoch [8/10], Batch [868/1562], Loss: 0.2890\n",
      "Epoch [8/10], Batch [870/1562], Loss: 0.2846\n",
      "Epoch [8/10], Batch [872/1562], Loss: 0.2943\n",
      "Epoch [8/10], Batch [874/1562], Loss: 0.2763\n",
      "Epoch [8/10], Batch [876/1562], Loss: 0.2829\n",
      "Epoch [8/10], Batch [878/1562], Loss: 0.2986\n",
      "Epoch [8/10], Batch [880/1562], Loss: 0.2447\n",
      "Epoch [8/10], Batch [882/1562], Loss: 0.2790\n",
      "Epoch [8/10], Batch [884/1562], Loss: 0.2728\n",
      "Epoch [8/10], Batch [886/1562], Loss: 0.2618\n",
      "Epoch [8/10], Batch [888/1562], Loss: 0.3068\n",
      "Epoch [8/10], Batch [890/1562], Loss: 0.2785\n",
      "Epoch [8/10], Batch [892/1562], Loss: 0.2879\n",
      "Epoch [8/10], Batch [894/1562], Loss: 0.3003\n",
      "Epoch [8/10], Batch [896/1562], Loss: 0.3119\n",
      "Epoch [8/10], Batch [898/1562], Loss: 0.3181\n",
      "Epoch [8/10], Batch [900/1562], Loss: 0.3305\n",
      "Epoch [8/10], Batch [902/1562], Loss: 0.3046\n",
      "Epoch [8/10], Batch [904/1562], Loss: 0.2631\n",
      "Epoch [8/10], Batch [906/1562], Loss: 0.3144\n",
      "Epoch [8/10], Batch [908/1562], Loss: 0.2903\n",
      "Epoch [8/10], Batch [910/1562], Loss: 0.2773\n",
      "Epoch [8/10], Batch [912/1562], Loss: 0.3224\n",
      "Epoch [8/10], Batch [914/1562], Loss: 0.2784\n",
      "Epoch [8/10], Batch [916/1562], Loss: 0.2601\n",
      "Epoch [8/10], Batch [918/1562], Loss: 0.3175\n",
      "Epoch [8/10], Batch [920/1562], Loss: 0.2854\n",
      "Epoch [8/10], Batch [922/1562], Loss: 0.2832\n",
      "Epoch [8/10], Batch [924/1562], Loss: 0.3052\n",
      "Epoch [8/10], Batch [926/1562], Loss: 0.3032\n",
      "Epoch [8/10], Batch [928/1562], Loss: 0.2872\n",
      "Epoch [8/10], Batch [930/1562], Loss: 0.2751\n",
      "Epoch [8/10], Batch [932/1562], Loss: 0.3004\n",
      "Epoch [8/10], Batch [934/1562], Loss: 0.2940\n",
      "Epoch [8/10], Batch [936/1562], Loss: 0.2910\n",
      "Epoch [8/10], Batch [938/1562], Loss: 0.3036\n",
      "Epoch [8/10], Batch [940/1562], Loss: 0.2832\n",
      "Epoch [8/10], Batch [942/1562], Loss: 0.2494\n",
      "Epoch [8/10], Batch [944/1562], Loss: 0.2842\n",
      "Epoch [8/10], Batch [946/1562], Loss: 0.3181\n",
      "Epoch [8/10], Batch [948/1562], Loss: 0.2915\n",
      "Epoch [8/10], Batch [950/1562], Loss: 0.2824\n",
      "Epoch [8/10], Batch [952/1562], Loss: 0.2992\n",
      "Epoch [8/10], Batch [954/1562], Loss: 0.2742\n",
      "Epoch [8/10], Batch [956/1562], Loss: 0.3149\n",
      "Epoch [8/10], Batch [958/1562], Loss: 0.2822\n",
      "Epoch [8/10], Batch [960/1562], Loss: 0.2583\n",
      "Epoch [8/10], Batch [962/1562], Loss: 0.2845\n",
      "Epoch [8/10], Batch [964/1562], Loss: 0.2524\n",
      "Epoch [8/10], Batch [966/1562], Loss: 0.2962\n",
      "Epoch [8/10], Batch [968/1562], Loss: 0.2785\n",
      "Epoch [8/10], Batch [970/1562], Loss: 0.2898\n",
      "Epoch [8/10], Batch [972/1562], Loss: 0.2650\n",
      "Epoch [8/10], Batch [974/1562], Loss: 0.2655\n",
      "Epoch [8/10], Batch [976/1562], Loss: 0.2911\n",
      "Epoch [8/10], Batch [978/1562], Loss: 0.3072\n",
      "Epoch [8/10], Batch [980/1562], Loss: 0.2987\n",
      "Epoch [8/10], Batch [982/1562], Loss: 0.2456\n",
      "Epoch [8/10], Batch [984/1562], Loss: 0.3074\n",
      "Epoch [8/10], Batch [986/1562], Loss: 0.3053\n",
      "Epoch [8/10], Batch [988/1562], Loss: 0.3093\n",
      "Epoch [8/10], Batch [990/1562], Loss: 0.3086\n",
      "Epoch [8/10], Batch [992/1562], Loss: 0.3126\n",
      "Epoch [8/10], Batch [994/1562], Loss: 0.2880\n",
      "Epoch [8/10], Batch [996/1562], Loss: 0.2964\n",
      "Epoch [8/10], Batch [998/1562], Loss: 0.2695\n",
      "Epoch [8/10], Batch [1000/1562], Loss: 0.2952\n",
      "Epoch [8/10], Batch [1002/1562], Loss: 0.2804\n",
      "Epoch [8/10], Batch [1004/1562], Loss: 0.3297\n",
      "Epoch [8/10], Batch [1006/1562], Loss: 0.2654\n",
      "Epoch [8/10], Batch [1008/1562], Loss: 0.2844\n",
      "Epoch [8/10], Batch [1010/1562], Loss: 0.3055\n",
      "Epoch [8/10], Batch [1012/1562], Loss: 0.3254\n",
      "Epoch [8/10], Batch [1014/1562], Loss: 0.2888\n",
      "Epoch [8/10], Batch [1016/1562], Loss: 0.3149\n",
      "Epoch [8/10], Batch [1018/1562], Loss: 0.3135\n",
      "Epoch [8/10], Batch [1020/1562], Loss: 0.2827\n",
      "Epoch [8/10], Batch [1022/1562], Loss: 0.3111\n",
      "Epoch [8/10], Batch [1024/1562], Loss: 0.2676\n",
      "Epoch [8/10], Batch [1026/1562], Loss: 0.2748\n",
      "Epoch [8/10], Batch [1028/1562], Loss: 0.2954\n",
      "Epoch [8/10], Batch [1030/1562], Loss: 0.2583\n",
      "Epoch [8/10], Batch [1032/1562], Loss: 0.2754\n",
      "Epoch [8/10], Batch [1034/1562], Loss: 0.2605\n",
      "Epoch [8/10], Batch [1036/1562], Loss: 0.2749\n",
      "Epoch [8/10], Batch [1038/1562], Loss: 0.3020\n",
      "Epoch [8/10], Batch [1040/1562], Loss: 0.2622\n",
      "Epoch [8/10], Batch [1042/1562], Loss: 0.3051\n",
      "Epoch [8/10], Batch [1044/1562], Loss: 0.2981\n",
      "Epoch [8/10], Batch [1046/1562], Loss: 0.2922\n",
      "Epoch [8/10], Batch [1048/1562], Loss: 0.2508\n",
      "Epoch [8/10], Batch [1050/1562], Loss: 0.3008\n",
      "Epoch [8/10], Batch [1052/1562], Loss: 0.3077\n",
      "Epoch [8/10], Batch [1054/1562], Loss: 0.2699\n",
      "Epoch [8/10], Batch [1056/1562], Loss: 0.2918\n",
      "Epoch [8/10], Batch [1058/1562], Loss: 0.3169\n",
      "Epoch [8/10], Batch [1060/1562], Loss: 0.3069\n",
      "Epoch [8/10], Batch [1062/1562], Loss: 0.2703\n",
      "Epoch [8/10], Batch [1064/1562], Loss: 0.2394\n",
      "Epoch [8/10], Batch [1066/1562], Loss: 0.3232\n",
      "Epoch [8/10], Batch [1068/1562], Loss: 0.2715\n",
      "Epoch [8/10], Batch [1070/1562], Loss: 0.2896\n",
      "Epoch [8/10], Batch [1072/1562], Loss: 0.2856\n",
      "Epoch [8/10], Batch [1074/1562], Loss: 0.2682\n",
      "Epoch [8/10], Batch [1076/1562], Loss: 0.3033\n",
      "Epoch [8/10], Batch [1078/1562], Loss: 0.2732\n",
      "Epoch [8/10], Batch [1080/1562], Loss: 0.2902\n",
      "Epoch [8/10], Batch [1082/1562], Loss: 0.3102\n",
      "Epoch [8/10], Batch [1084/1562], Loss: 0.3059\n",
      "Epoch [8/10], Batch [1086/1562], Loss: 0.2825\n",
      "Epoch [8/10], Batch [1088/1562], Loss: 0.2933\n",
      "Epoch [8/10], Batch [1090/1562], Loss: 0.2819\n",
      "Epoch [8/10], Batch [1092/1562], Loss: 0.2919\n",
      "Epoch [8/10], Batch [1094/1562], Loss: 0.2753\n",
      "Epoch [8/10], Batch [1096/1562], Loss: 0.2892\n",
      "Epoch [8/10], Batch [1098/1562], Loss: 0.2368\n",
      "Epoch [8/10], Batch [1100/1562], Loss: 0.2573\n",
      "Epoch [8/10], Batch [1102/1562], Loss: 0.2676\n",
      "Epoch [8/10], Batch [1104/1562], Loss: 0.2880\n",
      "Epoch [8/10], Batch [1106/1562], Loss: 0.3071\n",
      "Epoch [8/10], Batch [1108/1562], Loss: 0.2491\n",
      "Epoch [8/10], Batch [1110/1562], Loss: 0.3048\n",
      "Epoch [8/10], Batch [1112/1562], Loss: 0.3115\n",
      "Epoch [8/10], Batch [1114/1562], Loss: 0.2819\n",
      "Epoch [8/10], Batch [1116/1562], Loss: 0.2844\n",
      "Epoch [8/10], Batch [1118/1562], Loss: 0.2940\n",
      "Epoch [8/10], Batch [1120/1562], Loss: 0.2827\n",
      "Epoch [8/10], Batch [1122/1562], Loss: 0.2715\n",
      "Epoch [8/10], Batch [1124/1562], Loss: 0.2428\n",
      "Epoch [8/10], Batch [1126/1562], Loss: 0.3051\n",
      "Epoch [8/10], Batch [1128/1562], Loss: 0.2809\n",
      "Epoch [8/10], Batch [1130/1562], Loss: 0.2712\n",
      "Epoch [8/10], Batch [1132/1562], Loss: 0.2862\n",
      "Epoch [8/10], Batch [1134/1562], Loss: 0.3177\n",
      "Epoch [8/10], Batch [1136/1562], Loss: 0.2591\n",
      "Epoch [8/10], Batch [1138/1562], Loss: 0.2716\n",
      "Epoch [8/10], Batch [1140/1562], Loss: 0.3139\n",
      "Epoch [8/10], Batch [1142/1562], Loss: 0.3163\n",
      "Epoch [8/10], Batch [1144/1562], Loss: 0.2489\n",
      "Epoch [8/10], Batch [1146/1562], Loss: 0.2704\n",
      "Epoch [8/10], Batch [1148/1562], Loss: 0.2850\n",
      "Epoch [8/10], Batch [1150/1562], Loss: 0.2916\n",
      "Epoch [8/10], Batch [1152/1562], Loss: 0.3187\n",
      "Epoch [8/10], Batch [1154/1562], Loss: 0.2841\n",
      "Epoch [8/10], Batch [1156/1562], Loss: 0.2581\n",
      "Epoch [8/10], Batch [1158/1562], Loss: 0.2910\n",
      "Epoch [8/10], Batch [1160/1562], Loss: 0.2930\n",
      "Epoch [8/10], Batch [1162/1562], Loss: 0.2836\n",
      "Epoch [8/10], Batch [1164/1562], Loss: 0.2565\n",
      "Epoch [8/10], Batch [1166/1562], Loss: 0.3284\n",
      "Epoch [8/10], Batch [1168/1562], Loss: 0.2715\n",
      "Epoch [8/10], Batch [1170/1562], Loss: 0.3008\n",
      "Epoch [8/10], Batch [1172/1562], Loss: 0.2995\n",
      "Epoch [8/10], Batch [1174/1562], Loss: 0.3163\n",
      "Epoch [8/10], Batch [1176/1562], Loss: 0.2861\n",
      "Epoch [8/10], Batch [1178/1562], Loss: 0.2710\n",
      "Epoch [8/10], Batch [1180/1562], Loss: 0.2465\n",
      "Epoch [8/10], Batch [1182/1562], Loss: 0.2881\n",
      "Epoch [8/10], Batch [1184/1562], Loss: 0.3168\n",
      "Epoch [8/10], Batch [1186/1562], Loss: 0.3300\n",
      "Epoch [8/10], Batch [1188/1562], Loss: 0.2840\n",
      "Epoch [8/10], Batch [1190/1562], Loss: 0.2743\n",
      "Epoch [8/10], Batch [1192/1562], Loss: 0.3552\n",
      "Epoch [8/10], Batch [1194/1562], Loss: 0.2688\n",
      "Epoch [8/10], Batch [1196/1562], Loss: 0.2660\n",
      "Epoch [8/10], Batch [1198/1562], Loss: 0.2992\n",
      "Epoch [8/10], Batch [1200/1562], Loss: 0.2806\n",
      "Epoch [8/10], Batch [1202/1562], Loss: 0.2705\n",
      "Epoch [8/10], Batch [1204/1562], Loss: 0.3026\n",
      "Epoch [8/10], Batch [1206/1562], Loss: 0.2697\n",
      "Epoch [8/10], Batch [1208/1562], Loss: 0.2352\n",
      "Epoch [8/10], Batch [1210/1562], Loss: 0.2621\n",
      "Epoch [8/10], Batch [1212/1562], Loss: 0.3227\n",
      "Epoch [8/10], Batch [1214/1562], Loss: 0.3005\n",
      "Epoch [8/10], Batch [1216/1562], Loss: 0.3105\n",
      "Epoch [8/10], Batch [1218/1562], Loss: 0.2520\n",
      "Epoch [8/10], Batch [1220/1562], Loss: 0.3483\n",
      "Epoch [8/10], Batch [1222/1562], Loss: 0.2558\n",
      "Epoch [8/10], Batch [1224/1562], Loss: 0.2539\n",
      "Epoch [8/10], Batch [1226/1562], Loss: 0.3057\n",
      "Epoch [8/10], Batch [1228/1562], Loss: 0.2580\n",
      "Epoch [8/10], Batch [1230/1562], Loss: 0.2998\n",
      "Epoch [8/10], Batch [1232/1562], Loss: 0.2878\n",
      "Epoch [8/10], Batch [1234/1562], Loss: 0.3150\n",
      "Epoch [8/10], Batch [1236/1562], Loss: 0.2410\n",
      "Epoch [8/10], Batch [1238/1562], Loss: 0.2708\n",
      "Epoch [8/10], Batch [1240/1562], Loss: 0.3032\n",
      "Epoch [8/10], Batch [1242/1562], Loss: 0.3140\n",
      "Epoch [8/10], Batch [1244/1562], Loss: 0.2803\n",
      "Epoch [8/10], Batch [1246/1562], Loss: 0.3185\n",
      "Epoch [8/10], Batch [1248/1562], Loss: 0.3010\n",
      "Epoch [8/10], Batch [1250/1562], Loss: 0.2891\n",
      "Epoch [8/10], Batch [1252/1562], Loss: 0.3399\n",
      "Epoch [8/10], Batch [1254/1562], Loss: 0.3120\n",
      "Epoch [8/10], Batch [1256/1562], Loss: 0.3052\n",
      "Epoch [8/10], Batch [1258/1562], Loss: 0.2587\n",
      "Epoch [8/10], Batch [1260/1562], Loss: 0.2726\n",
      "Epoch [8/10], Batch [1262/1562], Loss: 0.2807\n",
      "Epoch [8/10], Batch [1264/1562], Loss: 0.3000\n",
      "Epoch [8/10], Batch [1266/1562], Loss: 0.2901\n",
      "Epoch [8/10], Batch [1268/1562], Loss: 0.2358\n",
      "Epoch [8/10], Batch [1270/1562], Loss: 0.2533\n",
      "Epoch [8/10], Batch [1272/1562], Loss: 0.2816\n",
      "Epoch [8/10], Batch [1274/1562], Loss: 0.3002\n",
      "Epoch [8/10], Batch [1276/1562], Loss: 0.2881\n",
      "Epoch [8/10], Batch [1278/1562], Loss: 0.2805\n",
      "Epoch [8/10], Batch [1280/1562], Loss: 0.2385\n",
      "Epoch [8/10], Batch [1282/1562], Loss: 0.3176\n",
      "Epoch [8/10], Batch [1284/1562], Loss: 0.2834\n",
      "Epoch [8/10], Batch [1286/1562], Loss: 0.2505\n",
      "Epoch [8/10], Batch [1288/1562], Loss: 0.3001\n",
      "Epoch [8/10], Batch [1290/1562], Loss: 0.2886\n",
      "Epoch [8/10], Batch [1292/1562], Loss: 0.3348\n",
      "Epoch [8/10], Batch [1294/1562], Loss: 0.3166\n",
      "Epoch [8/10], Batch [1296/1562], Loss: 0.2870\n",
      "Epoch [8/10], Batch [1298/1562], Loss: 0.3109\n",
      "Epoch [8/10], Batch [1300/1562], Loss: 0.2884\n",
      "Epoch [8/10], Batch [1302/1562], Loss: 0.2820\n",
      "Epoch [8/10], Batch [1304/1562], Loss: 0.2784\n",
      "Epoch [8/10], Batch [1306/1562], Loss: 0.2845\n",
      "Epoch [8/10], Batch [1308/1562], Loss: 0.3114\n",
      "Epoch [8/10], Batch [1310/1562], Loss: 0.2785\n",
      "Epoch [8/10], Batch [1312/1562], Loss: 0.3195\n",
      "Epoch [8/10], Batch [1314/1562], Loss: 0.2798\n",
      "Epoch [8/10], Batch [1316/1562], Loss: 0.3184\n",
      "Epoch [8/10], Batch [1318/1562], Loss: 0.3043\n",
      "Epoch [8/10], Batch [1320/1562], Loss: 0.2942\n",
      "Epoch [8/10], Batch [1322/1562], Loss: 0.2482\n",
      "Epoch [8/10], Batch [1324/1562], Loss: 0.2967\n",
      "Epoch [8/10], Batch [1326/1562], Loss: 0.2933\n",
      "Epoch [8/10], Batch [1328/1562], Loss: 0.2759\n",
      "Epoch [8/10], Batch [1330/1562], Loss: 0.2536\n",
      "Epoch [8/10], Batch [1332/1562], Loss: 0.2580\n",
      "Epoch [8/10], Batch [1334/1562], Loss: 0.3057\n",
      "Epoch [8/10], Batch [1336/1562], Loss: 0.3110\n",
      "Epoch [8/10], Batch [1338/1562], Loss: 0.2823\n",
      "Epoch [8/10], Batch [1340/1562], Loss: 0.2712\n",
      "Epoch [8/10], Batch [1342/1562], Loss: 0.2719\n",
      "Epoch [8/10], Batch [1344/1562], Loss: 0.2969\n",
      "Epoch [8/10], Batch [1346/1562], Loss: 0.3179\n",
      "Epoch [8/10], Batch [1348/1562], Loss: 0.2452\n",
      "Epoch [8/10], Batch [1350/1562], Loss: 0.3554\n",
      "Epoch [8/10], Batch [1352/1562], Loss: 0.3284\n",
      "Epoch [8/10], Batch [1354/1562], Loss: 0.2916\n",
      "Epoch [8/10], Batch [1356/1562], Loss: 0.2655\n",
      "Epoch [8/10], Batch [1358/1562], Loss: 0.2759\n",
      "Epoch [8/10], Batch [1360/1562], Loss: 0.2946\n",
      "Epoch [8/10], Batch [1362/1562], Loss: 0.2834\n",
      "Epoch [8/10], Batch [1364/1562], Loss: 0.2591\n",
      "Epoch [8/10], Batch [1366/1562], Loss: 0.2651\n",
      "Epoch [8/10], Batch [1368/1562], Loss: 0.3189\n",
      "Epoch [8/10], Batch [1370/1562], Loss: 0.2779\n",
      "Epoch [8/10], Batch [1372/1562], Loss: 0.3122\n",
      "Epoch [8/10], Batch [1374/1562], Loss: 0.2673\n",
      "Epoch [8/10], Batch [1376/1562], Loss: 0.2680\n",
      "Epoch [8/10], Batch [1378/1562], Loss: 0.2644\n",
      "Epoch [8/10], Batch [1380/1562], Loss: 0.2845\n",
      "Epoch [8/10], Batch [1382/1562], Loss: 0.2754\n",
      "Epoch [8/10], Batch [1384/1562], Loss: 0.2563\n",
      "Epoch [8/10], Batch [1386/1562], Loss: 0.3052\n",
      "Epoch [8/10], Batch [1388/1562], Loss: 0.3387\n",
      "Epoch [8/10], Batch [1390/1562], Loss: 0.3058\n",
      "Epoch [8/10], Batch [1392/1562], Loss: 0.2989\n",
      "Epoch [8/10], Batch [1394/1562], Loss: 0.2775\n",
      "Epoch [8/10], Batch [1396/1562], Loss: 0.2482\n",
      "Epoch [8/10], Batch [1398/1562], Loss: 0.3054\n",
      "Epoch [8/10], Batch [1400/1562], Loss: 0.2575\n",
      "Epoch [8/10], Batch [1402/1562], Loss: 0.2926\n",
      "Epoch [8/10], Batch [1404/1562], Loss: 0.3073\n",
      "Epoch [8/10], Batch [1406/1562], Loss: 0.2933\n",
      "Epoch [8/10], Batch [1408/1562], Loss: 0.2542\n",
      "Epoch [8/10], Batch [1410/1562], Loss: 0.2449\n",
      "Epoch [8/10], Batch [1412/1562], Loss: 0.3030\n",
      "Epoch [8/10], Batch [1414/1562], Loss: 0.2790\n",
      "Epoch [8/10], Batch [1416/1562], Loss: 0.2823\n",
      "Epoch [8/10], Batch [1418/1562], Loss: 0.2859\n",
      "Epoch [8/10], Batch [1420/1562], Loss: 0.2892\n",
      "Epoch [8/10], Batch [1422/1562], Loss: 0.2572\n",
      "Epoch [8/10], Batch [1424/1562], Loss: 0.2898\n",
      "Epoch [8/10], Batch [1426/1562], Loss: 0.3251\n",
      "Epoch [8/10], Batch [1428/1562], Loss: 0.2620\n",
      "Epoch [8/10], Batch [1430/1562], Loss: 0.2969\n",
      "Epoch [8/10], Batch [1432/1562], Loss: 0.2590\n",
      "Epoch [8/10], Batch [1434/1562], Loss: 0.3287\n",
      "Epoch [8/10], Batch [1436/1562], Loss: 0.2598\n",
      "Epoch [8/10], Batch [1438/1562], Loss: 0.2721\n",
      "Epoch [8/10], Batch [1440/1562], Loss: 0.2584\n",
      "Epoch [8/10], Batch [1442/1562], Loss: 0.2632\n",
      "Epoch [8/10], Batch [1444/1562], Loss: 0.3031\n",
      "Epoch [8/10], Batch [1446/1562], Loss: 0.2792\n",
      "Epoch [8/10], Batch [1448/1562], Loss: 0.2647\n",
      "Epoch [8/10], Batch [1450/1562], Loss: 0.3122\n",
      "Epoch [8/10], Batch [1452/1562], Loss: 0.2963\n",
      "Epoch [8/10], Batch [1454/1562], Loss: 0.2617\n",
      "Epoch [8/10], Batch [1456/1562], Loss: 0.2870\n",
      "Epoch [8/10], Batch [1458/1562], Loss: 0.2813\n",
      "Epoch [8/10], Batch [1460/1562], Loss: 0.2446\n",
      "Epoch [8/10], Batch [1462/1562], Loss: 0.2876\n",
      "Epoch [8/10], Batch [1464/1562], Loss: 0.2808\n",
      "Epoch [8/10], Batch [1466/1562], Loss: 0.3021\n",
      "Epoch [8/10], Batch [1468/1562], Loss: 0.2902\n",
      "Epoch [8/10], Batch [1470/1562], Loss: 0.2685\n",
      "Epoch [8/10], Batch [1472/1562], Loss: 0.3223\n",
      "Epoch [8/10], Batch [1474/1562], Loss: 0.2842\n",
      "Epoch [8/10], Batch [1476/1562], Loss: 0.2449\n",
      "Epoch [8/10], Batch [1478/1562], Loss: 0.2692\n",
      "Epoch [8/10], Batch [1480/1562], Loss: 0.2686\n",
      "Epoch [8/10], Batch [1482/1562], Loss: 0.2798\n",
      "Epoch [8/10], Batch [1484/1562], Loss: 0.3057\n",
      "Epoch [8/10], Batch [1486/1562], Loss: 0.2650\n",
      "Epoch [8/10], Batch [1488/1562], Loss: 0.2935\n",
      "Epoch [8/10], Batch [1490/1562], Loss: 0.3583\n",
      "Epoch [8/10], Batch [1492/1562], Loss: 0.3032\n",
      "Epoch [8/10], Batch [1494/1562], Loss: 0.2595\n",
      "Epoch [8/10], Batch [1496/1562], Loss: 0.2517\n",
      "Epoch [8/10], Batch [1498/1562], Loss: 0.2652\n",
      "Epoch [8/10], Batch [1500/1562], Loss: 0.3014\n",
      "Epoch [8/10], Batch [1502/1562], Loss: 0.3405\n",
      "Epoch [8/10], Batch [1504/1562], Loss: 0.2940\n",
      "Epoch [8/10], Batch [1506/1562], Loss: 0.2753\n",
      "Epoch [8/10], Batch [1508/1562], Loss: 0.2573\n",
      "Epoch [8/10], Batch [1510/1562], Loss: 0.3008\n",
      "Epoch [8/10], Batch [1512/1562], Loss: 0.2572\n",
      "Epoch [8/10], Batch [1514/1562], Loss: 0.3221\n",
      "Epoch [8/10], Batch [1516/1562], Loss: 0.2485\n",
      "Epoch [8/10], Batch [1518/1562], Loss: 0.2647\n",
      "Epoch [8/10], Batch [1520/1562], Loss: 0.3256\n",
      "Epoch [8/10], Batch [1522/1562], Loss: 0.2576\n",
      "Epoch [8/10], Batch [1524/1562], Loss: 0.2918\n",
      "Epoch [8/10], Batch [1526/1562], Loss: 0.2943\n",
      "Epoch [8/10], Batch [1528/1562], Loss: 0.3187\n",
      "Epoch [8/10], Batch [1530/1562], Loss: 0.2500\n",
      "Epoch [8/10], Batch [1532/1562], Loss: 0.3284\n",
      "Epoch [8/10], Batch [1534/1562], Loss: 0.2727\n",
      "Epoch [8/10], Batch [1536/1562], Loss: 0.3390\n",
      "Epoch [8/10], Batch [1538/1562], Loss: 0.2647\n",
      "Epoch [8/10], Batch [1540/1562], Loss: 0.2773\n",
      "Epoch [8/10], Batch [1542/1562], Loss: 0.2862\n",
      "Epoch [8/10], Batch [1544/1562], Loss: 0.2840\n",
      "Epoch [8/10], Batch [1546/1562], Loss: 0.2807\n",
      "Epoch [8/10], Batch [1548/1562], Loss: 0.2879\n",
      "Epoch [8/10], Batch [1550/1562], Loss: 0.2509\n",
      "Epoch [8/10], Batch [1552/1562], Loss: 0.2911\n",
      "Epoch [8/10], Batch [1554/1562], Loss: 0.2728\n",
      "Epoch [8/10], Batch [1556/1562], Loss: 0.3164\n",
      "Epoch [8/10], Batch [1558/1562], Loss: 0.2834\n",
      "Epoch [8/10], Batch [1560/1562], Loss: 0.3022\n",
      "Epoch [8/10], Batch [1562/1562], Loss: 0.2935\n",
      "Epoch [8/10] completed. Average Loss: 0.2875\n",
      "Epoch [9/10], Batch [2/1562], Loss: 0.3082\n",
      "Epoch [9/10], Batch [4/1562], Loss: 0.2740\n",
      "Epoch [9/10], Batch [6/1562], Loss: 0.2871\n",
      "Epoch [9/10], Batch [8/1562], Loss: 0.2740\n",
      "Epoch [9/10], Batch [10/1562], Loss: 0.3093\n",
      "Epoch [9/10], Batch [12/1562], Loss: 0.3016\n",
      "Epoch [9/10], Batch [14/1562], Loss: 0.2776\n",
      "Epoch [9/10], Batch [16/1562], Loss: 0.2695\n",
      "Epoch [9/10], Batch [18/1562], Loss: 0.2732\n",
      "Epoch [9/10], Batch [20/1562], Loss: 0.3257\n",
      "Epoch [9/10], Batch [22/1562], Loss: 0.3210\n",
      "Epoch [9/10], Batch [24/1562], Loss: 0.2828\n",
      "Epoch [9/10], Batch [26/1562], Loss: 0.3055\n",
      "Epoch [9/10], Batch [28/1562], Loss: 0.2509\n",
      "Epoch [9/10], Batch [30/1562], Loss: 0.2623\n",
      "Epoch [9/10], Batch [32/1562], Loss: 0.3094\n",
      "Epoch [9/10], Batch [34/1562], Loss: 0.3295\n",
      "Epoch [9/10], Batch [36/1562], Loss: 0.2617\n",
      "Epoch [9/10], Batch [38/1562], Loss: 0.3791\n",
      "Epoch [9/10], Batch [40/1562], Loss: 0.2600\n",
      "Epoch [9/10], Batch [42/1562], Loss: 0.2742\n",
      "Epoch [9/10], Batch [44/1562], Loss: 0.3046\n",
      "Epoch [9/10], Batch [46/1562], Loss: 0.2385\n",
      "Epoch [9/10], Batch [48/1562], Loss: 0.2437\n",
      "Epoch [9/10], Batch [50/1562], Loss: 0.3311\n",
      "Epoch [9/10], Batch [52/1562], Loss: 0.2852\n",
      "Epoch [9/10], Batch [54/1562], Loss: 0.2991\n",
      "Epoch [9/10], Batch [56/1562], Loss: 0.2878\n",
      "Epoch [9/10], Batch [58/1562], Loss: 0.2414\n",
      "Epoch [9/10], Batch [60/1562], Loss: 0.2722\n",
      "Epoch [9/10], Batch [62/1562], Loss: 0.2567\n",
      "Epoch [9/10], Batch [64/1562], Loss: 0.2760\n",
      "Epoch [9/10], Batch [66/1562], Loss: 0.2924\n",
      "Epoch [9/10], Batch [68/1562], Loss: 0.3046\n",
      "Epoch [9/10], Batch [70/1562], Loss: 0.2896\n",
      "Epoch [9/10], Batch [72/1562], Loss: 0.3034\n",
      "Epoch [9/10], Batch [74/1562], Loss: 0.2901\n",
      "Epoch [9/10], Batch [76/1562], Loss: 0.2738\n",
      "Epoch [9/10], Batch [78/1562], Loss: 0.3130\n",
      "Epoch [9/10], Batch [80/1562], Loss: 0.3061\n",
      "Epoch [9/10], Batch [82/1562], Loss: 0.3108\n",
      "Epoch [9/10], Batch [84/1562], Loss: 0.2911\n",
      "Epoch [9/10], Batch [86/1562], Loss: 0.3036\n",
      "Epoch [9/10], Batch [88/1562], Loss: 0.3056\n",
      "Epoch [9/10], Batch [90/1562], Loss: 0.2465\n",
      "Epoch [9/10], Batch [92/1562], Loss: 0.2669\n",
      "Epoch [9/10], Batch [94/1562], Loss: 0.2911\n",
      "Epoch [9/10], Batch [96/1562], Loss: 0.2889\n",
      "Epoch [9/10], Batch [98/1562], Loss: 0.2734\n",
      "Epoch [9/10], Batch [100/1562], Loss: 0.2922\n",
      "Epoch [9/10], Batch [102/1562], Loss: 0.2817\n",
      "Epoch [9/10], Batch [104/1562], Loss: 0.2854\n",
      "Epoch [9/10], Batch [106/1562], Loss: 0.2828\n",
      "Epoch [9/10], Batch [108/1562], Loss: 0.2855\n",
      "Epoch [9/10], Batch [110/1562], Loss: 0.3013\n",
      "Epoch [9/10], Batch [112/1562], Loss: 0.2497\n",
      "Epoch [9/10], Batch [114/1562], Loss: 0.2696\n",
      "Epoch [9/10], Batch [116/1562], Loss: 0.2781\n",
      "Epoch [9/10], Batch [118/1562], Loss: 0.2907\n",
      "Epoch [9/10], Batch [120/1562], Loss: 0.3285\n",
      "Epoch [9/10], Batch [122/1562], Loss: 0.3098\n",
      "Epoch [9/10], Batch [124/1562], Loss: 0.2099\n",
      "Epoch [9/10], Batch [126/1562], Loss: 0.3109\n",
      "Epoch [9/10], Batch [128/1562], Loss: 0.2914\n",
      "Epoch [9/10], Batch [130/1562], Loss: 0.2975\n",
      "Epoch [9/10], Batch [132/1562], Loss: 0.2364\n",
      "Epoch [9/10], Batch [134/1562], Loss: 0.2502\n",
      "Epoch [9/10], Batch [136/1562], Loss: 0.3040\n",
      "Epoch [9/10], Batch [138/1562], Loss: 0.2969\n",
      "Epoch [9/10], Batch [140/1562], Loss: 0.2798\n",
      "Epoch [9/10], Batch [142/1562], Loss: 0.2977\n",
      "Epoch [9/10], Batch [144/1562], Loss: 0.2877\n",
      "Epoch [9/10], Batch [146/1562], Loss: 0.2781\n",
      "Epoch [9/10], Batch [148/1562], Loss: 0.3316\n",
      "Epoch [9/10], Batch [150/1562], Loss: 0.3016\n",
      "Epoch [9/10], Batch [152/1562], Loss: 0.3460\n",
      "Epoch [9/10], Batch [154/1562], Loss: 0.2768\n",
      "Epoch [9/10], Batch [156/1562], Loss: 0.3353\n",
      "Epoch [9/10], Batch [158/1562], Loss: 0.2830\n",
      "Epoch [9/10], Batch [160/1562], Loss: 0.2737\n",
      "Epoch [9/10], Batch [162/1562], Loss: 0.2490\n",
      "Epoch [9/10], Batch [164/1562], Loss: 0.3106\n",
      "Epoch [9/10], Batch [166/1562], Loss: 0.3004\n",
      "Epoch [9/10], Batch [168/1562], Loss: 0.2566\n",
      "Epoch [9/10], Batch [170/1562], Loss: 0.2930\n",
      "Epoch [9/10], Batch [172/1562], Loss: 0.2580\n",
      "Epoch [9/10], Batch [174/1562], Loss: 0.2755\n",
      "Epoch [9/10], Batch [176/1562], Loss: 0.2606\n",
      "Epoch [9/10], Batch [178/1562], Loss: 0.2645\n",
      "Epoch [9/10], Batch [180/1562], Loss: 0.3029\n",
      "Epoch [9/10], Batch [182/1562], Loss: 0.3253\n",
      "Epoch [9/10], Batch [184/1562], Loss: 0.2962\n",
      "Epoch [9/10], Batch [186/1562], Loss: 0.2732\n",
      "Epoch [9/10], Batch [188/1562], Loss: 0.2743\n",
      "Epoch [9/10], Batch [190/1562], Loss: 0.2881\n",
      "Epoch [9/10], Batch [192/1562], Loss: 0.2731\n",
      "Epoch [9/10], Batch [194/1562], Loss: 0.2593\n",
      "Epoch [9/10], Batch [196/1562], Loss: 0.2914\n",
      "Epoch [9/10], Batch [198/1562], Loss: 0.2961\n",
      "Epoch [9/10], Batch [200/1562], Loss: 0.3143\n",
      "Epoch [9/10], Batch [202/1562], Loss: 0.2557\n",
      "Epoch [9/10], Batch [204/1562], Loss: 0.3014\n",
      "Epoch [9/10], Batch [206/1562], Loss: 0.2830\n",
      "Epoch [9/10], Batch [208/1562], Loss: 0.2836\n",
      "Epoch [9/10], Batch [210/1562], Loss: 0.3099\n",
      "Epoch [9/10], Batch [212/1562], Loss: 0.2667\n",
      "Epoch [9/10], Batch [214/1562], Loss: 0.2919\n",
      "Epoch [9/10], Batch [216/1562], Loss: 0.2900\n",
      "Epoch [9/10], Batch [218/1562], Loss: 0.2915\n",
      "Epoch [9/10], Batch [220/1562], Loss: 0.2945\n",
      "Epoch [9/10], Batch [222/1562], Loss: 0.2699\n",
      "Epoch [9/10], Batch [224/1562], Loss: 0.2944\n",
      "Epoch [9/10], Batch [226/1562], Loss: 0.3360\n",
      "Epoch [9/10], Batch [228/1562], Loss: 0.2868\n",
      "Epoch [9/10], Batch [230/1562], Loss: 0.2900\n",
      "Epoch [9/10], Batch [232/1562], Loss: 0.2776\n",
      "Epoch [9/10], Batch [234/1562], Loss: 0.2922\n",
      "Epoch [9/10], Batch [236/1562], Loss: 0.2928\n",
      "Epoch [9/10], Batch [238/1562], Loss: 0.2934\n",
      "Epoch [9/10], Batch [240/1562], Loss: 0.2671\n",
      "Epoch [9/10], Batch [242/1562], Loss: 0.2770\n",
      "Epoch [9/10], Batch [244/1562], Loss: 0.2731\n",
      "Epoch [9/10], Batch [246/1562], Loss: 0.2564\n",
      "Epoch [9/10], Batch [248/1562], Loss: 0.2969\n",
      "Epoch [9/10], Batch [250/1562], Loss: 0.3105\n",
      "Epoch [9/10], Batch [252/1562], Loss: 0.2788\n",
      "Epoch [9/10], Batch [254/1562], Loss: 0.2991\n",
      "Epoch [9/10], Batch [256/1562], Loss: 0.2737\n",
      "Epoch [9/10], Batch [258/1562], Loss: 0.2740\n",
      "Epoch [9/10], Batch [260/1562], Loss: 0.3140\n",
      "Epoch [9/10], Batch [262/1562], Loss: 0.3026\n",
      "Epoch [9/10], Batch [264/1562], Loss: 0.2569\n",
      "Epoch [9/10], Batch [266/1562], Loss: 0.2978\n",
      "Epoch [9/10], Batch [268/1562], Loss: 0.2678\n",
      "Epoch [9/10], Batch [270/1562], Loss: 0.2522\n",
      "Epoch [9/10], Batch [272/1562], Loss: 0.3033\n",
      "Epoch [9/10], Batch [274/1562], Loss: 0.2670\n",
      "Epoch [9/10], Batch [276/1562], Loss: 0.3064\n",
      "Epoch [9/10], Batch [278/1562], Loss: 0.2866\n",
      "Epoch [9/10], Batch [280/1562], Loss: 0.2853\n",
      "Epoch [9/10], Batch [282/1562], Loss: 0.3013\n",
      "Epoch [9/10], Batch [284/1562], Loss: 0.3012\n",
      "Epoch [9/10], Batch [286/1562], Loss: 0.2720\n",
      "Epoch [9/10], Batch [288/1562], Loss: 0.2650\n",
      "Epoch [9/10], Batch [290/1562], Loss: 0.3322\n",
      "Epoch [9/10], Batch [292/1562], Loss: 0.3031\n",
      "Epoch [9/10], Batch [294/1562], Loss: 0.3029\n",
      "Epoch [9/10], Batch [296/1562], Loss: 0.3146\n",
      "Epoch [9/10], Batch [298/1562], Loss: 0.2965\n",
      "Epoch [9/10], Batch [300/1562], Loss: 0.2933\n",
      "Epoch [9/10], Batch [302/1562], Loss: 0.2615\n",
      "Epoch [9/10], Batch [304/1562], Loss: 0.2965\n",
      "Epoch [9/10], Batch [306/1562], Loss: 0.2896\n",
      "Epoch [9/10], Batch [308/1562], Loss: 0.3240\n",
      "Epoch [9/10], Batch [310/1562], Loss: 0.2779\n",
      "Epoch [9/10], Batch [312/1562], Loss: 0.3425\n",
      "Epoch [9/10], Batch [314/1562], Loss: 0.2919\n",
      "Epoch [9/10], Batch [316/1562], Loss: 0.2641\n",
      "Epoch [9/10], Batch [318/1562], Loss: 0.2787\n",
      "Epoch [9/10], Batch [320/1562], Loss: 0.2821\n",
      "Epoch [9/10], Batch [322/1562], Loss: 0.3153\n",
      "Epoch [9/10], Batch [324/1562], Loss: 0.2637\n",
      "Epoch [9/10], Batch [326/1562], Loss: 0.3080\n",
      "Epoch [9/10], Batch [328/1562], Loss: 0.2928\n",
      "Epoch [9/10], Batch [330/1562], Loss: 0.2640\n",
      "Epoch [9/10], Batch [332/1562], Loss: 0.2924\n",
      "Epoch [9/10], Batch [334/1562], Loss: 0.2937\n",
      "Epoch [9/10], Batch [336/1562], Loss: 0.2682\n",
      "Epoch [9/10], Batch [338/1562], Loss: 0.2831\n",
      "Epoch [9/10], Batch [340/1562], Loss: 0.2910\n",
      "Epoch [9/10], Batch [342/1562], Loss: 0.3218\n",
      "Epoch [9/10], Batch [344/1562], Loss: 0.3213\n",
      "Epoch [9/10], Batch [346/1562], Loss: 0.3007\n",
      "Epoch [9/10], Batch [348/1562], Loss: 0.3058\n",
      "Epoch [9/10], Batch [350/1562], Loss: 0.2777\n",
      "Epoch [9/10], Batch [352/1562], Loss: 0.3019\n",
      "Epoch [9/10], Batch [354/1562], Loss: 0.2898\n",
      "Epoch [9/10], Batch [356/1562], Loss: 0.2755\n",
      "Epoch [9/10], Batch [358/1562], Loss: 0.2695\n",
      "Epoch [9/10], Batch [360/1562], Loss: 0.2846\n",
      "Epoch [9/10], Batch [362/1562], Loss: 0.2561\n",
      "Epoch [9/10], Batch [364/1562], Loss: 0.2725\n",
      "Epoch [9/10], Batch [366/1562], Loss: 0.3111\n",
      "Epoch [9/10], Batch [368/1562], Loss: 0.3050\n",
      "Epoch [9/10], Batch [370/1562], Loss: 0.2877\n",
      "Epoch [9/10], Batch [372/1562], Loss: 0.2383\n",
      "Epoch [9/10], Batch [374/1562], Loss: 0.3136\n",
      "Epoch [9/10], Batch [376/1562], Loss: 0.2492\n",
      "Epoch [9/10], Batch [378/1562], Loss: 0.2839\n",
      "Epoch [9/10], Batch [380/1562], Loss: 0.3002\n",
      "Epoch [9/10], Batch [382/1562], Loss: 0.3408\n",
      "Epoch [9/10], Batch [384/1562], Loss: 0.2673\n",
      "Epoch [9/10], Batch [386/1562], Loss: 0.2840\n",
      "Epoch [9/10], Batch [388/1562], Loss: 0.3037\n",
      "Epoch [9/10], Batch [390/1562], Loss: 0.3118\n",
      "Epoch [9/10], Batch [392/1562], Loss: 0.2689\n",
      "Epoch [9/10], Batch [394/1562], Loss: 0.2858\n",
      "Epoch [9/10], Batch [396/1562], Loss: 0.2905\n",
      "Epoch [9/10], Batch [398/1562], Loss: 0.2589\n",
      "Epoch [9/10], Batch [400/1562], Loss: 0.2727\n",
      "Epoch [9/10], Batch [402/1562], Loss: 0.2778\n",
      "Epoch [9/10], Batch [404/1562], Loss: 0.3204\n",
      "Epoch [9/10], Batch [406/1562], Loss: 0.2983\n",
      "Epoch [9/10], Batch [408/1562], Loss: 0.2606\n",
      "Epoch [9/10], Batch [410/1562], Loss: 0.2805\n",
      "Epoch [9/10], Batch [412/1562], Loss: 0.3056\n",
      "Epoch [9/10], Batch [414/1562], Loss: 0.2542\n",
      "Epoch [9/10], Batch [416/1562], Loss: 0.2595\n",
      "Epoch [9/10], Batch [418/1562], Loss: 0.3264\n",
      "Epoch [9/10], Batch [420/1562], Loss: 0.3160\n",
      "Epoch [9/10], Batch [422/1562], Loss: 0.3134\n",
      "Epoch [9/10], Batch [424/1562], Loss: 0.3016\n",
      "Epoch [9/10], Batch [426/1562], Loss: 0.3028\n",
      "Epoch [9/10], Batch [428/1562], Loss: 0.2991\n",
      "Epoch [9/10], Batch [430/1562], Loss: 0.2320\n",
      "Epoch [9/10], Batch [432/1562], Loss: 0.3187\n",
      "Epoch [9/10], Batch [434/1562], Loss: 0.3054\n",
      "Epoch [9/10], Batch [436/1562], Loss: 0.3056\n",
      "Epoch [9/10], Batch [438/1562], Loss: 0.2835\n",
      "Epoch [9/10], Batch [440/1562], Loss: 0.2724\n",
      "Epoch [9/10], Batch [442/1562], Loss: 0.3213\n",
      "Epoch [9/10], Batch [444/1562], Loss: 0.2892\n",
      "Epoch [9/10], Batch [446/1562], Loss: 0.2703\n",
      "Epoch [9/10], Batch [448/1562], Loss: 0.3035\n",
      "Epoch [9/10], Batch [450/1562], Loss: 0.2885\n",
      "Epoch [9/10], Batch [452/1562], Loss: 0.3322\n",
      "Epoch [9/10], Batch [454/1562], Loss: 0.2898\n",
      "Epoch [9/10], Batch [456/1562], Loss: 0.3281\n",
      "Epoch [9/10], Batch [458/1562], Loss: 0.2878\n",
      "Epoch [9/10], Batch [460/1562], Loss: 0.3052\n",
      "Epoch [9/10], Batch [462/1562], Loss: 0.3054\n",
      "Epoch [9/10], Batch [464/1562], Loss: 0.2685\n",
      "Epoch [9/10], Batch [466/1562], Loss: 0.2822\n",
      "Epoch [9/10], Batch [468/1562], Loss: 0.3060\n",
      "Epoch [9/10], Batch [470/1562], Loss: 0.2709\n",
      "Epoch [9/10], Batch [472/1562], Loss: 0.2962\n",
      "Epoch [9/10], Batch [474/1562], Loss: 0.2701\n",
      "Epoch [9/10], Batch [476/1562], Loss: 0.2860\n",
      "Epoch [9/10], Batch [478/1562], Loss: 0.3044\n",
      "Epoch [9/10], Batch [480/1562], Loss: 0.3053\n",
      "Epoch [9/10], Batch [482/1562], Loss: 0.3286\n",
      "Epoch [9/10], Batch [484/1562], Loss: 0.2491\n",
      "Epoch [9/10], Batch [486/1562], Loss: 0.2768\n",
      "Epoch [9/10], Batch [488/1562], Loss: 0.3042\n",
      "Epoch [9/10], Batch [490/1562], Loss: 0.2783\n",
      "Epoch [9/10], Batch [492/1562], Loss: 0.2993\n",
      "Epoch [9/10], Batch [494/1562], Loss: 0.3027\n",
      "Epoch [9/10], Batch [496/1562], Loss: 0.2707\n",
      "Epoch [9/10], Batch [498/1562], Loss: 0.2836\n",
      "Epoch [9/10], Batch [500/1562], Loss: 0.2763\n",
      "Epoch [9/10], Batch [502/1562], Loss: 0.2740\n",
      "Epoch [9/10], Batch [504/1562], Loss: 0.2463\n",
      "Epoch [9/10], Batch [506/1562], Loss: 0.2653\n",
      "Epoch [9/10], Batch [508/1562], Loss: 0.2597\n",
      "Epoch [9/10], Batch [510/1562], Loss: 0.3049\n",
      "Epoch [9/10], Batch [512/1562], Loss: 0.3330\n",
      "Epoch [9/10], Batch [514/1562], Loss: 0.2485\n",
      "Epoch [9/10], Batch [516/1562], Loss: 0.3189\n",
      "Epoch [9/10], Batch [518/1562], Loss: 0.2530\n",
      "Epoch [9/10], Batch [520/1562], Loss: 0.3315\n",
      "Epoch [9/10], Batch [522/1562], Loss: 0.2786\n",
      "Epoch [9/10], Batch [524/1562], Loss: 0.2596\n",
      "Epoch [9/10], Batch [526/1562], Loss: 0.2794\n",
      "Epoch [9/10], Batch [528/1562], Loss: 0.2563\n",
      "Epoch [9/10], Batch [530/1562], Loss: 0.2677\n",
      "Epoch [9/10], Batch [532/1562], Loss: 0.2850\n",
      "Epoch [9/10], Batch [534/1562], Loss: 0.2785\n",
      "Epoch [9/10], Batch [536/1562], Loss: 0.2892\n",
      "Epoch [9/10], Batch [538/1562], Loss: 0.2659\n",
      "Epoch [9/10], Batch [540/1562], Loss: 0.3071\n",
      "Epoch [9/10], Batch [542/1562], Loss: 0.2857\n",
      "Epoch [9/10], Batch [544/1562], Loss: 0.2578\n",
      "Epoch [9/10], Batch [546/1562], Loss: 0.2989\n",
      "Epoch [9/10], Batch [548/1562], Loss: 0.2796\n",
      "Epoch [9/10], Batch [550/1562], Loss: 0.3082\n",
      "Epoch [9/10], Batch [552/1562], Loss: 0.2979\n",
      "Epoch [9/10], Batch [554/1562], Loss: 0.2666\n",
      "Epoch [9/10], Batch [556/1562], Loss: 0.2848\n",
      "Epoch [9/10], Batch [558/1562], Loss: 0.2962\n",
      "Epoch [9/10], Batch [560/1562], Loss: 0.2828\n",
      "Epoch [9/10], Batch [562/1562], Loss: 0.2727\n",
      "Epoch [9/10], Batch [564/1562], Loss: 0.2737\n",
      "Epoch [9/10], Batch [566/1562], Loss: 0.2884\n",
      "Epoch [9/10], Batch [568/1562], Loss: 0.2798\n",
      "Epoch [9/10], Batch [570/1562], Loss: 0.2355\n",
      "Epoch [9/10], Batch [572/1562], Loss: 0.2989\n",
      "Epoch [9/10], Batch [574/1562], Loss: 0.2931\n",
      "Epoch [9/10], Batch [576/1562], Loss: 0.2665\n",
      "Epoch [9/10], Batch [578/1562], Loss: 0.2977\n",
      "Epoch [9/10], Batch [580/1562], Loss: 0.2703\n",
      "Epoch [9/10], Batch [582/1562], Loss: 0.2737\n",
      "Epoch [9/10], Batch [584/1562], Loss: 0.3307\n",
      "Epoch [9/10], Batch [586/1562], Loss: 0.2906\n",
      "Epoch [9/10], Batch [588/1562], Loss: 0.2879\n",
      "Epoch [9/10], Batch [590/1562], Loss: 0.2959\n",
      "Epoch [9/10], Batch [592/1562], Loss: 0.3144\n",
      "Epoch [9/10], Batch [594/1562], Loss: 0.3652\n",
      "Epoch [9/10], Batch [596/1562], Loss: 0.3043\n",
      "Epoch [9/10], Batch [598/1562], Loss: 0.2882\n",
      "Epoch [9/10], Batch [600/1562], Loss: 0.2611\n",
      "Epoch [9/10], Batch [602/1562], Loss: 0.3167\n",
      "Epoch [9/10], Batch [604/1562], Loss: 0.3373\n",
      "Epoch [9/10], Batch [606/1562], Loss: 0.2728\n",
      "Epoch [9/10], Batch [608/1562], Loss: 0.2906\n",
      "Epoch [9/10], Batch [610/1562], Loss: 0.2996\n",
      "Epoch [9/10], Batch [612/1562], Loss: 0.3203\n",
      "Epoch [9/10], Batch [614/1562], Loss: 0.2875\n",
      "Epoch [9/10], Batch [616/1562], Loss: 0.2966\n",
      "Epoch [9/10], Batch [618/1562], Loss: 0.2728\n",
      "Epoch [9/10], Batch [620/1562], Loss: 0.3264\n",
      "Epoch [9/10], Batch [622/1562], Loss: 0.2518\n",
      "Epoch [9/10], Batch [624/1562], Loss: 0.2718\n",
      "Epoch [9/10], Batch [626/1562], Loss: 0.2534\n",
      "Epoch [9/10], Batch [628/1562], Loss: 0.2329\n",
      "Epoch [9/10], Batch [630/1562], Loss: 0.2791\n",
      "Epoch [9/10], Batch [632/1562], Loss: 0.2798\n",
      "Epoch [9/10], Batch [634/1562], Loss: 0.2502\n",
      "Epoch [9/10], Batch [636/1562], Loss: 0.3427\n",
      "Epoch [9/10], Batch [638/1562], Loss: 0.2660\n",
      "Epoch [9/10], Batch [640/1562], Loss: 0.2651\n",
      "Epoch [9/10], Batch [642/1562], Loss: 0.2510\n",
      "Epoch [9/10], Batch [644/1562], Loss: 0.2619\n",
      "Epoch [9/10], Batch [646/1562], Loss: 0.3002\n",
      "Epoch [9/10], Batch [648/1562], Loss: 0.2793\n",
      "Epoch [9/10], Batch [650/1562], Loss: 0.2446\n",
      "Epoch [9/10], Batch [652/1562], Loss: 0.3058\n",
      "Epoch [9/10], Batch [654/1562], Loss: 0.3003\n",
      "Epoch [9/10], Batch [656/1562], Loss: 0.2430\n",
      "Epoch [9/10], Batch [658/1562], Loss: 0.2960\n",
      "Epoch [9/10], Batch [660/1562], Loss: 0.3141\n",
      "Epoch [9/10], Batch [662/1562], Loss: 0.2876\n",
      "Epoch [9/10], Batch [664/1562], Loss: 0.2995\n",
      "Epoch [9/10], Batch [666/1562], Loss: 0.2882\n",
      "Epoch [9/10], Batch [668/1562], Loss: 0.2862\n",
      "Epoch [9/10], Batch [670/1562], Loss: 0.2620\n",
      "Epoch [9/10], Batch [672/1562], Loss: 0.2927\n",
      "Epoch [9/10], Batch [674/1562], Loss: 0.2486\n",
      "Epoch [9/10], Batch [676/1562], Loss: 0.2574\n",
      "Epoch [9/10], Batch [678/1562], Loss: 0.3187\n",
      "Epoch [9/10], Batch [680/1562], Loss: 0.2408\n",
      "Epoch [9/10], Batch [682/1562], Loss: 0.2704\n",
      "Epoch [9/10], Batch [684/1562], Loss: 0.3051\n",
      "Epoch [9/10], Batch [686/1562], Loss: 0.2892\n",
      "Epoch [9/10], Batch [688/1562], Loss: 0.2824\n",
      "Epoch [9/10], Batch [690/1562], Loss: 0.2913\n",
      "Epoch [9/10], Batch [692/1562], Loss: 0.2713\n",
      "Epoch [9/10], Batch [694/1562], Loss: 0.2934\n",
      "Epoch [9/10], Batch [696/1562], Loss: 0.2899\n",
      "Epoch [9/10], Batch [698/1562], Loss: 0.2753\n",
      "Epoch [9/10], Batch [700/1562], Loss: 0.3360\n",
      "Epoch [9/10], Batch [702/1562], Loss: 0.3055\n",
      "Epoch [9/10], Batch [704/1562], Loss: 0.3220\n",
      "Epoch [9/10], Batch [706/1562], Loss: 0.2876\n",
      "Epoch [9/10], Batch [708/1562], Loss: 0.2885\n",
      "Epoch [9/10], Batch [710/1562], Loss: 0.2826\n",
      "Epoch [9/10], Batch [712/1562], Loss: 0.2953\n",
      "Epoch [9/10], Batch [714/1562], Loss: 0.2948\n",
      "Epoch [9/10], Batch [716/1562], Loss: 0.2960\n",
      "Epoch [9/10], Batch [718/1562], Loss: 0.3043\n",
      "Epoch [9/10], Batch [720/1562], Loss: 0.2815\n",
      "Epoch [9/10], Batch [722/1562], Loss: 0.2582\n",
      "Epoch [9/10], Batch [724/1562], Loss: 0.3153\n",
      "Epoch [9/10], Batch [726/1562], Loss: 0.2838\n",
      "Epoch [9/10], Batch [728/1562], Loss: 0.2670\n",
      "Epoch [9/10], Batch [730/1562], Loss: 0.3001\n",
      "Epoch [9/10], Batch [732/1562], Loss: 0.2562\n",
      "Epoch [9/10], Batch [734/1562], Loss: 0.2905\n",
      "Epoch [9/10], Batch [736/1562], Loss: 0.2620\n",
      "Epoch [9/10], Batch [738/1562], Loss: 0.2678\n",
      "Epoch [9/10], Batch [740/1562], Loss: 0.3030\n",
      "Epoch [9/10], Batch [742/1562], Loss: 0.2993\n",
      "Epoch [9/10], Batch [744/1562], Loss: 0.3174\n",
      "Epoch [9/10], Batch [746/1562], Loss: 0.2855\n",
      "Epoch [9/10], Batch [748/1562], Loss: 0.2741\n",
      "Epoch [9/10], Batch [750/1562], Loss: 0.2644\n",
      "Epoch [9/10], Batch [752/1562], Loss: 0.2724\n",
      "Epoch [9/10], Batch [754/1562], Loss: 0.3159\n",
      "Epoch [9/10], Batch [756/1562], Loss: 0.3173\n",
      "Epoch [9/10], Batch [758/1562], Loss: 0.2677\n",
      "Epoch [9/10], Batch [760/1562], Loss: 0.2989\n",
      "Epoch [9/10], Batch [762/1562], Loss: 0.2601\n",
      "Epoch [9/10], Batch [764/1562], Loss: 0.2991\n",
      "Epoch [9/10], Batch [766/1562], Loss: 0.3163\n",
      "Epoch [9/10], Batch [768/1562], Loss: 0.3275\n",
      "Epoch [9/10], Batch [770/1562], Loss: 0.2809\n",
      "Epoch [9/10], Batch [772/1562], Loss: 0.2893\n",
      "Epoch [9/10], Batch [774/1562], Loss: 0.2682\n",
      "Epoch [9/10], Batch [776/1562], Loss: 0.2524\n",
      "Epoch [9/10], Batch [778/1562], Loss: 0.2896\n",
      "Epoch [9/10], Batch [780/1562], Loss: 0.2914\n",
      "Epoch [9/10], Batch [782/1562], Loss: 0.2953\n",
      "Epoch [9/10], Batch [784/1562], Loss: 0.2409\n",
      "Epoch [9/10], Batch [786/1562], Loss: 0.2236\n",
      "Epoch [9/10], Batch [788/1562], Loss: 0.2965\n",
      "Epoch [9/10], Batch [790/1562], Loss: 0.2894\n",
      "Epoch [9/10], Batch [792/1562], Loss: 0.3049\n",
      "Epoch [9/10], Batch [794/1562], Loss: 0.2963\n",
      "Epoch [9/10], Batch [796/1562], Loss: 0.3001\n",
      "Epoch [9/10], Batch [798/1562], Loss: 0.3082\n",
      "Epoch [9/10], Batch [800/1562], Loss: 0.3028\n",
      "Epoch [9/10], Batch [802/1562], Loss: 0.2968\n",
      "Epoch [9/10], Batch [804/1562], Loss: 0.2655\n",
      "Epoch [9/10], Batch [806/1562], Loss: 0.3057\n",
      "Epoch [9/10], Batch [808/1562], Loss: 0.3069\n",
      "Epoch [9/10], Batch [810/1562], Loss: 0.2910\n",
      "Epoch [9/10], Batch [812/1562], Loss: 0.3171\n",
      "Epoch [9/10], Batch [814/1562], Loss: 0.2903\n",
      "Epoch [9/10], Batch [816/1562], Loss: 0.2779\n",
      "Epoch [9/10], Batch [818/1562], Loss: 0.3129\n",
      "Epoch [9/10], Batch [820/1562], Loss: 0.3178\n",
      "Epoch [9/10], Batch [822/1562], Loss: 0.3083\n",
      "Epoch [9/10], Batch [824/1562], Loss: 0.3012\n",
      "Epoch [9/10], Batch [826/1562], Loss: 0.2721\n",
      "Epoch [9/10], Batch [828/1562], Loss: 0.2924\n",
      "Epoch [9/10], Batch [830/1562], Loss: 0.2954\n",
      "Epoch [9/10], Batch [832/1562], Loss: 0.3420\n",
      "Epoch [9/10], Batch [834/1562], Loss: 0.2764\n",
      "Epoch [9/10], Batch [836/1562], Loss: 0.2786\n",
      "Epoch [9/10], Batch [838/1562], Loss: 0.3217\n",
      "Epoch [9/10], Batch [840/1562], Loss: 0.2967\n",
      "Epoch [9/10], Batch [842/1562], Loss: 0.3058\n",
      "Epoch [9/10], Batch [844/1562], Loss: 0.2853\n",
      "Epoch [9/10], Batch [846/1562], Loss: 0.1983\n",
      "Epoch [9/10], Batch [848/1562], Loss: 0.3076\n",
      "Epoch [9/10], Batch [850/1562], Loss: 0.2780\n",
      "Epoch [9/10], Batch [852/1562], Loss: 0.2986\n",
      "Epoch [9/10], Batch [854/1562], Loss: 0.2585\n",
      "Epoch [9/10], Batch [856/1562], Loss: 0.2857\n",
      "Epoch [9/10], Batch [858/1562], Loss: 0.3068\n",
      "Epoch [9/10], Batch [860/1562], Loss: 0.2955\n",
      "Epoch [9/10], Batch [862/1562], Loss: 0.3010\n",
      "Epoch [9/10], Batch [864/1562], Loss: 0.3133\n",
      "Epoch [9/10], Batch [866/1562], Loss: 0.2638\n",
      "Epoch [9/10], Batch [868/1562], Loss: 0.2537\n",
      "Epoch [9/10], Batch [870/1562], Loss: 0.2868\n",
      "Epoch [9/10], Batch [872/1562], Loss: 0.2898\n",
      "Epoch [9/10], Batch [874/1562], Loss: 0.2829\n",
      "Epoch [9/10], Batch [876/1562], Loss: 0.3186\n",
      "Epoch [9/10], Batch [878/1562], Loss: 0.2881\n",
      "Epoch [9/10], Batch [880/1562], Loss: 0.3020\n",
      "Epoch [9/10], Batch [882/1562], Loss: 0.2937\n",
      "Epoch [9/10], Batch [884/1562], Loss: 0.3019\n",
      "Epoch [9/10], Batch [886/1562], Loss: 0.2989\n",
      "Epoch [9/10], Batch [888/1562], Loss: 0.2829\n",
      "Epoch [9/10], Batch [890/1562], Loss: 0.3141\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(losse)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Backward pass to compute gradients\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m box\u001b[38;5;241m=\u001b[39m\u001b[43mm1_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlosse\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m prev \u001b[38;5;241m=\u001b[39msaver\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Update model parameters (assume the model has a method to update its parameters)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[113], line 34\u001b[0m, in \u001b[0;36mm1_backward\u001b[1;34m(IP, layers, losse, saver)\u001b[0m\n\u001b[0;32m     32\u001b[0m d_bn_a3\u001b[38;5;241m=\u001b[39mrelu_backward(d_act_a3)\n\u001b[0;32m     33\u001b[0m d_a3, d_bn_f3\u001b[38;5;241m=\u001b[39mbatch_norm_backward(d_bn_a3, a3, bn_f3[\u001b[38;5;241m0\u001b[39m,:])\n\u001b[1;32m---> 34\u001b[0m d_act_a2, d_deconv_f3\u001b[38;5;241m=\u001b[39m\u001b[43mdeconv_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_a3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_a2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeconv_f3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#print(d_act_a2.shape)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m d_bn_a2\u001b[38;5;241m=\u001b[39mrelu_backward(d_act_a2)\n",
      "Cell \u001b[1;32mIn[107], line 41\u001b[0m, in \u001b[0;36mdeconv_backward\u001b[1;34m(dout, x, W, stride, padding, output_padding)\u001b[0m\n\u001b[0;32m     39\u001b[0m H_up \u001b[38;5;241m=\u001b[39m (H_in \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m sh \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     40\u001b[0m W_up \u001b[38;5;241m=\u001b[39m (W_in \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m sw \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 41\u001b[0m x_upsampled \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_up\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_up\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m x_upsampled[:, :, ::sh, ::sw] \u001b[38;5;241m=\u001b[39m x    \n\u001b[0;32m     43\u001b[0m required_h \u001b[38;5;241m=\u001b[39m dout\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m fh \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_batch(image_paths):\n",
    "    \"\"\"Generates a batch of images for training.\"\"\"\n",
    "    batch_paths = np.random.choice(image_paths, batch_size, replace=False)\n",
    "    images = np.array([load_image(path) for path in batch_paths])\n",
    "    return images\n",
    "\n",
    "prev= np.zeros((batch_size, 3,32,32))    \n",
    "image_paths = load_image_paths()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = len(image_paths) // batch_size\n",
    "        \n",
    "    for batch_index in range(num_batches):\n",
    "        batch = get_batch(image_paths)\n",
    "        batch = np.transpose(batch, (0,3,1,2))  # Proper channel-first format\n",
    "        # Forward pass through the model\n",
    "        results = forward(batch)\n",
    "        act_a10, bn_a10, a10, act_a9, bn_a9, a9, act_a8, bn_a8, a8, act_a7, bn_a7, a7, act_a6, bn_a6, a6, act_a5, bn_a5, a5, act_a4, bn_a4, a4, act_a3, bn_a3, a3, act_a2, bn_a2, a2, act_a1, bn_a1, a1=results\n",
    "        saver=np.zeros((batch.shape))    \n",
    "        # Compute error (assume the error function is already implemented in the model)\n",
    "        losse = square_error(act_a10, batch)\n",
    "        loss =np.mean(losse)\n",
    "        # Backward pass to compute gradients\n",
    "        box=m1_backward(batch, results, 0.7*losse+ 0.3*prev, saver)\n",
    "        prev =saver\n",
    "        # Update model parameters (assume the model has a method to update its parameters)\n",
    "        update_params(box, learning_rate, conv_f1, conv_f2, deconv_f3, deconv_f4, deconv_f5, conv_f6, conv_f7, conv_f8, deconv_f9, deconv_f10, bn_f1, bn_f2, bn_f3, bn_f4, bn_f5, bn_f6, bn_f7, bn_f8, bn_f9, bn_f10)\n",
    "        \n",
    "        total_loss += loss\n",
    "\n",
    "        if (batch_index + 1) % 2 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_index+1}/{num_batches}], Loss: {loss:.4f}\")\n",
    "        \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] completed. Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_f1: [[[[-2.07815755e-01  3.24387129e-02 -7.23291664e-02  7.59978048e-02]\n",
      "   [-4.31037945e-01 -4.35561155e-02 -4.30622177e-02 -1.86366234e-01]\n",
      "   [ 1.68575944e-01  1.27352658e-01  1.16083010e-01 -3.68937533e-01]\n",
      "   [-2.77735084e-01 -1.68362683e-01 -1.79665512e-01 -1.45318130e-01]]\n",
      "\n",
      "  [[-2.69944423e-01 -3.16140522e-01 -1.92722061e-01 -8.80538576e-04]\n",
      "   [-3.81507178e-01 -8.83259037e-02  3.73870026e-02 -8.69346871e-02]\n",
      "   [-3.05138210e-01 -2.71642536e-01 -1.69896979e-01  8.50410066e-02]\n",
      "   [-1.18933094e-01  1.26259258e-01  3.92716285e-01 -5.82326861e-02]]\n",
      "\n",
      "  [[-2.13520248e-01 -2.27311900e-01  2.29037262e-01 -1.30004643e-01]\n",
      "   [ 1.08292054e-01  3.74445097e-01 -2.04655138e-01  4.10167807e-01]\n",
      "   [-1.59604890e-02 -1.75636055e-01 -1.89652690e-01 -2.35240242e-01]\n",
      "   [-4.08108460e-01  7.61471768e-02 -1.49836401e-01  2.92420095e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.09836165e-01 -5.51054572e-02 -2.33975563e-01  8.84351820e-03]\n",
      "   [ 3.08575698e-01  2.39634054e-02 -1.98955732e-01  3.84344480e-01]\n",
      "   [-1.07003771e-01  2.29131041e-01  1.07002683e-01 -1.33557141e-01]\n",
      "   [-4.76887790e-01  3.39655011e-02  4.27185971e-02  3.92709327e-02]]\n",
      "\n",
      "  [[-1.86513697e-01  2.62508278e-02  2.63447638e-02  3.26245459e-01]\n",
      "   [ 1.70804186e-01  5.48148990e-02 -2.05522162e-01  3.85107068e-01]\n",
      "   [-3.71114271e-01 -1.30128578e-01  1.23905187e-01 -1.72303333e-01]\n",
      "   [ 8.95657661e-02  2.07460516e-01 -4.20938115e-02  5.42336016e-01]]\n",
      "\n",
      "  [[-5.79789913e-01 -1.15017682e-01 -1.83749586e-02  3.56327561e-01]\n",
      "   [ 7.65381001e-02  2.70277846e-01  1.22422644e-01 -2.10671826e-01]\n",
      "   [-1.09648897e-01  1.48903823e-01 -1.79646194e-01  2.91034802e-02]\n",
      "   [-1.79550741e-01  3.13166671e-01 -1.37285872e-01 -8.81242144e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.74460396e-01  1.77065514e-02 -2.78810310e-01 -3.15552008e-01]\n",
      "   [ 1.20792435e-01 -3.29066134e-01  3.53137595e-02 -4.66175564e-02]\n",
      "   [-9.48857430e-02 -4.22083876e-01 -6.95835352e-02 -3.71784742e-01]\n",
      "   [-5.15907702e-01 -3.02799838e-01 -5.15588244e-02  3.05895290e-01]]\n",
      "\n",
      "  [[ 4.57542471e-03  2.89806789e-01 -2.19112498e-01 -1.82537337e-01]\n",
      "   [-1.25267952e-01 -2.11218110e-01  1.55991039e-01 -3.96311978e-01]\n",
      "   [-4.30313933e-02 -1.67468071e-01 -2.65195099e-01  5.88437346e-02]\n",
      "   [-8.67455610e-02 -2.70347540e-01  1.07838581e-02  4.50478424e-02]]\n",
      "\n",
      "  [[ 3.26182058e-01 -1.30394793e-01 -3.09524251e-01  2.55430243e-01]\n",
      "   [-1.55714727e-01  1.09463607e-01 -2.87730789e-01 -1.16353166e-01]\n",
      "   [ 3.02327590e-01 -1.55772471e-01  7.24099369e-02 -1.24425874e-01]\n",
      "   [-5.98066936e-02  5.05750559e-01  1.14836348e-01  2.26730054e-01]]]\n",
      "\n",
      "\n",
      " [[[ 7.66027616e-02 -3.00052827e-01 -8.75141793e-03 -7.79833976e-03]\n",
      "   [-2.18463570e-01  2.13121989e-01 -5.20685662e-01 -7.77698315e-02]\n",
      "   [-9.01680853e-02 -1.86293298e-01 -5.73019179e-02 -2.55722378e-01]\n",
      "   [-3.44690529e-01 -1.83538068e-01 -1.05429493e-01  8.62060380e-03]]\n",
      "\n",
      "  [[-1.44921872e-01  4.87268448e-02  3.63856891e-02  1.43663405e-01]\n",
      "   [ 8.06592929e-03 -6.03242691e-02 -1.19648236e-01 -1.65258456e-01]\n",
      "   [ 2.16620700e-01  8.85475169e-02  2.35737028e-01  4.89279436e-02]\n",
      "   [-5.89953977e-01 -3.44269608e-02 -3.12653531e-01 -1.80494626e-01]]\n",
      "\n",
      "  [[-1.90395304e-01 -1.71415336e-01 -1.96660379e-01 -2.00492329e-01]\n",
      "   [ 1.27849692e-01 -4.18991404e-02  4.52081131e-01 -1.11912978e-01]\n",
      "   [ 2.00077773e-01  2.23184987e-01 -1.13535099e-01  1.78252690e-01]\n",
      "   [-3.98599290e-01 -2.45860696e-01 -1.09127043e-01  6.54305522e-02]]]\n",
      "\n",
      "\n",
      " [[[ 2.03312524e-01 -2.06892283e-01  4.81801210e-02  1.33585105e-02]\n",
      "   [-1.85262121e-01  2.32676357e-01 -2.72734776e-01  6.78055208e-02]\n",
      "   [ 2.72838951e-02  3.66648033e-02  4.24357966e-01 -2.51565312e-01]\n",
      "   [ 3.46104835e-01 -4.87538398e-02  2.24695118e-01 -8.12573379e-02]]\n",
      "\n",
      "  [[-1.54195039e-02 -1.63121993e-01  4.46939394e-02  2.13323900e-02]\n",
      "   [ 3.29222692e-02  1.37474054e-02  1.95400590e-01 -6.15685294e-02]\n",
      "   [-8.26526413e-02  1.73739376e-01  3.72776057e-02  7.25604105e-02]\n",
      "   [-1.17345566e-01 -1.40473242e-02 -1.19088291e-01 -7.01595104e-02]]\n",
      "\n",
      "  [[ 1.90358740e-03  1.85925887e-02 -3.34001206e-01 -2.11787648e-01]\n",
      "   [ 1.47216643e-01  9.25732438e-02  1.69348292e-01 -2.12725049e-01]\n",
      "   [ 9.66580950e-02  1.65263079e-01 -1.30364490e-01 -2.60339930e-01]\n",
      "   [ 1.91263353e-01  1.29296681e-01  2.24444420e-01  1.06764671e-01]]]\n",
      "\n",
      "\n",
      " [[[ 7.67602122e-02 -2.01110713e-01 -2.97293959e-01 -1.87468204e-01]\n",
      "   [ 7.96035178e-02 -6.77587080e-02  1.98397936e-01  4.26370511e-01]\n",
      "   [-7.20832681e-02  1.37566926e-01  2.33894818e-01 -1.30956915e-01]\n",
      "   [ 2.54910916e-01 -1.64560762e-01 -1.25447019e-01 -2.94510819e-04]]\n",
      "\n",
      "  [[ 1.58987765e-01 -6.77654538e-02  3.06171524e-01  5.94948513e-02]\n",
      "   [ 2.39922157e-01 -2.21490716e-01 -3.30369926e-01  1.86171578e-01]\n",
      "   [ 3.28581952e-01  8.57467436e-02  1.46771897e-02  2.81237377e-02]\n",
      "   [ 2.56312033e-01  5.78302486e-03 -9.95474232e-02  1.96774616e-01]]\n",
      "\n",
      "  [[ 1.30216049e-01  3.36772116e-02  1.81382929e-01 -1.77389170e-01]\n",
      "   [ 1.49820848e-01 -2.52309562e-01 -8.02218582e-02  5.61630339e-01]\n",
      "   [ 9.34023633e-02 -8.74077013e-02 -1.14803446e-01  1.51752513e-01]\n",
      "   [ 5.39311370e-02 -1.42595481e-01 -1.42884785e-01 -1.57991881e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.32215011e-01 -2.71733193e-01  3.88923357e-01  1.72052438e-01]\n",
      "   [-8.89758117e-03 -6.63855758e-02  3.18417753e-01  5.00306249e-02]\n",
      "   [-1.46274862e-01 -3.31102475e-01 -1.57123327e-01  2.17418587e-01]\n",
      "   [-3.41397231e-01 -8.78809221e-02  1.02786197e-01 -1.80785578e-01]]\n",
      "\n",
      "  [[-4.15970624e-02 -2.11534432e-01 -5.66097942e-02  4.99048519e-02]\n",
      "   [-2.35572373e-01  3.15011912e-02  1.83150665e-01  4.35772902e-01]\n",
      "   [ 2.73055861e-01  1.08030774e-01  2.05055405e-01  8.45285939e-02]\n",
      "   [-3.01301333e-02  2.13983972e-01  2.21118963e-03 -2.59280184e-01]]\n",
      "\n",
      "  [[ 1.57652711e-01 -4.47001744e-01  2.64737276e-01  2.45652886e-01]\n",
      "   [-2.00244413e-01 -1.67095660e-01  3.18329278e-02 -1.23120196e-02]\n",
      "   [-9.52317228e-02 -4.15245229e-02  1.10270572e-01  3.94913272e-01]\n",
      "   [-4.79036325e-02 -1.84512953e-01 -7.36411821e-02 -2.36225623e-01]]]\n",
      "\n",
      "\n",
      " [[[-2.63969168e-01 -5.28286025e-02 -9.09828684e-02  7.78217854e-02]\n",
      "   [-4.06700615e-01  2.15614929e-01 -1.84648774e-01  1.33267877e-02]\n",
      "   [ 1.55314706e-01 -3.34266691e-02  2.21346824e-01  2.85262963e-01]\n",
      "   [ 8.15125508e-02 -5.29827967e-02  3.36219685e-01  4.19458873e-01]]\n",
      "\n",
      "  [[-2.99914745e-01 -2.47228171e-01 -5.25602332e-02 -2.16305328e-01]\n",
      "   [ 1.46324301e-01 -2.78731235e-01  4.65605191e-01  1.54017834e-01]\n",
      "   [ 1.25225882e-01 -2.86576161e-01  3.17606907e-02 -1.62289484e-01]\n",
      "   [ 2.68919720e-01  7.45437549e-02 -2.86985728e-01 -6.84017617e-02]]\n",
      "\n",
      "  [[-6.59503281e-02  1.82770389e-01  5.25457159e-02 -1.45512134e-01]\n",
      "   [-5.19718758e-02 -3.40900316e-02 -1.15304677e-01 -1.67930950e-01]\n",
      "   [ 1.53813412e-01 -1.50998851e-01  8.08031626e-02  4.24263543e-01]\n",
      "   [ 5.42781909e-02  5.21747825e-01 -2.33413367e-03 -2.21605841e-01]]]],\n",
      "bn_f1: [[-0.01695846  0.17702222 -0.45591713 -0.09859896 -0.00542645  0.30443047\n",
      "  -0.10502967  0.11012636]\n",
      " [ 0.20686917 -0.28470656  0.10799832 -0.09248176  0.13490901 -0.09194768\n",
      "  -0.06715057 -0.24913738]],\n",
      "conv_f2: [[[[ 4.63206249e-02  1.19802249e-02 -1.37128557e-01]\n",
      "   [ 6.21565171e-02 -2.47458771e-01 -5.42942776e-01]\n",
      "   [-3.49097027e-01 -1.89740238e-01  1.55331560e-01]]\n",
      "\n",
      "  [[ 1.03977093e-01  2.76160439e-02 -1.14327964e-01]\n",
      "   [ 1.62042866e-01  2.00710945e-02  2.89029908e-01]\n",
      "   [-3.15042651e-01  2.01407003e-02  2.74677437e-04]]\n",
      "\n",
      "  [[-2.72969615e-01  4.13551763e-02  1.91201886e-01]\n",
      "   [-2.61482978e-01 -2.01696199e-01 -1.55172567e-01]\n",
      "   [ 1.45458677e-01 -1.60595950e-01 -2.76874116e-02]]\n",
      "\n",
      "  [[ 1.76848244e-01  1.23742508e-01  2.98262451e-01]\n",
      "   [ 5.36959875e-03 -1.10800750e-01 -5.66723154e-02]\n",
      "   [-7.77323174e-02 -1.53575097e-02 -2.16978704e-01]]\n",
      "\n",
      "  [[-3.82629877e-02  1.38499922e-01 -1.84264317e-02]\n",
      "   [ 3.25075971e-01  2.63504195e-01  7.19412094e-02]\n",
      "   [-2.84261318e-01  4.15534351e-01 -4.86245745e-01]]\n",
      "\n",
      "  [[ 1.16338500e-02 -9.77532592e-02  1.29797144e-01]\n",
      "   [ 8.68791497e-02 -2.24181067e-02  1.11852549e-01]\n",
      "   [ 3.43790751e-01  2.19851040e-02 -6.29038186e-02]]\n",
      "\n",
      "  [[-5.14214739e-02 -6.57876257e-02  3.17941569e-01]\n",
      "   [-2.51557200e-01 -7.79520110e-02 -2.21845220e-01]\n",
      "   [ 9.62997299e-02 -2.56724280e-01  2.06065151e-01]]\n",
      "\n",
      "  [[ 3.27626229e-01 -1.12410891e-01 -8.66670251e-02]\n",
      "   [ 4.14717476e-01 -1.69104537e-01  9.38863002e-02]\n",
      "   [-1.14891812e-02 -5.17935147e-02 -9.57025689e-02]]]\n",
      "\n",
      "\n",
      " [[[-1.66301684e-01  2.02104233e-01  1.90377629e-01]\n",
      "   [ 3.62295579e-02  1.35746508e-01  1.55161087e-02]\n",
      "   [ 3.02682970e-01  1.35022006e-01 -1.98616478e-01]]\n",
      "\n",
      "  [[-4.97308205e-02  1.33706767e-01 -1.06356657e-01]\n",
      "   [-1.93417951e-01  3.10406446e-02 -1.08091524e-01]\n",
      "   [ 3.01378620e-01  3.62388068e-01  3.04969437e-01]]\n",
      "\n",
      "  [[ 1.19412790e-01  1.76335678e-01 -2.13399985e-02]\n",
      "   [-1.60255063e-01 -5.28414105e-02  1.79757576e-01]\n",
      "   [-9.15045822e-02  1.37639224e-01  5.79022437e-02]]\n",
      "\n",
      "  [[-4.77219381e-02 -1.26405407e-01 -3.79048291e-02]\n",
      "   [-2.42323068e-01 -2.39627380e-01  3.12114225e-02]\n",
      "   [-1.24762828e-01 -1.03269025e-01 -1.56177113e-01]]\n",
      "\n",
      "  [[-2.33507088e-01 -1.52021222e-01 -1.74178523e-01]\n",
      "   [ 5.86235104e-04  1.44518214e-01 -3.30392417e-02]\n",
      "   [ 4.62247001e-03 -3.20686756e-01 -3.83591563e-01]]\n",
      "\n",
      "  [[-8.80699722e-03  2.83419304e-01  1.61816372e-02]\n",
      "   [-8.20352201e-02 -8.16425801e-02  2.76367955e-01]\n",
      "   [ 9.46138855e-02  8.62139705e-02 -1.19289367e-01]]\n",
      "\n",
      "  [[-3.31230036e-02 -3.14470571e-01 -1.29287885e-01]\n",
      "   [-2.90802551e-02 -2.42640988e-01  5.24296782e-01]\n",
      "   [-8.64998720e-02 -5.89293562e-02  2.70433930e-01]]\n",
      "\n",
      "  [[-2.97887977e-02 -9.67581085e-02 -2.67748230e-01]\n",
      "   [ 1.50088135e-01  1.30596039e-01  7.12557080e-02]\n",
      "   [-2.79159180e-01 -1.07642692e-02  2.91316962e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.14630489e-01 -4.50751349e-02 -2.76999094e-01]\n",
      "   [ 8.98321759e-03 -1.90832755e-02  1.42905006e-03]\n",
      "   [ 9.70622782e-02 -5.48955502e-02  3.93515003e-01]]\n",
      "\n",
      "  [[ 1.56245489e-01  1.66352222e-01 -2.28242748e-01]\n",
      "   [-6.11128683e-02  1.01449018e-01 -5.17767723e-02]\n",
      "   [ 3.00864066e-02 -2.63035839e-01  2.87202911e-01]]\n",
      "\n",
      "  [[ 1.07183839e-01 -6.39168363e-03 -6.76171904e-02]\n",
      "   [ 4.42096445e-01 -6.95261872e-02  2.98498184e-01]\n",
      "   [-7.34480936e-02 -2.54857732e-01 -1.78276267e-01]]\n",
      "\n",
      "  [[-4.90643435e-01  1.65102155e-01  2.52732209e-01]\n",
      "   [-1.02825831e-01 -1.11411890e-01 -5.36653161e-01]\n",
      "   [ 1.55834538e-01 -6.96178314e-02  1.25171599e-01]]\n",
      "\n",
      "  [[ 2.39639837e-01 -3.06641708e-01 -7.24934290e-02]\n",
      "   [-7.84413533e-03  3.62865175e-02  7.04683445e-02]\n",
      "   [-1.97293295e-01 -1.94458518e-02  6.38831601e-01]]\n",
      "\n",
      "  [[ 1.51103981e-01  1.44336570e-01 -8.17030483e-02]\n",
      "   [-2.09256620e-01  3.48712740e-02  1.73393940e-01]\n",
      "   [ 4.31101215e-01 -1.32622795e-01 -6.82828344e-02]]\n",
      "\n",
      "  [[ 1.87902176e-01  1.19192435e-01  1.70046628e-01]\n",
      "   [-6.80381883e-01 -1.99156467e-01 -3.38786224e-01]\n",
      "   [ 1.05921889e-01 -1.75279863e-01 -2.27935126e-02]]\n",
      "\n",
      "  [[-1.96984041e-02  7.15734666e-02 -4.16829864e-01]\n",
      "   [-1.63934600e-01  3.19502775e-01 -2.34009557e-01]\n",
      "   [ 1.18731442e-01  1.05065196e-01  2.31433837e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.10809742e-01  2.65097422e-01 -8.21449384e-02]\n",
      "   [-1.56667229e-01  2.35570719e-01  2.45315292e-01]\n",
      "   [-1.34067214e-01  3.70000621e-01 -1.19332067e-01]]\n",
      "\n",
      "  [[ 3.37725351e-01 -2.34008513e-01 -1.04545239e-01]\n",
      "   [ 3.20274104e-01 -1.06897207e-02  1.07121850e-01]\n",
      "   [-1.24937143e-02  1.97606337e-01 -9.25283224e-02]]\n",
      "\n",
      "  [[ 2.06718513e-01 -1.31195755e-02 -6.98389159e-02]\n",
      "   [-2.97532582e-01 -4.51717712e-01  1.10404997e-01]\n",
      "   [ 6.77097069e-02 -1.50952081e-01  4.58037502e-01]]\n",
      "\n",
      "  [[ 1.64850672e-01  3.29954967e-01  8.46022402e-02]\n",
      "   [ 2.52735828e-01  1.90921353e-01  1.08908994e-01]\n",
      "   [-5.79930985e-02 -1.00784187e-01 -6.96770847e-02]]\n",
      "\n",
      "  [[ 3.02938414e-01 -3.33564880e-02 -1.82416805e-04]\n",
      "   [ 1.41382531e-01  2.79628790e-02 -2.97810101e-02]\n",
      "   [ 2.01376923e-02 -1.08561855e-01  9.14016772e-02]]\n",
      "\n",
      "  [[-1.48775887e-01  1.86725402e-01  4.16554345e-02]\n",
      "   [ 2.19632081e-02  2.45309291e-01  3.45822295e-01]\n",
      "   [ 2.09622390e-01  7.20958933e-02  2.19331145e-01]]\n",
      "\n",
      "  [[ 2.10130620e-01 -3.23510490e-01  3.18048621e-01]\n",
      "   [ 2.68582249e-01 -8.67677084e-02  3.46664419e-02]\n",
      "   [ 3.35918329e-01  2.74966660e-01 -1.48513838e-01]]\n",
      "\n",
      "  [[-1.07815771e-01  5.56773937e-01 -1.69738058e-02]\n",
      "   [-5.55589574e-01  4.58562629e-01  2.40052178e-01]\n",
      "   [ 2.13172744e-01  2.54525016e-01  1.64274658e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.83411736e-01 -5.88620752e-02 -7.25711614e-02]\n",
      "   [-1.98288383e-02  3.98624786e-01 -3.52729894e-01]\n",
      "   [ 1.37942620e-01 -2.12792763e-01  9.90568462e-02]]\n",
      "\n",
      "  [[ 1.35210662e-01 -3.02346262e-01  1.61916464e-01]\n",
      "   [-9.52629569e-02 -5.13099595e-01  2.27066375e-03]\n",
      "   [ 2.28381801e-03 -2.66740630e-01 -1.18670628e-01]]\n",
      "\n",
      "  [[-2.38570806e-01  1.06507219e-01 -1.56072634e-01]\n",
      "   [-2.53504220e-01  3.67382733e-01  3.96700037e-03]\n",
      "   [-1.41423409e-01 -4.48422396e-02  6.53113698e-02]]\n",
      "\n",
      "  [[-1.03019342e-01 -1.05342595e-01  2.71193866e-01]\n",
      "   [ 1.19555363e-01 -1.48242310e-01  1.64948307e-01]\n",
      "   [ 3.60818763e-01  1.95866035e-01  4.67186476e-02]]\n",
      "\n",
      "  [[-1.85970254e-01  1.14039523e-01 -1.96042066e-01]\n",
      "   [ 1.72726701e-01  2.88744231e-01  1.58093782e-01]\n",
      "   [ 8.74513528e-02  1.92868721e-01 -2.60616033e-01]]\n",
      "\n",
      "  [[-3.46124015e-01 -1.39288898e-01 -4.20042285e-01]\n",
      "   [ 1.97261173e-02  8.64761051e-03  1.12056534e-01]\n",
      "   [-1.58629478e-01  1.05910564e-02 -5.41768541e-02]]\n",
      "\n",
      "  [[ 4.16084790e-02 -2.55160501e-01  1.54808344e-01]\n",
      "   [-1.73686881e-01 -1.59388208e-01  4.77795541e-01]\n",
      "   [-1.50502120e-01 -2.31694146e-01 -3.89791480e-02]]\n",
      "\n",
      "  [[ 1.73365353e-01  2.70657027e-01 -9.10829527e-02]\n",
      "   [-1.93362884e-01  3.12037091e-01  1.48695836e-01]\n",
      "   [ 1.48267579e-01 -3.63904441e-02 -8.80359113e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.06766857e-01  2.29154113e-02 -3.72040262e-01]\n",
      "   [ 2.62735041e-01 -1.36238638e-01  1.68596835e-01]\n",
      "   [-2.30434128e-01  3.93334091e-01  4.97582367e-02]]\n",
      "\n",
      "  [[-1.44354191e-01 -1.94648035e-01  7.64398850e-02]\n",
      "   [-1.11361340e-01  2.15655079e-01 -3.74238924e-01]\n",
      "   [-2.41344880e-01 -1.16071855e-01  1.64849175e-01]]\n",
      "\n",
      "  [[-7.28652620e-02  2.33902234e-01  9.89922167e-02]\n",
      "   [ 4.12732594e-01 -1.72572243e-01 -1.04297105e-01]\n",
      "   [-1.23680565e-01  1.05094352e-01 -4.40009128e-01]]\n",
      "\n",
      "  [[ 1.42888710e-01 -1.04403583e-02  1.21479775e-01]\n",
      "   [-5.02125082e-02 -1.58570501e-01  1.50947262e-01]\n",
      "   [ 6.61164274e-01 -2.43055879e-01  3.39181024e-01]]\n",
      "\n",
      "  [[-2.51724635e-02  1.11020321e-02  2.32158287e-01]\n",
      "   [-8.40774775e-02  3.12715308e-01 -3.41272774e-02]\n",
      "   [ 1.09320058e-01  2.16248734e-01  4.00724155e-02]]\n",
      "\n",
      "  [[-5.92488014e-02  3.39634811e-01  3.17966089e-01]\n",
      "   [ 4.66329158e-01 -7.05807148e-02  1.00506630e-03]\n",
      "   [-2.35230555e-01  4.02869807e-01  1.35443686e-01]]\n",
      "\n",
      "  [[ 2.29147833e-01  1.42167109e-01 -1.05338556e-01]\n",
      "   [-6.24544872e-03  1.05121006e-01  2.19987957e-01]\n",
      "   [ 2.65315646e-02  1.28628335e-01  1.57762466e-01]]\n",
      "\n",
      "  [[ 3.53063366e-01 -1.46310828e-01 -1.10943383e-01]\n",
      "   [-1.08901209e-01  3.29623342e-01  2.52537473e-01]\n",
      "   [-1.60940593e-02  2.40694956e-02  1.58696982e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.77012290e-02 -5.44786649e-02 -2.18988548e-03]\n",
      "   [-6.23615596e-02  1.85312993e-01  5.51802545e-02]\n",
      "   [ 1.02592900e-01  1.99659805e-01  7.28893795e-02]]\n",
      "\n",
      "  [[-1.49299611e-01 -2.19430547e-01 -2.35679340e-02]\n",
      "   [-2.02387318e-01  1.89864944e-02  9.44931503e-02]\n",
      "   [-2.44011849e-02  2.86194906e-01  1.55335461e-01]]\n",
      "\n",
      "  [[-3.44424909e-01  1.78951771e-02 -1.13463549e-01]\n",
      "   [-3.98328488e-01 -1.03371159e-01 -7.41031865e-02]\n",
      "   [-2.17021277e-01 -1.63762893e-01  4.07832402e-02]]\n",
      "\n",
      "  [[ 1.31556792e-01  4.74825024e-02 -4.20212425e-01]\n",
      "   [-1.78237832e-01  1.21718805e-03  2.47526273e-01]\n",
      "   [ 5.57036805e-02  1.94494098e-01  2.97693395e-02]]\n",
      "\n",
      "  [[ 1.50741790e-01 -1.80158199e-01  7.06101975e-02]\n",
      "   [ 2.79455205e-01 -4.50355764e-01  4.27300274e-02]\n",
      "   [-1.38717133e-01  1.06411894e-01 -3.57525742e-01]]\n",
      "\n",
      "  [[ 4.87020351e-02  3.63739742e-02  2.81934458e-02]\n",
      "   [ 3.31955531e-02 -4.25235571e-01 -3.93860701e-02]\n",
      "   [ 1.33282299e-01  2.35329219e-01  3.44707406e-01]]\n",
      "\n",
      "  [[-1.79533867e-01  3.77721028e-02 -2.64091393e-01]\n",
      "   [-3.42425016e-01 -6.78202203e-03  5.03335300e-02]\n",
      "   [-4.10196800e-02 -4.26053526e-01 -4.41833395e-02]]\n",
      "\n",
      "  [[ 6.25304794e-02  1.83190367e-01 -4.34796010e-01]\n",
      "   [ 5.47968238e-01  2.25927881e-02 -2.44257319e-02]\n",
      "   [ 1.95218486e-01  4.84441087e-02 -1.02185382e-01]]]\n",
      "\n",
      "\n",
      " [[[ 2.02232209e-01  8.00981717e-02  6.89921360e-02]\n",
      "   [-1.36759765e-01 -1.65023351e-02 -2.52375547e-01]\n",
      "   [ 9.34069630e-02 -3.31640747e-01  1.68918977e-01]]\n",
      "\n",
      "  [[-6.94502155e-02 -2.56782837e-01  2.13809149e-01]\n",
      "   [ 2.61197633e-02  4.61615159e-01 -7.95264955e-02]\n",
      "   [-1.48814727e-01  3.13692399e-02  3.51376544e-02]]\n",
      "\n",
      "  [[-8.58392282e-02  1.69869073e-01 -2.30221666e-01]\n",
      "   [-1.11102822e-01 -3.09159445e-01 -3.42050111e-01]\n",
      "   [-2.27477305e-01  5.06526042e-02 -2.07950792e-01]]\n",
      "\n",
      "  [[ 4.50439772e-02 -1.48111556e-01 -1.51378574e-01]\n",
      "   [ 8.31129319e-02 -9.13626161e-02 -1.16866941e-01]\n",
      "   [-1.78869519e-01 -4.40025870e-01 -8.20910641e-02]]\n",
      "\n",
      "  [[-5.75029090e-02  3.25291743e-01  7.31653959e-02]\n",
      "   [-7.04658978e-02 -1.75636066e-01 -7.73477865e-02]\n",
      "   [-3.79682408e-02  1.09146276e-01 -6.50854373e-03]]\n",
      "\n",
      "  [[ 4.60170861e-03  1.07110937e-02  6.34005160e-02]\n",
      "   [ 1.63142918e-01  9.76836808e-03  3.66009754e-01]\n",
      "   [-1.11192971e-01 -2.00580049e-01  1.45659773e-01]]\n",
      "\n",
      "  [[ 1.74840799e-01 -3.40138415e-01 -1.45935826e-01]\n",
      "   [ 2.91978325e-01  1.68789380e-01 -7.25135773e-02]\n",
      "   [ 1.42408224e-01  9.74155696e-02 -9.87304474e-03]]\n",
      "\n",
      "  [[ 2.98339140e-01 -1.01370791e-01 -3.07682615e-01]\n",
      "   [-1.88411800e-01  8.15450224e-02  1.00651332e-01]\n",
      "   [-4.95318724e-02  1.76882012e-02  1.36516797e-01]]]\n",
      "\n",
      "\n",
      " [[[-2.02055848e-01 -4.04298215e-02 -3.60589795e-01]\n",
      "   [-3.18120443e-01  2.36696518e-01 -9.82020878e-02]\n",
      "   [ 1.70362224e-01 -1.48845993e-01  3.08680937e-01]]\n",
      "\n",
      "  [[ 1.17826554e-01 -4.85932778e-02 -2.74018076e-02]\n",
      "   [ 3.09865038e-01  8.42724477e-03 -1.86027548e-01]\n",
      "   [-5.87631293e-02  2.69470782e-01 -1.76504017e-01]]\n",
      "\n",
      "  [[-6.73281760e-02  5.41656679e-02  1.33583015e-01]\n",
      "   [-1.29002557e-01 -1.69637123e-01  6.24064403e-02]\n",
      "   [-8.69218060e-02 -2.84454102e-01  2.13218184e-01]]\n",
      "\n",
      "  [[ 4.91792008e-02  2.16377931e-01  1.14122162e-01]\n",
      "   [-1.82214233e-01  9.67062637e-02 -6.88540973e-02]\n",
      "   [-4.41119307e-01 -1.34215263e-01  1.36314022e-01]]\n",
      "\n",
      "  [[ 1.31989050e-01 -4.05260904e-01  1.25600263e-01]\n",
      "   [ 2.07388025e-02 -2.64608032e-01  3.03611466e-01]\n",
      "   [ 3.19331092e-01  2.22629930e-01  1.23069865e-01]]\n",
      "\n",
      "  [[-4.01040606e-01 -1.17030575e-02  1.88762252e-01]\n",
      "   [-1.31914919e-01 -1.64835174e-01  7.83843731e-02]\n",
      "   [ 2.14222379e-01  3.45028898e-01  3.59947846e-01]]\n",
      "\n",
      "  [[-4.69419700e-01 -2.43940210e-01  1.39144265e-01]\n",
      "   [ 1.55572428e-01  1.79213063e-01  1.38536093e-01]\n",
      "   [ 4.51712603e-02  1.20993506e-01 -5.53766390e-02]]\n",
      "\n",
      "  [[ 1.87240041e-01  2.29181741e-01  1.99170512e-01]\n",
      "   [ 2.32385230e-01 -5.01390764e-01  8.10456803e-03]\n",
      "   [-3.44108714e-01  3.30025632e-01 -1.67923806e-01]]]\n",
      "\n",
      "\n",
      " [[[ 7.30144819e-02  5.24804626e-02  1.52938300e-01]\n",
      "   [-3.21042588e-01 -7.61444082e-02  2.76466599e-02]\n",
      "   [-5.80344292e-02  1.19888683e-01 -1.77944970e-01]]\n",
      "\n",
      "  [[-2.26385707e-02 -1.38494044e-02 -3.09705833e-01]\n",
      "   [ 1.29261939e-01  8.64690180e-03  8.59644542e-02]\n",
      "   [-1.39294827e-01  5.88318116e-02  2.49569461e-01]]\n",
      "\n",
      "  [[ 2.11354829e-01 -2.63783702e-01  1.56207236e-01]\n",
      "   [ 1.67561539e-01  1.31529346e-01 -1.82231206e-02]\n",
      "   [-5.35341535e-02  4.45537409e-01 -1.57034304e-01]]\n",
      "\n",
      "  [[ 6.12767996e-03  5.20189093e-02 -3.37505213e-01]\n",
      "   [ 2.27141999e-01 -2.15666919e-01  2.28465720e-02]\n",
      "   [-3.44781616e-01  1.72630154e-01  3.35739990e-01]]\n",
      "\n",
      "  [[ 4.05462781e-01  5.51048048e-01  9.33938977e-02]\n",
      "   [-2.72669279e-01 -1.26381664e-01 -4.55930903e-01]\n",
      "   [-1.87758195e-01 -2.90967490e-01  4.15087006e-02]]\n",
      "\n",
      "  [[-3.52389731e-01  8.09284115e-02 -3.29000037e-02]\n",
      "   [ 2.03132681e-02  4.65014873e-02  8.91314707e-02]\n",
      "   [ 2.06734436e-01  4.77599076e-02 -2.31066805e-01]]\n",
      "\n",
      "  [[ 1.71740394e-01 -1.19488211e-01  1.65656314e-01]\n",
      "   [ 3.20004520e-01  4.67002078e-01  1.76204248e-01]\n",
      "   [ 3.70650846e-01  8.53305989e-01 -1.57730015e-01]]\n",
      "\n",
      "  [[-2.92828156e-01  2.98714123e-01 -3.32125835e-01]\n",
      "   [-6.33631661e-02 -1.26091445e-01 -1.73274313e-01]\n",
      "   [-6.09198003e-02 -5.96358981e-02  5.42134602e-02]]]\n",
      "\n",
      "\n",
      " [[[ 9.24222322e-02  2.15037367e-01 -1.01455393e-01]\n",
      "   [-1.02181912e-01 -7.00167503e-02  2.65861874e-01]\n",
      "   [-1.59133388e-02 -1.78127146e-01 -2.28732325e-01]]\n",
      "\n",
      "  [[-1.48849091e-01  1.79719656e-01 -1.75512967e-01]\n",
      "   [ 2.73911081e-01 -7.33909473e-02 -3.35221020e-01]\n",
      "   [-3.10530067e-01  9.91579991e-03 -9.36406030e-02]]\n",
      "\n",
      "  [[-1.77254624e-02  1.08883188e-01 -8.39303531e-02]\n",
      "   [ 8.05642946e-02  4.29719625e-02  4.00627034e-01]\n",
      "   [-2.36025182e-02 -4.33319429e-02  9.15980990e-02]]\n",
      "\n",
      "  [[-1.28024784e-02 -1.57707399e-01 -7.14693959e-02]\n",
      "   [ 4.32991691e-02  1.85445206e-01 -1.13217631e-01]\n",
      "   [-2.67918429e-01  1.59954777e-01  1.55735428e-01]]\n",
      "\n",
      "  [[ 1.13279943e-01  2.05691133e-01 -3.63616633e-01]\n",
      "   [-1.65590263e-01 -5.74053840e-02 -2.14342313e-01]\n",
      "   [ 2.30459879e-01  1.58664614e-01 -1.56503993e-01]]\n",
      "\n",
      "  [[ 2.24221621e-03  1.59043601e-01 -1.66445799e-01]\n",
      "   [ 1.79223683e-01  2.15713226e-01  1.40334458e-01]\n",
      "   [ 7.53613017e-02 -4.45248522e-02 -9.84834014e-02]]\n",
      "\n",
      "  [[ 1.11954081e-02 -3.63507970e-03 -4.12377585e-01]\n",
      "   [-1.20640220e-01  1.01203373e-01  3.68920900e-01]\n",
      "   [-5.64063140e-02 -7.75012173e-02  1.80128193e-01]]\n",
      "\n",
      "  [[-2.76397051e-01  7.08923214e-02 -4.93345484e-01]\n",
      "   [-8.07467558e-02  4.11085193e-01 -2.90848669e-01]\n",
      "   [ 2.09484756e-02 -3.39503669e-01  3.72751968e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.47262831e-02  2.18832998e-01 -1.53308969e-01]\n",
      "   [-2.37385550e-01 -1.09479705e-01  2.75718871e-01]\n",
      "   [-1.89431903e-01 -1.13694068e-01  1.97067254e-01]]\n",
      "\n",
      "  [[ 4.03609019e-02  8.80933238e-02  2.81574903e-01]\n",
      "   [-1.53876806e-01 -3.89675163e-01  3.58161130e-02]\n",
      "   [-1.15319834e-01  2.00957020e-01 -3.99511995e-01]]\n",
      "\n",
      "  [[-4.47480054e-01  1.93669040e-01 -1.41020070e-01]\n",
      "   [ 1.91007709e-01  4.03525243e-02  3.80509473e-01]\n",
      "   [ 7.32946966e-02 -2.00538571e-01 -4.08988611e-02]]\n",
      "\n",
      "  [[ 6.91834207e-02 -1.31553666e-01 -1.80413678e-01]\n",
      "   [-3.21443096e-01  2.68636423e-01  2.95180695e-01]\n",
      "   [ 1.44327806e-02  8.34619710e-02  7.63211285e-02]]\n",
      "\n",
      "  [[-1.75917501e-02 -3.27249154e-01 -1.70780193e-01]\n",
      "   [ 3.68018693e-01 -7.56342890e-03  1.10379955e-01]\n",
      "   [-2.49787943e-01 -1.74257632e-01 -2.64710753e-01]]\n",
      "\n",
      "  [[-1.33383823e-02  2.36087092e-02 -1.52085474e-01]\n",
      "   [ 6.04526677e-02 -3.22071122e-01  4.70111401e-01]\n",
      "   [ 1.97273251e-02  8.96218965e-02 -3.19404203e-02]]\n",
      "\n",
      "  [[ 4.44241090e-01  1.29178518e-01 -2.26935314e-02]\n",
      "   [-5.72253281e-01  5.40709927e-02  1.05620521e-01]\n",
      "   [ 5.90438707e-02  3.11658851e-01 -1.67434802e-01]]\n",
      "\n",
      "  [[ 2.27333896e-01  1.31278176e-01  3.35387917e-01]\n",
      "   [ 3.33639448e-02 -9.03189334e-02 -8.08396845e-02]\n",
      "   [-1.06517386e-01 -8.77735619e-02 -4.37404129e-02]]]],\n",
      "bn_f2: [[0.05433405 0.05696125 0.09300716 0.11118921 0.11082504 0.0226558\n",
      "  0.08295647 0.12103239 0.01695237 0.20412046 0.00878849 0.00355152]\n",
      " [0.05687688 0.12989068 0.08038365 0.09620673 0.00993875 0.08081073\n",
      "  0.10503054 0.15420922 0.15203321 0.06815531 0.08560398 0.17356583]],\n",
      "deconv_f3: [[[[-0. -0.  0.  0. -0.]\n",
      "   [-0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]\n",
      "   [-0. -0.  0. -0. -0.]\n",
      "   [-0.  0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0. -0. -0.]\n",
      "   [-0. -0. -0.  0.  0.]\n",
      "   [ 0.  0.  0. -0.  0.]\n",
      "   [ 0. -0. -0.  0. -0.]\n",
      "   [ 0.  0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0. -0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [-0. -0.  0.  0.  0.]\n",
      "   [-0.  0.  0. -0. -0.]\n",
      "   [ 0.  0.  0.  0.  0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0. -0.  0.  0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [-0.  0.  0.  0.  0.]\n",
      "   [-0. -0.  0.  0. -0.]\n",
      "   [-0. -0.  0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0. -0. -0.]\n",
      "   [-0. -0. -0. -0. -0.]\n",
      "   [ 0.  0. -0.  0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [-0.  0. -0. -0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.  0. -0.]\n",
      "   [-0. -0. -0. -0.  0.]\n",
      "   [ 0. -0. -0. -0.  0.]\n",
      "   [-0. -0.  0.  0.  0.]\n",
      "   [-0.  0. -0. -0.  0.]]]\n",
      "\n",
      "\n",
      " [[[-0.  0.  0. -0.  0.]\n",
      "   [-0. -0.  0. -0. -0.]\n",
      "   [-0. -0.  0.  0. -0.]\n",
      "   [ 0. -0. -0.  0. -0.]\n",
      "   [ 0. -0. -0.  0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0. -0.  0.  0.]\n",
      "   [ 0. -0. -0. -0. -0.]\n",
      "   [ 0.  0.  0.  0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0. -0.]\n",
      "   [-0. -0. -0. -0.  0.]\n",
      "   [ 0.  0. -0.  0.  0.]\n",
      "   [ 0.  0. -0.  0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.  0. -0.  0.  0.]\n",
      "   [-0.  0.  0.  0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [ 0.  0.  0.  0. -0.]\n",
      "   [ 0. -0. -0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0. -0.]\n",
      "   [-0. -0. -0. -0. -0.]\n",
      "   [ 0. -0.  0. -0.  0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [-0. -0.  0. -0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.  0. -0.]\n",
      "   [ 0.  0. -0.  0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.  0.]]]\n",
      "\n",
      "\n",
      " [[[-0. -0. -0.  0. -0.]\n",
      "   [-0. -0. -0. -0.  0.]\n",
      "   [-0. -0. -0. -0. -0.]\n",
      "   [ 0. -0.  0. -0.  0.]\n",
      "   [ 0. -0. -0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0. -0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [-0. -0. -0. -0. -0.]\n",
      "   [ 0. -0. -0. -0.  0.]\n",
      "   [ 0.  0.  0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0.  0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [ 0.  0.  0. -0.  0.]\n",
      "   [ 0. -0.  0.  0. -0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0. -0. -0.  0. -0.]\n",
      "   [-0.  0.  0.  0.  0.]\n",
      "   [ 0. -0. -0. -0.  0.]\n",
      "   [-0.  0. -0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [ 0.  0.  0. -0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [-0. -0.  0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0. -0.  0.]\n",
      "   [-0.  0. -0. -0.  0.]\n",
      "   [ 0.  0. -0.  0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0. -0.  0. -0. -0.]\n",
      "   [ 0.  0. -0. -0. -0.]\n",
      "   [-0. -0.  0. -0.  0.]\n",
      "   [-0. -0.  0. -0. -0.]\n",
      "   [-0.  0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0. -0.  0.]\n",
      "   [-0. -0.  0. -0.  0.]\n",
      "   [-0.  0. -0. -0.  0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [ 0.  0. -0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0. -0.  0.]\n",
      "   [ 0.  0.  0. -0.  0.]\n",
      "   [ 0. -0. -0.  0. -0.]\n",
      "   [ 0. -0. -0.  0.  0.]\n",
      "   [-0. -0. -0.  0. -0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.  0.  0.  0. -0.]\n",
      "   [-0.  0.  0. -0. -0.]\n",
      "   [-0. -0.  0.  0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [-0.  0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.  0.]\n",
      "   [ 0.  0. -0. -0. -0.]\n",
      "   [ 0.  0.  0.  0. -0.]\n",
      "   [-0. -0. -0.  0. -0.]\n",
      "   [ 0.  0. -0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0.  0. -0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [-0. -0. -0.  0. -0.]\n",
      "   [ 0.  0.  0.  0. -0.]]]\n",
      "\n",
      "\n",
      " [[[ 0. -0. -0. -0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [-0. -0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.  0.]\n",
      "   [ 0.  0. -0. -0.  0.]\n",
      "   [-0.  0.  0. -0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0.  0. -0.]\n",
      "   [-0. -0. -0. -0. -0.]\n",
      "   [ 0. -0. -0. -0.  0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [-0. -0.  0. -0. -0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0. -0. -0. -0. -0.]\n",
      "   [-0.  0. -0. -0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [-0. -0. -0.  0.  0.]\n",
      "   [ 0.  0.  0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0. -0. -0.]\n",
      "   [-0. -0. -0.  0. -0.]\n",
      "   [ 0. -0. -0. -0. -0.]\n",
      "   [ 0. -0.  0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.  0. -0.]\n",
      "   [-0. -0.  0.  0.  0.]\n",
      "   [-0. -0.  0.  0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [ 0.  0. -0. -0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.  0.  0.]\n",
      "   [-0. -0. -0.  0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [-0.  0. -0.  0.  0.]\n",
      "   [-0.  0.  0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.  0.  0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [-0. -0.  0.  0. -0.]\n",
      "   [-0.  0.  0.  0.  0.]\n",
      "   [ 0.  0. -0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0.  0.]\n",
      "   [-0.  0.  0. -0.  0.]\n",
      "   [-0. -0.  0.  0. -0.]\n",
      "   [-0. -0. -0. -0.  0.]\n",
      "   [-0. -0. -0. -0. -0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0. -0. -0. -0.  0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [ 0. -0.  0. -0.  0.]\n",
      "   [-0. -0.  0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0. -0.  0.]\n",
      "   [-0. -0.  0. -0.  0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [-0. -0. -0. -0. -0.]\n",
      "   [-0. -0. -0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0. -0. -0.]\n",
      "   [ 0.  0.  0.  0.  0.]\n",
      "   [-0.  0. -0. -0.  0.]\n",
      "   [-0. -0.  0. -0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]]]],\n",
      "bn_f3: [[0.0829699  0.13964418 0.09172248 0.0287634  0.18845049 0.16700765\n",
      "  0.08395016 0.02132033 0.0051489  0.18858028]\n",
      " [0.0130159  0.19323754 0.16180403 0.08747419 0.11486062 0.05550408\n",
      "  0.03489626 0.07710835 0.06738322 0.03250825]],\n",
      "deconv_f4: [[[[ 0. -0.  0. -0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [-0. -0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [-0.  0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.  0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [ 0. -0. -0. -0.]\n",
      "   [-0.  0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.  0.]\n",
      "   [ 0. -0.  0. -0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0. -0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [ 0.  0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0. -0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [-0.  0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [-0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0. -0.]\n",
      "   [-0.  0. -0.  0.]\n",
      "   [-0.  0. -0.  0.]\n",
      "   [-0. -0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [ 0.  0. -0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.  0.]\n",
      "   [-0. -0. -0. -0.]\n",
      "   [ 0.  0.  0. -0.]\n",
      "   [ 0.  0. -0.  0.]]]\n",
      "\n",
      "\n",
      " [[[-0. -0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [ 0. -0.  0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0.  0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [ 0.  0. -0.  0.]\n",
      "   [-0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [-0. -0. -0. -0.]\n",
      "   [ 0.  0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [ 0. -0. -0. -0.]\n",
      "   [-0.  0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.  0.]\n",
      "   [-0.  0. -0.  0.]\n",
      "   [-0. -0. -0. -0.]\n",
      "   [ 0. -0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0.]\n",
      "   [ 0.  0. -0.  0.]\n",
      "   [-0. -0. -0. -0.]\n",
      "   [ 0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [ 0. -0. -0. -0.]\n",
      "   [-0.  0. -0. -0.]\n",
      "   [ 0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0.]\n",
      "   [ 0. -0.  0. -0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [ 0. -0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [-0.  0. -0.  0.]\n",
      "   [ 0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [-0.  0. -0. -0.]]]\n",
      "\n",
      "\n",
      " [[[-0.  0.  0.  0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [-0. -0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.  0.]\n",
      "   [-0. -0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [-0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [ 0. -0.  0. -0.]\n",
      "   [ 0. -0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0.]\n",
      "   [-0.  0. -0.  0.]\n",
      "   [ 0. -0. -0. -0.]\n",
      "   [-0.  0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. -0.]\n",
      "   [ 0. -0.  0. -0.]\n",
      "   [-0.  0. -0. -0.]\n",
      "   [ 0. -0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [-0.  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [-0.  0.  0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0. -0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [ 0. -0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0. -0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [ 0. -0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [-0.  0.  0. -0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.  0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [-0. -0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [ 0. -0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [ 0.  0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [ 0. -0.  0. -0.]\n",
      "   [-0.  0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.  0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [ 0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.  0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [-0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [ 0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0.]\n",
      "   [ 0.  0. -0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.  0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [-0. -0. -0. -0.]\n",
      "   [ 0.  0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0. -0.]\n",
      "   [-0.  0. -0. -0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [-0. -0. -0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0. -0.]\n",
      "   [ 0.  0. -0.  0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [ 0.  0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [ 0. -0.  0. -0.]\n",
      "   [-0.  0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [-0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0. -0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [-0.  0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0. -0.]\n",
      "   [-0.  0. -0. -0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [-0. -0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0. -0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [-0. -0.  0. -0.]\n",
      "   [-0. -0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [-0. -0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0. -0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [ 0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [ 0. -0.  0. -0.]\n",
      "   [-0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0. -0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [ 0. -0.  0. -0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0.  0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [-0.  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.  0.]\n",
      "   [ 0.  0. -0. -0.]\n",
      "   [ 0.  0.  0. -0.]\n",
      "   [ 0. -0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0. -0.]\n",
      "   [ 0.  0.  0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [-0.  0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.  0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [-0.  0. -0.  0.]\n",
      "   [-0. -0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0. -0.]\n",
      "   [ 0. -0. -0. -0.]\n",
      "   [-0. -0.  0.  0.]\n",
      "   [-0. -0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0. -0.]\n",
      "   [-0.  0. -0.  0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [ 0. -0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.  0.]\n",
      "   [-0. -0. -0.  0.]\n",
      "   [ 0. -0. -0.  0.]\n",
      "   [-0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0. -0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [ 0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.  0.]\n",
      "   [-0.  0.  0. -0.]\n",
      "   [-0.  0.  0.  0.]\n",
      "   [-0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [ 0. -0.  0.  0.]\n",
      "   [-0. -0.  0. -0.]]]],\n",
      "bn_f4: [[0.17771214 0.02436838 0.1009551  0.11915302 0.04352    0.06633427]\n",
      " [0.17489147 0.01289525 0.17863619 0.12454269 0.13439777 0.1096418 ]],\n",
      "deconv_f5: [[[[-0. -0. -0.  0. -0.]\n",
      "   [-0. -0.  0. -0.  0.]\n",
      "   [-0. -0. -0. -0.  0.]\n",
      "   [-0.  0. -0.  0.  0.]\n",
      "   [ 0. -0.  0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0. -0.  0.]\n",
      "   [-0. -0. -0. -0. -0.]\n",
      "   [-0. -0. -0.  0. -0.]\n",
      "   [-0.  0. -0. -0.  0.]\n",
      "   [-0. -0. -0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.  0. -0.]\n",
      "   [-0.  0.  0.  0.  0.]\n",
      "   [ 0.  0.  0. -0.  0.]\n",
      "   [ 0.  0. -0. -0.  0.]\n",
      "   [-0. -0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [ 0. -0.  0.  0. -0.]\n",
      "   [-0. -0.  0. -0. -0.]\n",
      "   [ 0.  0. -0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0. -0.]\n",
      "   [-0. -0. -0.  0. -0.]\n",
      "   [-0.  0.  0.  0.  0.]\n",
      "   [-0.  0.  0.  0. -0.]\n",
      "   [ 0. -0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0. -0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [-0.  0.  0.  0. -0.]\n",
      "   [-0.  0.  0. -0.  0.]\n",
      "   [-0.  0.  0.  0. -0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0. -0.  0.]\n",
      "   [-0. -0. -0.  0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [ 0. -0.  0.  0.  0.]\n",
      "   [ 0. -0. -0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0.  0.  0.]\n",
      "   [-0.  0.  0. -0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [ 0.  0. -0.  0. -0.]\n",
      "   [ 0. -0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0. -0.  0.]\n",
      "   [-0.  0. -0.  0.  0.]\n",
      "   [ 0.  0.  0.  0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0. -0.  0.]\n",
      "   [ 0. -0.  0.  0.  0.]\n",
      "   [ 0.  0. -0. -0. -0.]\n",
      "   [ 0.  0.  0.  0. -0.]\n",
      "   [ 0.  0.  0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0.  0.  0.]\n",
      "   [ 0. -0.  0. -0.  0.]\n",
      "   [ 0. -0. -0. -0.  0.]\n",
      "   [ 0.  0.  0. -0. -0.]\n",
      "   [ 0.  0. -0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0. -0. -0.]\n",
      "   [ 0. -0. -0. -0. -0.]\n",
      "   [-0. -0.  0. -0. -0.]\n",
      "   [ 0.  0.  0.  0. -0.]\n",
      "   [-0.  0. -0. -0. -0.]]]\n",
      "\n",
      "\n",
      " [[[ 0. -0. -0.  0.  0.]\n",
      "   [ 0.  0.  0. -0.  0.]\n",
      "   [ 0.  0. -0. -0.  0.]\n",
      "   [ 0. -0. -0.  0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0. -0.  0.]\n",
      "   [-0.  0. -0. -0. -0.]\n",
      "   [ 0. -0.  0. -0.  0.]\n",
      "   [ 0.  0. -0. -0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0.  0.  0.]\n",
      "   [ 0.  0. -0. -0. -0.]\n",
      "   [ 0.  0.  0.  0. -0.]\n",
      "   [ 0.  0. -0. -0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0. -0.]\n",
      "   [-0.  0. -0.  0. -0.]\n",
      "   [-0. -0. -0.  0.  0.]\n",
      "   [-0.  0.  0.  0. -0.]\n",
      "   [ 0.  0.  0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0. -0.  0.]\n",
      "   [ 0.  0.  0.  0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]\n",
      "   [-0.  0. -0. -0.  0.]\n",
      "   [-0.  0.  0.  0. -0.]]\n",
      "\n",
      "  [[ 0. -0. -0.  0.  0.]\n",
      "   [-0.  0. -0.  0.  0.]\n",
      "   [ 0. -0. -0. -0.  0.]\n",
      "   [-0. -0. -0. -0.  0.]\n",
      "   [ 0. -0.  0. -0. -0.]]]],\n",
      "bn_f5: [[0.12894459 0.11056641 0.16448257]\n",
      " [0.07178453 0.10726696 0.1918057 ]],\n",
      "conv_f6: [[[[-1.14052144e-01 -3.19681452e-01  3.44000239e-01 -3.65918567e-01\n",
      "     2.68230819e-01]\n",
      "   [-7.86624837e-02  1.59587497e-02 -1.95283836e-01  2.22076089e-01\n",
      "    -2.39765661e-01]\n",
      "   [ 5.63611091e-02  7.45224994e-02 -1.94822305e-01  5.46207786e-02\n",
      "     1.34158544e-01]\n",
      "   [-1.36885187e-01  1.57106991e-02 -8.10011322e-02 -3.57020848e-02\n",
      "    -4.76164294e-01]\n",
      "   [-3.74181799e-01 -2.51735986e-01 -7.00465981e-02 -4.23399866e-01\n",
      "    -4.29213735e-02]]\n",
      "\n",
      "  [[-2.05872212e-02  1.70194747e-01 -3.11212906e-01 -1.92826522e-01\n",
      "    -7.31944037e-02]\n",
      "   [-9.09116838e-02  3.06205905e-01 -3.12638571e-02 -1.84949502e-01\n",
      "     1.55769756e-01]\n",
      "   [ 2.20316212e-01  6.17582113e-02 -3.11771940e-01 -2.80679607e-01\n",
      "    -1.69577248e-01]\n",
      "   [-1.52628589e-01 -5.24594647e-02  2.96897194e-02  1.06782984e-02\n",
      "    -1.32202914e-01]\n",
      "   [ 1.67770476e-01  1.82468769e-02  3.06020889e-01 -4.88935125e-02\n",
      "     3.73389483e-03]]\n",
      "\n",
      "  [[-8.22455584e-02  6.38757544e-02 -3.79234989e-01 -5.91530431e-02\n",
      "     2.56013244e-01]\n",
      "   [-2.12901543e-03  2.51500250e-01 -2.36948626e-01 -5.02907092e-01\n",
      "     1.43334572e-02]\n",
      "   [-5.99639196e-02 -1.07563370e-01 -7.98543134e-02  4.65791093e-02\n",
      "    -1.96503243e-01]\n",
      "   [-5.69054627e-02  2.32696415e-01  1.42024587e-01 -3.79371974e-01\n",
      "     1.81116587e-02]\n",
      "   [-2.47849823e-01 -1.09530840e-01  1.86436176e-01  1.07003245e-01\n",
      "    -1.16054885e-01]]]\n",
      "\n",
      "\n",
      " [[[-2.88784042e-01 -2.24667796e-01  1.76646234e-02 -2.43463075e-01\n",
      "    -9.17255093e-02]\n",
      "   [-3.78256433e-03  1.01350623e-01  2.86064387e-01 -5.88878703e-02\n",
      "     2.27154783e-02]\n",
      "   [-1.89040419e-01  1.14841501e-01  1.17425698e-01  3.79968583e-02\n",
      "     1.61740685e-01]\n",
      "   [-1.51452176e-01  9.60857824e-02 -2.21180803e-01  3.38920350e-02\n",
      "    -4.66808323e-02]\n",
      "   [ 3.63954250e-01 -1.70107669e-01 -2.71845666e-02  3.89809451e-02\n",
      "     6.32903939e-02]]\n",
      "\n",
      "  [[-2.63528252e-01 -1.11039005e-01  2.84338928e-02  1.22546469e-01\n",
      "     3.25029021e-01]\n",
      "   [-2.86697483e-01  9.12997985e-02  3.52626236e-02 -1.11916562e-01\n",
      "    -1.40242542e-02]\n",
      "   [ 1.83507247e-01  7.83944807e-02  1.47259320e-01 -1.15850780e-01\n",
      "    -2.69855074e-01]\n",
      "   [ 1.40196646e-01 -2.43949287e-01  3.37327382e-02  1.35415307e-01\n",
      "    -4.57116069e-01]\n",
      "   [-1.85955874e-01  9.19325788e-02  2.14327055e-02 -4.79446652e-01\n",
      "    -2.79927746e-01]]\n",
      "\n",
      "  [[ 1.07236945e-01 -1.16830836e-01 -8.94396782e-02 -8.38415000e-02\n",
      "    -6.19989439e-02]\n",
      "   [-1.40831120e-01  3.15611536e-01 -2.08668456e-01  1.65767036e-02\n",
      "    -5.32434181e-02]\n",
      "   [ 8.81368533e-03 -1.33621372e-01  2.81052172e-01  4.38963357e-01\n",
      "    -2.23356126e-01]\n",
      "   [ 8.12835706e-02 -1.99338347e-01  2.16928425e-01 -2.08231786e-01\n",
      "    -3.08920875e-01]\n",
      "   [ 4.13499849e-02  2.15449815e-01  1.65676361e-01  8.47102825e-02\n",
      "    -3.08942049e-01]]]\n",
      "\n",
      "\n",
      " [[[ 5.15065079e-04  4.63825973e-02  1.64103536e-01  1.21291125e-01\n",
      "    -2.71943734e-01]\n",
      "   [ 1.06193764e-01 -2.66434929e-01  1.94892030e-01  3.54174043e-01\n",
      "    -7.28959894e-02]\n",
      "   [-1.38141122e-01 -5.04575454e-02 -3.66493101e-02 -2.49842525e-02\n",
      "    -5.51399328e-03]\n",
      "   [-5.59140335e-01  9.84720044e-02  3.82512355e-01  6.15735850e-02\n",
      "    -5.38161804e-02]\n",
      "   [-2.51447347e-01  2.07366125e-02 -6.68613701e-04  1.53186204e-01\n",
      "    -4.29838340e-01]]\n",
      "\n",
      "  [[ 1.43731122e-01 -1.63591315e-01  2.02672655e-01  1.39749100e-01\n",
      "     1.09641342e-01]\n",
      "   [-8.64471781e-02 -2.57681232e-01 -4.58878813e-01  2.93858156e-01\n",
      "    -7.28421325e-02]\n",
      "   [ 8.05637299e-02 -2.54875977e-01 -1.77882069e-03  1.26692495e-01\n",
      "    -1.08647118e-01]\n",
      "   [ 2.34952322e-01 -6.37776608e-02  1.07399983e-02  1.03909048e-01\n",
      "    -1.79334370e-01]\n",
      "   [ 2.30813129e-03 -6.12383754e-02 -2.55183371e-01  8.91783897e-03\n",
      "     2.03784005e-01]]\n",
      "\n",
      "  [[-1.51256583e-01 -1.78823430e-01 -8.83090365e-02  3.22963134e-02\n",
      "     2.68683033e-01]\n",
      "   [-1.85158155e-01  3.85302548e-01 -3.77498853e-01 -9.10644311e-02\n",
      "    -3.40334643e-02]\n",
      "   [-3.48250725e-01 -3.08170254e-02 -7.83094444e-02  5.74910069e-02\n",
      "     1.04476486e-01]\n",
      "   [ 3.57921412e-02  5.75007495e-02 -3.70857225e-01  2.48042346e-01\n",
      "    -2.29808876e-02]\n",
      "   [-2.33526500e-02 -3.72194919e-02 -1.57226370e-01 -7.91689492e-02\n",
      "     2.65150145e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.88665801e-01 -1.49972402e-01  2.55347161e-02 -1.33570885e-01\n",
      "     2.72448560e-02]\n",
      "   [ 1.44434190e-01  3.71446752e-02  1.92756899e-01  1.23086844e-01\n",
      "     1.65242824e-02]\n",
      "   [ 1.83346106e-01 -4.87357737e-01  2.42710034e-01 -1.28615683e-01\n",
      "    -2.48304801e-01]\n",
      "   [-7.71597335e-02 -1.20471795e-01 -1.59590787e-01  2.85927461e-01\n",
      "     3.67986465e-02]\n",
      "   [ 2.28641032e-01 -1.68107316e-01 -6.48543975e-02  1.77548601e-01\n",
      "     1.14093216e-01]]\n",
      "\n",
      "  [[-1.97356964e-01 -4.75427292e-02  1.27119328e-01  7.80687803e-02\n",
      "     2.04408390e-01]\n",
      "   [-1.26287599e-01 -1.80653233e-02 -2.06416638e-01 -1.06096597e-01\n",
      "     1.97108026e-01]\n",
      "   [-2.17748899e-01  3.39216456e-01 -7.68201512e-02  2.55433272e-01\n",
      "     8.40149887e-02]\n",
      "   [ 1.98254267e-01 -8.83106456e-02  3.70493710e-02 -4.50203432e-02\n",
      "    -3.06789429e-01]\n",
      "   [ 1.26704881e-02  6.23733809e-02  3.80719154e-01 -1.26891825e-01\n",
      "     9.26617607e-03]]\n",
      "\n",
      "  [[ 1.54400401e-01 -2.22414927e-01 -3.07449755e-01 -8.40089647e-02\n",
      "     1.07137099e-01]\n",
      "   [-7.61724531e-02  1.12458460e-01 -2.01413256e-01 -2.81868860e-01\n",
      "    -9.40415542e-02]\n",
      "   [-4.02577938e-01  4.52801773e-02 -1.98252835e-01  1.70497448e-01\n",
      "    -2.59636998e-01]\n",
      "   [ 2.64388721e-01 -1.57923886e-01  1.63901533e-01 -1.15055828e-01\n",
      "    -2.29307504e-01]\n",
      "   [ 3.35950371e-02 -1.72191123e-01 -4.45332572e-02 -4.67197651e-02\n",
      "     1.86065482e-01]]]\n",
      "\n",
      "\n",
      " [[[-8.30058832e-02 -2.14395025e-01 -2.07169005e-01  2.60875467e-01\n",
      "     1.12466470e-02]\n",
      "   [-7.31616070e-02  1.63737098e-01 -2.77425463e-01  1.15305920e-01\n",
      "    -9.15774379e-03]\n",
      "   [ 2.44869453e-01 -1.75740192e-01  1.08677442e-02  1.85075416e-01\n",
      "     3.05471373e-02]\n",
      "   [-1.63105837e-01 -2.08495908e-01  2.75475845e-01  8.52545517e-02\n",
      "     1.11496331e-01]\n",
      "   [-1.59120959e-01 -1.27495296e-01  4.09547764e-01 -3.69193250e-03\n",
      "    -2.12176100e-01]]\n",
      "\n",
      "  [[ 6.94923595e-02 -2.39924392e-02  5.73318717e-02  1.20718428e-02\n",
      "     1.34528113e-01]\n",
      "   [-4.79853577e-02  1.78649601e-01 -3.52259168e-01  2.60051492e-01\n",
      "    -2.15500310e-02]\n",
      "   [-1.58078576e-01  5.77081969e-01 -3.04818445e-02 -5.21081296e-02\n",
      "     2.08696785e-01]\n",
      "   [ 3.30187435e-02 -5.24266346e-02  4.10441340e-01 -5.51997514e-02\n",
      "    -1.64738688e-01]\n",
      "   [ 8.10309880e-02 -7.83374918e-02  2.76199515e-01  1.62956939e-01\n",
      "     1.43843306e-02]]\n",
      "\n",
      "  [[-1.10329806e-01 -3.71051442e-01  1.57197935e-01 -1.29362469e-01\n",
      "     2.31393492e-01]\n",
      "   [ 1.33958286e-01  2.76296355e-01 -1.13162687e-01  1.15860852e-01\n",
      "    -3.58571955e-01]\n",
      "   [ 2.34098599e-01 -8.69764351e-03  1.34716448e-01 -1.12064074e-01\n",
      "    -7.52851473e-02]\n",
      "   [ 3.47272192e-01  4.76093095e-02 -9.77585118e-02  5.42057801e-02\n",
      "    -2.57187703e-01]\n",
      "   [-1.75582016e-02  6.21767076e-02 -1.71264785e-01 -1.46792883e-01\n",
      "     1.14720619e-01]]]\n",
      "\n",
      "\n",
      " [[[ 2.89292042e-01  5.38696303e-02 -1.89225575e-01 -1.08677448e-01\n",
      "     2.18609422e-01]\n",
      "   [-2.82658230e-02  1.31114666e-01 -3.40932089e-02 -1.32950569e-01\n",
      "     3.06237364e-01]\n",
      "   [ 2.21775079e-02 -1.00326736e-01 -1.67197367e-01 -2.43590892e-02\n",
      "     2.40265238e-01]\n",
      "   [ 4.12437037e-01  1.35696359e-01  1.89170154e-01 -4.09435149e-02\n",
      "    -2.48741364e-01]\n",
      "   [ 1.32549866e-02  3.75056482e-02 -1.75221570e-01 -9.64605529e-02\n",
      "    -7.81855611e-02]]\n",
      "\n",
      "  [[ 2.30735500e-01  1.63622675e-01  1.61805151e-03 -1.50978491e-01\n",
      "     2.38540396e-01]\n",
      "   [-3.58309215e-01 -1.30152805e-01  4.20393112e-02  9.00132985e-02\n",
      "     7.41780361e-02]\n",
      "   [-3.97976381e-01  2.98527919e-01  1.35983175e-01  3.38590332e-01\n",
      "     5.58523587e-02]\n",
      "   [-3.01651723e-01  3.80119965e-02 -2.49494731e-02  9.32303475e-02\n",
      "    -1.91080767e-01]\n",
      "   [ 9.42013701e-02 -5.21444156e-01  2.31250523e-01  3.28077219e-02\n",
      "     4.23178372e-01]]\n",
      "\n",
      "  [[ 1.20296415e-01  1.64725297e-01  4.16732984e-02  4.64573284e-02\n",
      "     4.26558707e-01]\n",
      "   [-3.49535152e-01 -3.02502229e-01  2.87258797e-02  4.64729873e-02\n",
      "    -4.61957056e-01]\n",
      "   [ 9.67576848e-04 -1.13807213e-01 -9.20016099e-02 -1.68944259e-02\n",
      "     1.78287037e-01]\n",
      "   [ 2.80430275e-01 -3.42505381e-02 -4.54413589e-01  3.26579671e-01\n",
      "    -2.62265492e-01]\n",
      "   [-5.61763457e-02  6.12267646e-02 -5.02062929e-01 -3.86707520e-01\n",
      "     8.58968223e-02]]]],\n",
      "bn_f6: [[0.18503966 0.09932937 0.02945637 0.11583542 0.00383821 0.14041909]\n",
      " [0.07646098 0.05939605 0.00949592 0.07577927 0.11292561 0.14017526]],\n",
      "conv_f7: [[[[-9.47488150e-02  1.16859663e-01  1.02841102e-01 -7.49229030e-02]\n",
      "   [ 1.66247193e-01 -3.67270651e-01  3.21851040e-01  9.11954116e-02]\n",
      "   [-4.71966155e-02 -2.46593905e-01  1.80788542e-01  6.29846200e-02]\n",
      "   [ 2.48771478e-01  3.06969794e-01 -1.22870626e-01  1.69382953e-02]]\n",
      "\n",
      "  [[ 9.50081133e-02  2.53896053e-01 -2.46496200e-02  2.01277649e-01]\n",
      "   [ 1.12752044e-02  3.54555043e-01 -5.42520508e-02  1.26685992e-01]\n",
      "   [ 1.25415470e-01  2.05084007e-01 -6.07467876e-02 -2.58839979e-01]\n",
      "   [ 3.29118649e-01 -1.76660429e-01 -1.35456170e-01  2.36613340e-01]]\n",
      "\n",
      "  [[ 6.89742068e-02  5.36325229e-02 -3.04587649e-01  3.27596752e-01]\n",
      "   [-1.63844325e-01  2.43816018e-01 -1.44374124e-01 -3.95435119e-01]\n",
      "   [ 4.71131267e-02 -9.13628683e-02  8.36077243e-03 -5.29979482e-01]\n",
      "   [-5.01960328e-02 -4.58853663e-01  1.11981994e-01  5.03274128e-02]]\n",
      "\n",
      "  [[-3.51444685e-02 -9.51703870e-02 -1.13514915e-01 -3.18960577e-01]\n",
      "   [ 1.03415815e-01  8.24534815e-02  1.44322525e-01 -3.56483449e-01]\n",
      "   [ 5.09397960e-02  2.88710500e-01  8.52936336e-02 -2.22975264e-01]\n",
      "   [ 1.08141407e-01  3.85060011e-01 -2.67159842e-01  3.48056160e-01]]\n",
      "\n",
      "  [[ 7.26016213e-02 -1.35974545e-01 -2.67185342e-01 -1.50589723e-02]\n",
      "   [ 1.23911764e-01  1.67291439e-01  2.83083435e-01 -2.04365592e-04]\n",
      "   [ 1.91456444e-01  1.72992351e-01  1.00885461e-01  4.02322587e-02]\n",
      "   [-2.64224429e-02  1.27247104e-01  7.20140405e-02 -1.50858372e-01]]\n",
      "\n",
      "  [[ 7.70204531e-03 -8.54441342e-02 -8.12465449e-02  8.45977459e-02]\n",
      "   [ 7.27524456e-02 -9.67096486e-02  4.36722920e-03 -1.96197645e-01]\n",
      "   [ 1.25007890e-01  4.06310471e-02 -3.03416991e-01  3.23624937e-01]\n",
      "   [-1.16215546e-01  5.07802858e-02  3.44768411e-02  2.35206962e-01]]]\n",
      "\n",
      "\n",
      " [[[ 1.57432620e-01  1.18716888e-01 -4.02177739e-02 -1.19958763e-01]\n",
      "   [-1.18208178e-01 -1.31738520e-01  9.59268068e-02  7.91315647e-02]\n",
      "   [ 9.82824829e-02 -2.03586221e-01 -2.19708054e-01  2.03447341e-01]\n",
      "   [ 1.00172344e-01  1.26017502e-01 -3.35108546e-01  1.67297709e-01]]\n",
      "\n",
      "  [[-1.80359539e-01 -3.58458143e-01 -9.83351451e-02 -3.03969347e-02]\n",
      "   [ 2.58314876e-01 -3.65241886e-01 -3.37003338e-03  1.68481377e-01]\n",
      "   [-7.95088278e-02 -9.04117647e-03  2.86437306e-01 -9.42731079e-02]\n",
      "   [ 4.16907012e-01 -9.62060894e-02  1.92778350e-01 -5.46010696e-02]]\n",
      "\n",
      "  [[-9.69399085e-02  1.05357233e-01 -1.94286494e-01 -1.83119943e-01]\n",
      "   [ 3.53755820e-01 -5.83905991e-02  3.23642296e-01  2.69819276e-01]\n",
      "   [-1.63903740e-02 -4.49664292e-02  2.07285673e-01  1.08641186e-01]\n",
      "   [ 6.40904054e-02  4.31530368e-02  9.37896568e-02  1.10044088e-01]]\n",
      "\n",
      "  [[ 6.43212592e-02  7.00467052e-02  1.37310955e-02  1.52827958e-01]\n",
      "   [-1.71977731e-01  2.06907999e-01 -3.20006135e-01 -5.95811624e-02]\n",
      "   [-5.66824716e-02  1.08969059e-01  8.65734701e-02  1.49725834e-01]\n",
      "   [ 2.53912992e-02  1.80725865e-01 -3.33108508e-01  2.18820975e-01]]\n",
      "\n",
      "  [[-1.61574850e-01 -2.17779237e-01  3.85601341e-02  8.19901181e-02]\n",
      "   [ 3.64953256e-02 -2.19216802e-01  1.06736233e-01  1.85946807e-02]\n",
      "   [ 2.24373821e-01  4.79631981e-01  1.84277606e-01  2.66215006e-02]\n",
      "   [ 2.76005158e-01 -1.07428875e-01 -7.35587609e-02 -2.55476758e-01]]\n",
      "\n",
      "  [[ 7.03669015e-02 -1.54685727e-02 -2.39404574e-02 -5.19648440e-01]\n",
      "   [ 4.23090572e-02 -1.86236192e-01  2.92728162e-01 -1.78367670e-01]\n",
      "   [-5.96894393e-02 -2.58806473e-01  6.69208731e-02 -2.24145040e-01]\n",
      "   [ 1.21637407e-01 -1.55458391e-01  2.10800514e-01 -5.36714853e-01]]]\n",
      "\n",
      "\n",
      " [[[-2.75696613e-02 -4.58326943e-02  2.09693359e-02  1.24523294e-01]\n",
      "   [-2.61227412e-01  2.60597021e-01 -2.10122224e-01  1.82418947e-01]\n",
      "   [-2.23581447e-01 -1.71718704e-01 -1.26004447e-01  3.37431067e-01]\n",
      "   [-6.96263398e-02  2.01276819e-01  8.36632386e-02 -2.58083930e-01]]\n",
      "\n",
      "  [[-9.58388585e-02  1.00381132e-01  1.06336889e-02 -1.78516460e-02]\n",
      "   [-2.49392244e-01  1.22872450e-01 -2.47109217e-01  2.57678136e-01]\n",
      "   [-2.65194361e-01 -1.47191282e-01 -3.12638915e-02 -6.42823265e-03]\n",
      "   [-3.11840238e-01  1.63751990e-01  4.72666369e-02 -2.87750770e-01]]\n",
      "\n",
      "  [[-1.28855379e-01 -1.78266350e-02 -4.53389876e-01  4.32375438e-01]\n",
      "   [ 1.20807968e-01 -3.23306251e-01 -1.45348278e-01  3.02030147e-01]\n",
      "   [-2.94588889e-01  9.37877165e-02 -2.09466363e-01 -3.56437855e-01]\n",
      "   [-4.44145489e-02 -1.27456784e-01  1.00820938e-01  2.73314462e-02]]\n",
      "\n",
      "  [[-1.48395729e-01  3.63096825e-01 -1.31075216e-01 -4.55700537e-02]\n",
      "   [-3.10805870e-01 -2.77583056e-01 -3.65282890e-01  6.87885429e-02]\n",
      "   [-8.84308264e-02 -1.34171992e-01 -1.92782874e-01  3.97237036e-02]\n",
      "   [ 1.44505307e-01  2.83656509e-02 -1.43894512e-01 -1.94876199e-01]]\n",
      "\n",
      "  [[ 3.35945501e-01  1.63805168e-01  4.12481873e-02 -2.29698890e-01]\n",
      "   [ 8.36245965e-02 -1.53947385e-01 -2.41332163e-01 -1.77459771e-01]\n",
      "   [ 3.11760931e-01 -1.19168313e-01 -2.62855105e-01 -1.86936976e-01]\n",
      "   [ 2.67767106e-01  5.47878597e-02 -1.03684206e-01  7.41181517e-03]]\n",
      "\n",
      "  [[-1.05612376e-01 -1.55619699e-01 -2.17609842e-01 -1.66267322e-01]\n",
      "   [-3.01539974e-01 -3.88457876e-01  2.31596649e-02 -2.18079791e-01]\n",
      "   [ 1.15535046e-01 -3.13022442e-02 -9.56357776e-02  1.03663693e-01]\n",
      "   [ 2.36943066e-01  4.00935323e-01  3.38925626e-01 -4.00811677e-02]]]\n",
      "\n",
      "\n",
      " [[[ 4.43039685e-01 -1.42462287e-01  1.45436310e-01  1.93277363e-01]\n",
      "   [ 1.27012549e-02  1.69064503e-01  1.23283569e-01  4.36195860e-02]\n",
      "   [-5.50401778e-02  8.79395058e-02 -9.29053537e-02 -1.73426138e-01]\n",
      "   [-7.73145196e-02  1.96335386e-01  2.82740139e-01 -1.43796175e-01]]\n",
      "\n",
      "  [[-3.75710785e-01 -2.69925763e-01  4.38925456e-01 -6.72716796e-02]\n",
      "   [-1.42759973e-02  4.19800553e-02  2.19670221e-01 -2.68712499e-01]\n",
      "   [ 1.80603927e-01 -7.46511045e-02 -7.88345302e-02  4.24651258e-01]\n",
      "   [ 8.96918779e-02  4.59553920e-03 -1.49247616e-02  8.04990003e-02]]\n",
      "\n",
      "  [[-1.82700134e-01 -4.71547699e-02 -5.90301327e-01 -8.32192994e-02]\n",
      "   [ 8.51444877e-02  1.19788436e-01  1.94842557e-01  6.82053796e-03]\n",
      "   [-1.41249241e-01  2.82253381e-01 -6.06170924e-02  1.20840625e-01]\n",
      "   [-1.14405501e-01 -2.40535484e-01  1.14521246e-01  8.85241308e-02]]\n",
      "\n",
      "  [[-1.89925771e-01 -2.42162947e-01 -2.88532954e-01  1.22108753e-01]\n",
      "   [ 3.15646938e-01  3.63324772e-01  4.22258163e-02  2.19609269e-01]\n",
      "   [ 7.13545862e-02  2.27926726e-01 -2.00946194e-01 -1.22162149e-01]\n",
      "   [-6.34552481e-02  2.76543144e-02 -3.15273654e-01 -8.98635179e-02]]\n",
      "\n",
      "  [[ 2.09825615e-01  3.17215345e-02  1.62010530e-01 -9.34562265e-02]\n",
      "   [-2.91254007e-01 -5.76236339e-02  2.27114425e-01  1.65409959e-01]\n",
      "   [-4.65716577e-01 -4.23352463e-02  3.72387153e-02 -2.55214265e-01]\n",
      "   [-2.24335971e-01  3.76395244e-01 -1.70926099e-01  1.53699157e-01]]\n",
      "\n",
      "  [[-2.46756621e-01  1.32451689e-01  1.80398294e-01 -2.49294106e-01]\n",
      "   [-1.98736004e-01 -3.76657093e-02  3.36778655e-01  1.17494352e-01]\n",
      "   [-1.06118069e-01  9.25375675e-02  6.24679919e-02 -1.14150120e-02]\n",
      "   [ 2.78473160e-01 -1.09737372e-01 -1.35772898e-01  5.11781403e-02]]]\n",
      "\n",
      "\n",
      " [[[ 2.27094757e-01 -2.01245669e-01  7.91719411e-03  8.06865795e-02]\n",
      "   [ 2.39992936e-01 -2.03457190e-01 -7.22524027e-02 -2.39204402e-01]\n",
      "   [ 8.37521011e-02 -1.58111797e-01  1.13413994e-01  2.12159378e-01]\n",
      "   [-4.92964647e-04  3.39762087e-01 -3.24803870e-01 -3.19863277e-01]]\n",
      "\n",
      "  [[-2.38758105e-01 -9.45352821e-02  1.47771555e-01 -7.63424744e-02]\n",
      "   [ 1.88816240e-01  2.06093331e-01  2.87341062e-01  2.37677176e-01]\n",
      "   [-2.98390366e-01  1.83622560e-01 -1.50332473e-01 -1.44178774e-01]\n",
      "   [-4.29192985e-01 -5.39708475e-02 -3.85091579e-02 -3.21508592e-01]]\n",
      "\n",
      "  [[ 1.57597414e-01  9.13537164e-02 -2.27742392e-01 -2.41556646e-01]\n",
      "   [-1.03037956e-01 -3.80212682e-01  7.39020560e-02  1.70425968e-01]\n",
      "   [ 1.37309647e-01  3.19001734e-01  1.05623790e-01 -6.37169689e-01]\n",
      "   [ 8.45956622e-02  5.97969741e-02 -1.75803406e-01 -2.22628788e-01]]\n",
      "\n",
      "  [[-1.96169024e-03 -2.69857223e-01  1.64138424e-01 -2.53370174e-01]\n",
      "   [-4.84515713e-01 -9.80007251e-03  1.35681701e-02  2.58080669e-01]\n",
      "   [ 2.30765853e-01  2.24637185e-01  3.25509684e-01  2.00121053e-01]\n",
      "   [-7.51138942e-02  6.76710070e-02 -3.88406285e-01  1.59286725e-02]]\n",
      "\n",
      "  [[ 1.95248617e-01  1.23933575e-01 -2.11616613e-01  2.76364692e-01]\n",
      "   [ 1.25244964e-01  1.81337070e-01  1.35954815e-01  2.76775600e-01]\n",
      "   [ 5.58714508e-02 -3.11555595e-01  4.56561769e-01 -8.76622374e-02]\n",
      "   [ 2.56752981e-01  3.57816144e-02  3.75120546e-02  4.46930284e-01]]\n",
      "\n",
      "  [[-5.59408308e-02  1.12677718e-01  1.03744869e-02  1.01067820e-01]\n",
      "   [-7.47782281e-02  1.60831168e-01  7.70240518e-02  2.29747376e-01]\n",
      "   [-1.89802855e-01 -9.60400014e-02  1.41823200e-01 -1.46201522e-03]\n",
      "   [ 2.44834012e-02  1.45602795e-01 -5.39597797e-02 -9.18215788e-02]]]\n",
      "\n",
      "\n",
      " [[[-3.55274902e-02 -5.59916523e-02  2.47183023e-03  1.70276038e-02]\n",
      "   [-3.68253675e-01 -2.98835819e-01 -2.01053572e-01 -9.21340732e-02]\n",
      "   [ 1.85774789e-01  1.32421640e-02  1.50609447e-01  9.79132233e-02]\n",
      "   [ 2.05177869e-01  3.37658390e-01  3.04439247e-01  5.22922640e-05]]\n",
      "\n",
      "  [[ 3.08232184e-01 -1.58949939e-01 -4.67414847e-01  8.44712583e-02]\n",
      "   [ 3.29463480e-01  1.29138997e-01 -4.80208657e-01  4.08865813e-01]\n",
      "   [-7.98715440e-03  1.29419996e-01 -5.17810368e-01  4.02821254e-02]\n",
      "   [-1.41669707e-01  2.49721334e-01 -1.72463223e-01  1.69898433e-01]]\n",
      "\n",
      "  [[-1.49866780e-01  4.58823106e-01 -7.22398943e-02  4.84794632e-01]\n",
      "   [-2.95952858e-01 -6.22466423e-02  8.06171551e-02 -1.74200928e-01]\n",
      "   [ 2.22722660e-01  5.30934722e-01  3.29590632e-01  1.60515503e-02]\n",
      "   [ 2.50617171e-01 -8.31138865e-02  4.41501436e-02  2.74420581e-01]]\n",
      "\n",
      "  [[-2.03790664e-01  2.56508015e-01  3.35830331e-01 -1.45922021e-01]\n",
      "   [ 1.03907632e-01 -1.07558000e-01  5.24971011e-02 -1.73839796e-01]\n",
      "   [-3.36632554e-01  1.97264789e-01  2.84158672e-01  2.04545531e-01]\n",
      "   [-1.02215963e-01  1.09825864e-01 -2.44008386e-02  2.84432345e-01]]\n",
      "\n",
      "  [[ 4.40821702e-01  1.76068453e-01  1.51781375e-01  4.94246837e-02]\n",
      "   [ 2.19098010e-01  1.38073110e-01  2.97821250e-01 -1.01398476e-01]\n",
      "   [-2.09386688e-01 -3.18122161e-01 -1.26831365e-01  3.20412339e-01]\n",
      "   [ 2.21269440e-01  1.24138902e-01 -1.62903774e-01 -2.33716562e-01]]\n",
      "\n",
      "  [[ 3.64264150e-02  9.65353033e-02 -1.86365729e-01 -1.85730101e-01]\n",
      "   [-4.94519474e-02 -5.43687348e-01 -2.60879078e-02  1.12978002e-01]\n",
      "   [ 8.99689523e-02 -3.33361664e-01 -2.62156212e-01 -1.03154987e-01]\n",
      "   [ 3.48156206e-01 -1.78378839e-01  1.94182412e-01  1.38100468e-01]]]\n",
      "\n",
      "\n",
      " [[[ 7.92736071e-02  1.08363216e-01  9.39894479e-02  1.70083514e-01]\n",
      "   [ 9.31007356e-02 -1.49096261e-01  1.15140972e-01 -5.90836697e-02]\n",
      "   [-9.87225445e-02 -4.53262104e-02  3.35259772e-01  1.64819846e-02]\n",
      "   [ 2.45591496e-01  1.98550771e-01  8.28712229e-02 -8.72276356e-02]]\n",
      "\n",
      "  [[-1.84456348e-01  1.44747171e-01  1.70222428e-01 -2.78149447e-01]\n",
      "   [-1.58421070e-01  4.16885431e-01  1.08901188e-01 -9.86142907e-02]\n",
      "   [-8.35878096e-02 -1.02087255e-01 -2.15757526e-01 -1.51999998e-01]\n",
      "   [-2.16861637e-01 -2.04613528e-01  1.87956728e-02 -1.00894162e-01]]\n",
      "\n",
      "  [[-2.83409305e-01 -3.11008228e-02 -1.41368794e-01 -6.08119332e-02]\n",
      "   [ 3.61761448e-01 -1.41858089e-01  3.60584738e-01  1.69026854e-01]\n",
      "   [-3.27254097e-02  1.53275184e-03 -1.24563781e-01  1.74366937e-01]\n",
      "   [ 2.55821328e-02  2.90707910e-01 -2.74718497e-01  1.39803430e-03]]\n",
      "\n",
      "  [[-1.10409658e-02  1.95320669e-01  3.02806664e-01 -1.37141893e-01]\n",
      "   [-5.75307892e-02 -3.92856249e-01  1.45459700e-01 -2.31652086e-01]\n",
      "   [-1.82439143e-01  3.77678088e-01 -3.64157344e-01 -1.65090843e-01]\n",
      "   [ 1.73301085e-02 -1.73683863e-01  1.33430500e-01 -1.12753493e-01]]\n",
      "\n",
      "  [[-1.82195418e-01  5.29850747e-01  4.29913395e-01 -1.58179527e-01]\n",
      "   [-2.15210232e-01 -2.33176581e-01 -3.94307873e-01  1.91637976e-01]\n",
      "   [ 9.11829432e-03  3.36849535e-01 -3.18517912e-02  5.39854768e-02]\n",
      "   [-6.34104683e-02  4.10590105e-01  4.61923444e-01  3.37471920e-01]]\n",
      "\n",
      "  [[ 1.92444212e-02 -1.13939817e-01  1.40655781e-01 -3.07221956e-01]\n",
      "   [-5.56817371e-02  2.34551794e-01  1.25872954e-01  1.42855405e-01]\n",
      "   [-9.05496949e-02  1.68433998e-01 -1.46831388e-01  1.42185181e-01]\n",
      "   [-1.68129497e-01 -1.79387511e-01  3.76840803e-02 -1.31519320e-02]]]\n",
      "\n",
      "\n",
      " [[[-2.21823472e-02  2.33312694e-02  4.55664571e-02 -1.17498460e-01]\n",
      "   [ 8.02447881e-03 -3.12186503e-01  2.21101437e-01  6.15899252e-02]\n",
      "   [ 2.29424917e-02 -2.90182532e-01 -6.74444116e-02 -2.33335549e-01]\n",
      "   [ 8.22081644e-02 -7.26111269e-02  8.60396196e-02  3.89198016e-02]]\n",
      "\n",
      "  [[-2.67733018e-01 -1.35875139e-01 -2.39864309e-01 -3.65954537e-01]\n",
      "   [-3.01344245e-01 -7.84624839e-02 -1.21840207e-01 -6.98742261e-02]\n",
      "   [ 6.57892558e-02  2.02076127e-01  4.70801927e-02  7.53183682e-02]\n",
      "   [-3.46575318e-01  1.33783086e-02 -3.18037000e-01 -3.22638183e-01]]\n",
      "\n",
      "  [[ 1.91292132e-01 -1.78474056e-01 -3.36528627e-01 -3.36238683e-01]\n",
      "   [ 2.19620983e-02 -3.81206828e-01  1.84401936e-01  3.72340358e-01]\n",
      "   [-1.92089461e-01  1.75225402e-01  1.01553937e-02  4.47703839e-01]\n",
      "   [-1.98259495e-01 -1.62177627e-02 -2.09363651e-02  6.97742252e-02]]\n",
      "\n",
      "  [[ 8.02144971e-02  1.14970437e-01 -3.82123274e-01 -2.18019849e-01]\n",
      "   [ 1.39174115e-01  2.46861784e-01  1.33954600e-02  1.29989397e-01]\n",
      "   [-1.49696417e-01 -2.13236475e-02  1.72089035e-01  3.20472359e-01]\n",
      "   [-2.49641299e-01  1.19507249e-01 -1.64188716e-01 -9.76928288e-02]]\n",
      "\n",
      "  [[ 1.91484662e-02 -2.11114496e-01 -1.22856029e-01 -2.29816101e-01]\n",
      "   [-1.40689391e-01  2.18374847e-01  4.11982929e-02  2.44792980e-01]\n",
      "   [-1.44027237e-01 -2.35341826e-01 -3.12280502e-01  2.41893755e-01]\n",
      "   [-1.82949508e-01 -3.38130080e-02 -1.37252919e-01 -2.94480850e-03]]\n",
      "\n",
      "  [[-1.72384639e-01  1.69740656e-01 -2.72872052e-01  2.01873041e-01]\n",
      "   [-1.09825800e-02  1.81407938e-01  2.73016290e-01 -1.62561604e-01]\n",
      "   [-1.60476236e-01  2.75430110e-01  4.57470960e-01  1.33713125e-01]\n",
      "   [-7.84243974e-02 -4.48316802e-02 -5.48051405e-02 -1.66401641e-01]]]\n",
      "\n",
      "\n",
      " [[[-3.89485905e-01 -1.04828050e-01 -2.22343141e-01  3.59502846e-01]\n",
      "   [-1.80519794e-01 -1.97907695e-01 -2.52755259e-01  7.81002166e-02]\n",
      "   [-4.27066895e-01  4.85712121e-02 -3.42292068e-01  1.65811268e-01]\n",
      "   [-3.73020414e-01  2.05553597e-01 -1.63064923e-01 -4.55535290e-01]]\n",
      "\n",
      "  [[-5.52435496e-03 -1.02404771e-01  2.78006016e-02  7.92543791e-02]\n",
      "   [-1.15411868e-02 -7.03046475e-02  4.26625487e-01 -3.20393686e-01]\n",
      "   [ 4.93969348e-02  8.39512227e-03  3.90954717e-02  2.48748980e-01]\n",
      "   [ 1.13847940e-01 -1.03817494e-01  1.72828121e-01  7.90646463e-02]]\n",
      "\n",
      "  [[ 2.85681935e-01 -1.58945253e-01  2.20732367e-01  1.85707884e-01]\n",
      "   [ 7.22727421e-02 -4.46206484e-02  1.91507487e-01  2.58317350e-01]\n",
      "   [ 6.58008876e-02  4.90360950e-01 -1.06770031e-01  8.03878958e-02]\n",
      "   [-1.26766446e-01  3.12077003e-01  1.80158446e-01 -3.68999063e-02]]\n",
      "\n",
      "  [[-3.08454433e-01 -3.93844624e-01 -3.25254886e-01 -3.05898703e-01]\n",
      "   [-2.24201482e-01  1.45532331e-02 -4.04844455e-01  2.84534323e-01]\n",
      "   [ 9.48134260e-02 -3.82446268e-01  1.44935088e-01  1.35979069e-02]\n",
      "   [ 1.47832114e-01  1.14477073e-01  2.47132840e-01  2.26699114e-01]]\n",
      "\n",
      "  [[-1.71672998e-01  2.77731708e-01 -4.82787533e-03  3.41163341e-01]\n",
      "   [-2.41606804e-02 -2.29251007e-01 -1.22590842e-01 -1.87560860e-01]\n",
      "   [-8.64742318e-03  7.15414720e-02  7.63021567e-02  4.61015315e-02]\n",
      "   [-2.05242140e-01  5.08609881e-02 -2.25497010e-02 -8.65638045e-02]]\n",
      "\n",
      "  [[-3.80585632e-01 -9.66694029e-02 -1.16994470e-01 -6.79527320e-02]\n",
      "   [ 6.64584614e-02  1.45534078e-01  1.79730878e-01  4.10541888e-03]\n",
      "   [-9.18475209e-03 -2.75363766e-01  8.28471487e-02  2.97681935e-01]\n",
      "   [ 2.12738140e-01  1.94135485e-02  4.60422162e-02 -1.49874188e-01]]]\n",
      "\n",
      "\n",
      " [[[-6.96508945e-02  7.38735839e-02 -3.67239923e-01  1.50869044e-01]\n",
      "   [-3.54517515e-01 -2.92398499e-01  1.22583075e-02 -3.11647525e-01]\n",
      "   [-1.73666250e-01 -3.24662596e-02 -1.82520330e-01 -3.92272473e-01]\n",
      "   [ 3.67081762e-02  3.89982822e-01  2.68599981e-01 -2.34358145e-01]]\n",
      "\n",
      "  [[ 1.35809432e-01  2.50809536e-01  1.61873547e-02  1.57179966e-01]\n",
      "   [ 4.54279112e-01  2.11105146e-01 -4.62414681e-02 -7.43156923e-02]\n",
      "   [-3.82650753e-01 -2.19285881e-02 -8.31490900e-02  1.40891989e-01]\n",
      "   [-6.07860807e-02  5.64006549e-01 -1.17898748e-01 -1.27478113e-01]]\n",
      "\n",
      "  [[ 1.26635181e-01  1.63646578e-02  1.61275052e-01 -2.35595874e-01]\n",
      "   [-1.45659128e-01  1.72966356e-01 -5.31889191e-03 -2.26878289e-01]\n",
      "   [-1.98552694e-01  3.11438767e-02  2.33582284e-01  1.85806916e-01]\n",
      "   [ 2.59325725e-01 -2.55279418e-01  3.48557091e-01 -1.62233364e-01]]\n",
      "\n",
      "  [[-2.92284541e-01  2.54587455e-02 -3.41923291e-01  4.28147166e-02]\n",
      "   [-1.60784485e-01  5.24248210e-01  3.58915834e-03  1.09753185e-01]\n",
      "   [-2.69341099e-02  1.39450668e-01 -9.36204677e-02  5.52866356e-02]\n",
      "   [-1.03789674e-01 -3.48634808e-02  2.58989367e-01 -2.81323707e-01]]\n",
      "\n",
      "  [[-5.04529204e-02  1.51414411e-01  9.35278060e-02  5.79053137e-03]\n",
      "   [ 2.42210038e-01  1.53503112e-01  2.38405905e-03 -1.15977189e-01]\n",
      "   [-2.26891930e-01  3.13999919e-02 -2.88276216e-01 -2.63188014e-01]\n",
      "   [-2.20454362e-01 -3.78735745e-01 -3.65553152e-01 -3.51068107e-01]]\n",
      "\n",
      "  [[ 3.12898956e-02 -3.55619486e-01 -3.20344176e-02  5.85771036e-02]\n",
      "   [ 3.44775423e-01 -1.25659830e-01 -5.48740730e-02  1.28415165e-01]\n",
      "   [-5.36350499e-02 -3.83141051e-01  3.34546023e-01  3.87517385e-02]\n",
      "   [-2.21511584e-02 -2.32408000e-01 -6.76335797e-03  4.10951465e-02]]]],\n",
      "bn_f7: [[0.18813693 0.08095998 0.15710968 0.04669312 0.16394598 0.06645738\n",
      "  0.07106711 0.15342007 0.14532866 0.17611837]\n",
      " [0.00857631 0.07525515 0.14298217 0.08936485 0.08665189 0.17632533\n",
      "  0.08967425 0.08036705 0.14370998 0.02206369]],\n",
      "conv_f8: [[[[-0.10578265  0.17174231 -0.3560184  -0.19676122  0.1427065 ]\n",
      "   [-0.16503705  0.06955356 -0.06032944 -0.19673599  0.07302195]\n",
      "   [ 0.0104633   0.05984357  0.10944933  0.02940906  0.04538936]\n",
      "   [ 0.0391586  -0.03435842  0.17764235  0.25442237  0.14367493]\n",
      "   [ 0.15449666 -0.2314152  -0.03149093 -0.38548682 -0.06159787]]\n",
      "\n",
      "  [[ 0.29561461  0.1393242   0.16391686  0.07960539  0.07653825]\n",
      "   [-0.11421996  0.3078688   0.01189207  0.01173086  0.2489846 ]\n",
      "   [ 0.06964343  0.14874268  0.06403237 -0.0135733  -0.08414456]\n",
      "   [ 0.15227506  0.16361785 -0.22767338 -0.05694807  0.0345371 ]\n",
      "   [ 0.18311838  0.11461274  0.0778758   0.44163165  0.16554618]]\n",
      "\n",
      "  [[ 0.20620798 -0.00491298  0.25413846 -0.17592333 -0.08365159]\n",
      "   [ 0.11434293  0.49701085 -0.09276131 -0.35432803  0.26454383]\n",
      "   [ 0.11280089 -0.44335252  0.21386019 -0.14956097  0.12337757]\n",
      "   [ 0.30957137  0.11627476  0.24913366  0.01575001 -0.06666779]\n",
      "   [ 0.34804771  0.06837537 -0.24290312 -0.24799074 -0.43768104]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.26427939 -0.167531   -0.13360673 -0.07549415  0.01300648]\n",
      "   [ 0.25734223  0.02625179 -0.21645396 -0.13697732 -0.02359687]\n",
      "   [ 0.06309531  0.06921446 -0.28750101  0.0275274   0.03693452]\n",
      "   [-0.02061597 -0.18192707  0.08440954 -0.17939735 -0.36449386]\n",
      "   [ 0.03820072 -0.12195738 -0.05142011  0.13763064  0.07230716]]\n",
      "\n",
      "  [[ 0.31334867 -0.1339678   0.37632459 -0.31155637 -0.28465882]\n",
      "   [ 0.25260121 -0.0718811   0.11525404  0.01542855 -0.11890133]\n",
      "   [-0.02468123 -0.22796624 -0.29312135  0.09729499  0.38894883]\n",
      "   [-0.26502816  0.02420803  0.1461212  -0.14813764 -0.45075143]\n",
      "   [ 0.42532881 -0.09887208  0.07671977 -0.10370199  0.02170634]]\n",
      "\n",
      "  [[ 0.13230159 -0.13381879  0.32735511  0.05885429 -0.23140028]\n",
      "   [-0.06868987 -0.08909475 -0.06399554  0.26963434  0.15271266]\n",
      "   [-0.00333323 -0.01985112 -0.13082262  0.35160194  0.05436498]\n",
      "   [-0.08999638 -0.2991427  -0.17314124  0.19079753  0.88898694]\n",
      "   [-0.32206639  0.25910835  0.06595417 -0.04853964  0.04221778]]]\n",
      "\n",
      "\n",
      " [[[ 0.10117725 -0.06047707 -0.17410435 -0.08582782 -0.14390129]\n",
      "   [-0.72158435 -0.094633    0.1299678   0.09902636  0.45729765]\n",
      "   [ 0.10246092 -0.13036752  0.02329782  0.25076454 -0.13404483]\n",
      "   [-0.29688881  0.27005392 -0.16005925  0.02649917 -0.25608873]\n",
      "   [ 0.14450693  0.09910867 -0.06541655 -0.18318042 -0.02597459]]\n",
      "\n",
      "  [[ 0.11005779  0.34067249 -0.2438194   0.15210049 -0.07239836]\n",
      "   [-0.04492942  0.26241464  0.18795914  0.11548762  0.06585442]\n",
      "   [-0.01197853  0.21188583 -0.16862585  0.24378161 -0.18027729]\n",
      "   [ 0.33623108  0.00285112 -0.17251882 -0.01364919 -0.45664894]\n",
      "   [ 0.09853104  0.01493103 -0.08429931  0.18101761 -0.02063466]]\n",
      "\n",
      "  [[-0.59260335 -0.03702446  0.70392704 -0.2949418   0.26983047]\n",
      "   [-0.13048601  0.18980885 -0.11663661 -0.12525451 -0.04483171]\n",
      "   [-0.0723078   0.00330066  0.00936116  0.02659699  0.2307924 ]\n",
      "   [-0.16858098 -0.0296827   0.05398811  0.05791093  0.0313829 ]\n",
      "   [-0.05398656  0.08950077  0.0430415   0.0191663  -0.39044129]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.19734923  0.22075265 -0.03208477 -0.05001978 -0.15222352]\n",
      "   [ 0.03794183  0.24257096  0.13655558 -0.03208128 -0.21319489]\n",
      "   [-0.05074198 -0.14547291 -0.3502189  -0.10246     0.23547469]\n",
      "   [-0.13907174  0.19765675  0.09370798  0.16588551 -0.05816202]\n",
      "   [-0.0812544   0.03646882 -0.08767603  0.01695582  0.48163809]]\n",
      "\n",
      "  [[-0.01771021 -0.02479639  0.08796911 -0.26387114 -0.01085805]\n",
      "   [ 0.10685073 -0.03890227 -0.01812204  0.11075929 -0.06513903]\n",
      "   [-0.02350163 -0.08166616  0.22177442  0.01105103  0.01034328]\n",
      "   [-0.02500778  0.09469531 -0.15938301 -0.2685525  -0.13285694]\n",
      "   [ 0.1871203  -0.07908948 -0.23791573  0.39928278 -0.09943677]]\n",
      "\n",
      "  [[-0.15310658 -0.3810666  -0.39522798 -0.08205597  0.18956023]\n",
      "   [-0.19988514 -0.0389519  -0.10964208 -0.35350959 -0.00584022]\n",
      "   [ 0.47805038  0.0729736   0.06467792  0.13342509  0.00512863]\n",
      "   [ 0.25992145  0.44170159 -0.03213264  0.28894628 -0.06002774]\n",
      "   [-0.21076342  0.18898222 -0.06922096  0.25266994  0.01149145]]]\n",
      "\n",
      "\n",
      " [[[ 0.00653552  0.28646559  0.04747074 -0.27987126  0.4214356 ]\n",
      "   [-0.12354522 -0.12828093 -0.15700165 -0.14980265 -0.01152208]\n",
      "   [-0.10811907 -0.14287638  0.07855119 -0.35415904  0.14246648]\n",
      "   [ 0.14493114 -0.19777562  0.00965616  0.01730512 -0.18863529]\n",
      "   [-0.01316805  0.03002924 -0.32775878 -0.21937277 -0.02102657]]\n",
      "\n",
      "  [[-0.10079939 -0.31652663  0.19261492  0.06425336  0.02241886]\n",
      "   [ 0.21511613  0.06974732  0.46728047  0.01167164 -0.21434539]\n",
      "   [ 0.35665356 -0.35572836  0.16742602 -0.31663629 -0.02999952]\n",
      "   [ 0.33793442 -0.02780484  0.16625987  0.33545055 -0.22601298]\n",
      "   [-0.00529244  0.23635579 -0.69991454  0.11331699 -0.24584037]]\n",
      "\n",
      "  [[ 0.20890463 -0.2976005  -0.04587412 -0.24522358 -0.23543314]\n",
      "   [-0.19373781  0.11604445  0.21004865  0.2735907   0.0258217 ]\n",
      "   [-0.07219393 -0.13352313 -0.05690433 -0.01878327  0.25524309]\n",
      "   [-0.09979984  0.1196074  -0.06262691 -0.15565702 -0.09779368]\n",
      "   [ 0.12249041  0.07364341  0.17724312  0.36142328 -0.27211834]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.18898911 -0.04216011 -0.38088951  0.05070611 -0.13948483]\n",
      "   [-0.15890146 -0.20189773  0.20165312 -0.22351094  0.03722505]\n",
      "   [ 0.27215808  0.03536848 -0.46114867 -0.08888386 -0.14338063]\n",
      "   [ 0.07117416 -0.65572297  0.32050626 -0.05446152  0.22221829]\n",
      "   [ 0.01212591 -0.15987773 -0.10076615  0.34066357 -0.06835003]]\n",
      "\n",
      "  [[ 0.16239031 -0.11069273 -0.31912983  0.08612282  0.13696512]\n",
      "   [ 0.11161925  0.1113053   0.07992918 -0.27948774 -0.03387184]\n",
      "   [-0.3017317  -0.00492926  0.02136022 -0.05886786  0.09005659]\n",
      "   [-0.09790311  0.04515835 -0.10638159 -0.0610115  -0.04694237]\n",
      "   [ 0.41862929  0.02760881 -0.21358302  0.12772886 -0.10003257]]\n",
      "\n",
      "  [[ 0.17148429  0.01757536  0.02687282  0.08402017  0.05578256]\n",
      "   [ 0.07290318  0.16104559 -0.12014002  0.21632678 -0.07657998]\n",
      "   [-0.49539301  0.15683717 -0.05156287 -0.16546754  0.00740071]\n",
      "   [-0.33302945  0.11356954 -0.20357741  0.13544506 -0.13813309]\n",
      "   [-0.10015215 -0.0773699   0.17042159  0.43145939  0.19776219]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.14148098 -0.17558006  0.16049331 -0.25331375 -0.23575841]\n",
      "   [ 0.23576352 -0.54054134 -0.02457533  0.14591424  0.23032722]\n",
      "   [-0.20985317 -0.23085518 -0.05406123  0.35433143  0.06387756]\n",
      "   [-0.56002548 -0.09611062  0.12942478  0.07421355 -0.12259702]\n",
      "   [ 0.08438504 -0.01133205 -0.24228935 -0.13569588  0.5004673 ]]\n",
      "\n",
      "  [[-0.07812647  0.09312319  0.07373949  0.1637887  -0.08581891]\n",
      "   [-0.14713822  0.08809461 -0.1025558  -0.02484989 -0.09983516]\n",
      "   [-0.06140793 -0.26489474 -0.44526537 -0.0292911   0.18892638]\n",
      "   [-0.25173297  0.08598489  0.01560244  0.12513673 -0.19792567]\n",
      "   [ 0.32802568  0.15372344  0.06780214  0.005689    0.22487982]]\n",
      "\n",
      "  [[ 0.08876785 -0.07659965 -0.38031169  0.14389654 -0.23354934]\n",
      "   [ 0.03423944  0.3892646  -0.04288453 -0.14592966 -0.30778144]\n",
      "   [ 0.07091072  0.06671489  0.15119197  0.19515898 -0.00483458]\n",
      "   [ 0.32435958  0.11888089 -0.02101593  0.09861299 -0.11624536]\n",
      "   [-0.02214011 -0.06555772  0.09590305  0.02903415  0.14790321]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.03836454  0.17411429  0.15030624  0.03724258  0.19783953]\n",
      "   [ 0.32822006  0.04518168 -0.06601956 -0.08884509 -0.14178565]\n",
      "   [-0.30921125 -0.05468658  0.17014255  0.40062286  0.41510804]\n",
      "   [-0.06638723 -0.12972231 -0.28826018  0.01589844 -0.03567757]\n",
      "   [ 0.29464058  0.25755396  0.13592227 -0.34452838 -0.16021506]]\n",
      "\n",
      "  [[ 0.11797269 -0.36153478 -0.05708433 -0.56898973 -0.19591851]\n",
      "   [-0.06071823 -0.32603401  0.00826504  0.03644589  0.18922991]\n",
      "   [ 0.41093679 -0.26842585  0.03252989 -0.18757334  0.16801706]\n",
      "   [ 0.40569818  0.01024589 -0.28575775  0.04583042 -0.08181315]\n",
      "   [-0.30717362  0.26690112 -0.03491089  0.29723509 -0.22296083]]\n",
      "\n",
      "  [[ 0.05725389  0.15578406  0.23807856  0.05647218  0.1024889 ]\n",
      "   [-0.09217302 -0.11103991  0.10389742  0.31421188  0.2902309 ]\n",
      "   [-0.05806054 -0.44118435  0.11727272  0.01112597 -0.11805489]\n",
      "   [-0.03566868  0.08067101 -0.16544316  0.18541108  0.15731308]\n",
      "   [-0.19953539  0.06551584 -0.22661896 -0.0011667  -0.4986313 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.30419795 -0.23712948 -0.04990865 -0.14080201  0.23999908]\n",
      "   [-0.45448845  0.16226101  0.35453736 -0.02922874  0.31599995]\n",
      "   [ 0.00422933 -0.34731385 -0.14235364 -0.2647815  -0.29055819]\n",
      "   [ 0.0545195  -0.1358315  -0.6737883   0.30681475 -0.08143192]\n",
      "   [-0.29129795 -0.14169064 -0.12538821 -0.11718274 -0.16015466]]\n",
      "\n",
      "  [[-0.2280558  -0.13943847 -0.14102094 -0.42132543 -0.0567257 ]\n",
      "   [ 0.28570503  0.15727153 -0.50186555 -0.43472943 -0.25280936]\n",
      "   [-0.09517827  0.16650073 -0.00759084 -0.12571165 -0.09257317]\n",
      "   [-0.09026922  0.43927233  0.15436984  0.01141075 -0.25510209]\n",
      "   [ 0.0089506   0.05842327 -0.26634563 -0.09083775  0.25869071]]\n",
      "\n",
      "  [[-0.05860167  0.73314815  0.23479782  0.22431817  0.01744681]\n",
      "   [-0.51149234 -0.33776103 -0.06690081 -0.1955317  -0.03697025]\n",
      "   [ 0.06765729 -0.06097492 -0.02953494 -0.19535691 -0.276747  ]\n",
      "   [ 0.54774335 -0.05890837 -0.08482246 -0.02541883 -0.08290273]\n",
      "   [-0.06104322  0.05797305  0.01884407  0.01528964 -0.35625391]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.12742772 -0.05399429 -0.26526438  0.18509157 -0.10889011]\n",
      "   [ 0.19693702 -0.26018523 -0.17936916 -0.02613882  0.13633486]\n",
      "   [ 0.2924179   0.0525324  -0.02455493  0.07286445 -0.04934557]\n",
      "   [-0.15005518  0.28609092  0.04584071  0.22928611 -0.00549289]\n",
      "   [ 0.08889405 -0.01521402  0.02156933 -0.1083885  -0.28619205]]\n",
      "\n",
      "  [[-0.2816241   0.32758371  0.29495041 -0.21654557 -0.32085683]\n",
      "   [-0.41672779 -0.10427672  0.04874971 -0.09310096 -0.03708229]\n",
      "   [ 0.43641976  0.31461733  0.04178695  0.04766886  0.00312955]\n",
      "   [-0.07156325 -0.1431505   0.03833777  0.40502059  0.22191719]\n",
      "   [ 0.02654724  0.32808787 -0.06710421  0.20582569 -0.15800391]]\n",
      "\n",
      "  [[ 0.49280256 -0.08971921  0.18100961  0.2878062   0.03360075]\n",
      "   [ 0.10734042 -0.03093597  0.22092191 -0.24880812  0.35732028]\n",
      "   [-0.2721221  -0.36945295 -0.21455704 -0.08692689  0.21408999]\n",
      "   [-0.11224626 -0.12805388 -0.20051854  0.11217822 -0.14395521]\n",
      "   [ 0.17659581  0.08743609  0.14641592 -0.24999722  0.07186849]]]\n",
      "\n",
      "\n",
      " [[[ 0.28159914 -0.06418342  0.05449106 -0.1835434   0.00546449]\n",
      "   [ 0.18503492  0.21722191  0.07385801  0.43646272  0.21016571]\n",
      "   [-0.1507459  -0.25392275 -0.00782479 -0.14988909 -0.10768252]\n",
      "   [ 0.31749122  0.30394942  0.01043677 -0.03155304  0.17743341]\n",
      "   [ 0.03948283  0.24099887  0.32524445 -0.05769936  0.25925906]]\n",
      "\n",
      "  [[-0.44015092  0.06742962 -0.27042203  0.52860511 -0.28589461]\n",
      "   [-0.22246443  0.27308975 -0.20064089  0.04788792 -0.06304407]\n",
      "   [-0.25932052  0.29265676 -0.17881843 -0.23049805  0.08574447]\n",
      "   [ 0.09485147 -0.01947313 -0.01803021  0.18007228 -0.10675886]\n",
      "   [-0.55743172 -0.00987629  0.05029946 -0.05453718 -0.00575735]]\n",
      "\n",
      "  [[-0.06719495 -0.18622773  0.11417844 -0.03834342 -0.18565353]\n",
      "   [ 0.05075958  0.31557072  0.11784107 -0.26398695 -0.11074628]\n",
      "   [ 0.0875042   0.04802723 -0.08608575  0.19441801 -0.0924846 ]\n",
      "   [-0.00697401 -0.14962078 -0.14007703  0.31143036 -0.06151523]\n",
      "   [ 0.42975201 -0.08362295  0.07134333 -0.01614474  0.13801915]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.01139992  0.24793112 -0.11566367  0.04856778 -0.35232351]\n",
      "   [-0.41479586  0.03027252  0.07269882 -0.16477199 -0.08098256]\n",
      "   [-0.01118693 -0.08977519  0.14081637  0.32525449 -0.32812801]\n",
      "   [-0.52287369  0.04002118  0.01500299 -0.0583691  -0.06039856]\n",
      "   [ 0.0254349   0.14031682 -0.01396295  0.06942835 -0.07841278]]\n",
      "\n",
      "  [[-0.14884952 -0.12565946 -0.58045455  0.0121546  -0.09741305]\n",
      "   [ 0.4496926   0.08727957 -0.10511535 -0.11726286  0.16588277]\n",
      "   [-0.03137382  0.14822265  0.21258294  0.55840646 -0.00325463]\n",
      "   [ 0.2901464  -0.05968558  0.26224987  0.18502102 -0.31866721]\n",
      "   [-0.44187176 -0.2641029   0.01959882  0.02766044 -0.21529516]]\n",
      "\n",
      "  [[-0.13819878 -0.20284298 -0.10908341  0.15055729 -0.00513645]\n",
      "   [-0.0278269  -0.08685476 -0.00643989  0.07722786  0.44511217]\n",
      "   [ 0.33466633  0.13658134  0.01090909  0.29159894  0.13603842]\n",
      "   [ 0.18021442  0.117842    0.01959984 -0.00757951  0.05093229]\n",
      "   [-0.0309121  -0.19903874  0.24330096 -0.06802162 -0.22014662]]]],\n",
      "bn_f8: [[0.05488464 0.04890541 0.13895872 0.11608359 0.14525036 0.14335674\n",
      "  0.12957982 0.06674504 0.02688591 0.17086917 0.07070848 0.15591257]\n",
      " [0.01864715 0.07535966 0.12262627 0.15020167 0.14430731 0.04761648\n",
      "  0.19368882 0.11649239 0.13811214 0.09531706 0.07460308 0.04841339]],\n",
      "deconv_f9: [[[[-0.  0. -0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [-0.  0.  0.]\n",
      "   [ 0. -0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0.  0. -0.]]]\n",
      "\n",
      "\n",
      " [[[-0.  0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0. -0. -0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [ 0.  0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0.  0. -0.]]]\n",
      "\n",
      "\n",
      " [[[ 0. -0. -0.]\n",
      "   [-0. -0. -0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0. -0. -0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [-0. -0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [-0. -0. -0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0. -0.  0.]\n",
      "   [-0. -0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [-0. -0.  0.]\n",
      "   [ 0. -0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [-0. -0. -0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0. -0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0. -0.  0.]\n",
      "   [ 0. -0. -0.]]]\n",
      "\n",
      "\n",
      " [[[-0.  0.  0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [ 0.  0. -0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [ 0.  0. -0.]]]\n",
      "\n",
      "\n",
      " [[[-0. -0.  0.]\n",
      "   [-0. -0. -0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [ 0.  0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.]\n",
      "   [-0.  0.  0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [-0. -0. -0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [ 0. -0.  0.]\n",
      "   [ 0. -0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0. -0.]\n",
      "   [ 0.  0. -0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[ 0. -0.  0.]\n",
      "   [ 0.  0. -0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0. -0. -0.]\n",
      "   [-0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [-0.  0.  0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[ 0. -0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0. -0.  0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [-0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0. -0.]\n",
      "   [ 0. -0. -0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0.]\n",
      "   [-0. -0. -0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[-0. -0.  0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0.  0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0.  0.  0.]\n",
      "   [ 0.  0.  0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0. -0. -0.]]\n",
      "\n",
      "  [[-0.  0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [ 0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [-0. -0.  0.]\n",
      "   [-0.  0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0.]\n",
      "   [ 0.  0.  0.]\n",
      "   [ 0. -0.  0.]]\n",
      "\n",
      "  [[ 0.  0. -0.]\n",
      "   [-0.  0. -0.]\n",
      "   [-0.  0.  0.]]]],\n",
      "bn_f9: [[0.14439454 0.12554954 0.19244705 0.01952304 0.09650445 0.15354622\n",
      "  0.19342071 0.12156159]\n",
      " [0.07344367 0.11901688 0.12851128 0.18307443 0.00471638 0.17504857\n",
      "  0.07602905 0.04309328]],\n",
      "deconv_f10: [[[[-5.65133963e-03 -5.65133943e-03 -5.65133963e-03 -5.65133943e-03]\n",
      "   [-7.40487863e-03 -4.77456944e-03 -7.40487863e-03 -4.77456944e-03]\n",
      "   [-5.65133963e-03 -5.65133943e-03 -5.65133963e-03 -5.65133943e-03]\n",
      "   [-7.40487863e-03 -4.77456944e-03 -7.40487863e-03 -4.77456944e-03]]\n",
      "\n",
      "  [[-9.15810487e-03 -9.15810455e-03 -9.15810487e-03 -9.15810455e-03]\n",
      "   [-1.19997486e-02 -7.73728186e-03 -1.19997486e-02 -7.73728186e-03]\n",
      "   [-9.15810487e-03 -9.15810455e-03 -9.15810487e-03 -9.15810455e-03]\n",
      "   [-1.19997486e-02 -7.73728186e-03 -1.19997486e-02 -7.73728186e-03]]\n",
      "\n",
      "  [[-9.88867938e-03 -9.88867904e-03 -9.88867938e-03 -9.88867904e-03]\n",
      "   [-1.29570112e-02 -8.35451229e-03 -1.29570112e-02 -8.35451229e-03]\n",
      "   [-9.88867938e-03 -9.88867904e-03 -9.88867938e-03 -9.88867904e-03]\n",
      "   [-1.29570112e-02 -8.35451229e-03 -1.29570112e-02 -8.35451229e-03]]\n",
      "\n",
      "  [[-1.40872022e-02 -1.40872017e-02 -1.40872022e-02 -1.40872017e-02]\n",
      "   [-1.84582824e-02 -1.19016604e-02 -1.84582824e-02 -1.19016604e-02]\n",
      "   [-1.40872022e-02 -1.40872017e-02 -1.40872022e-02 -1.40872017e-02]\n",
      "   [-1.84582824e-02 -1.19016604e-02 -1.84582824e-02 -1.19016604e-02]]\n",
      "\n",
      "  [[-3.62915688e-04 -3.62915676e-04 -3.62915688e-04 -3.62915676e-04]\n",
      "   [-4.75523823e-04 -3.06611577e-04 -4.75523823e-04 -3.06611577e-04]\n",
      "   [-3.62915688e-04 -3.62915676e-04 -3.62915688e-04 -3.62915676e-04]\n",
      "   [-4.75523823e-04 -3.06611577e-04 -4.75523823e-04 -3.06611577e-04]]\n",
      "\n",
      "  [[-1.34696282e-02 -1.34696278e-02 -1.34696282e-02 -1.34696278e-02]\n",
      "   [-1.76490830e-02 -1.13798992e-02 -1.76490830e-02 -1.13798992e-02]\n",
      "   [-1.34696282e-02 -1.34696278e-02 -1.34696282e-02 -1.34696278e-02]\n",
      "   [-1.76490830e-02 -1.13798992e-02 -1.76490830e-02 -1.13798992e-02]]\n",
      "\n",
      "  [[-5.85027955e-03 -5.85027935e-03 -5.85027955e-03 -5.85027935e-03]\n",
      "   [-7.66554709e-03 -4.94264507e-03 -7.66554709e-03 -4.94264507e-03]\n",
      "   [-5.85027955e-03 -5.85027935e-03 -5.85027955e-03 -5.85027935e-03]\n",
      "   [-7.66554709e-03 -4.94264507e-03 -7.66554709e-03 -4.94264507e-03]]\n",
      "\n",
      "  [[-3.31593980e-03 -3.31593968e-03 -3.31593980e-03 -3.31593968e-03]\n",
      "   [-4.34483386e-03 -2.80149236e-03 -4.34483386e-03 -2.80149236e-03]\n",
      "   [-3.31593980e-03 -3.31593968e-03 -3.31593980e-03 -3.31593968e-03]\n",
      "   [-4.34483386e-03 -2.80149236e-03 -4.34483386e-03 -2.80149236e-03]]]\n",
      "\n",
      "\n",
      " [[[-7.76638242e-04 -6.07638802e-04 -7.76638242e-04 -6.07638802e-04]\n",
      "   [-6.41438692e-04 -6.75238579e-04 -6.41438692e-04 -6.75238579e-04]\n",
      "   [-7.76638242e-04 -6.07638802e-04 -7.76638242e-04 -6.07638802e-04]\n",
      "   [-6.41438692e-04 -6.75238579e-04 -6.41438692e-04 -6.75238579e-04]]\n",
      "\n",
      "  [[-1.25855725e-03 -9.84690399e-04 -1.25855725e-03 -9.84690399e-04]\n",
      "   [-1.03946377e-03 -1.09423714e-03 -1.03946377e-03 -1.09423714e-03]\n",
      "   [-1.25855725e-03 -9.84690399e-04 -1.25855725e-03 -9.84690399e-04]\n",
      "   [-1.03946377e-03 -1.09423714e-03 -1.03946377e-03 -1.09423714e-03]]\n",
      "\n",
      "  [[-1.35895683e-03 -1.06324265e-03 -1.35895683e-03 -1.06324265e-03]\n",
      "   [-1.12238548e-03 -1.18152832e-03 -1.12238548e-03 -1.18152832e-03]\n",
      "   [-1.35895683e-03 -1.06324265e-03 -1.35895683e-03 -1.06324265e-03]\n",
      "   [-1.12238548e-03 -1.18152832e-03 -1.12238548e-03 -1.18152832e-03]]\n",
      "\n",
      "  [[-1.93594098e-03 -1.51467285e-03 -1.93594098e-03 -1.51467285e-03]\n",
      "   [-1.59892648e-03 -1.68318010e-03 -1.59892648e-03 -1.68318010e-03]\n",
      "   [-1.93594098e-03 -1.51467285e-03 -1.93594098e-03 -1.51467285e-03]\n",
      "   [-1.59892648e-03 -1.68318010e-03 -1.59892648e-03 -1.68318010e-03]]\n",
      "\n",
      "  [[-4.98738743e-05 -3.90211293e-05 -4.98738743e-05 -3.90211293e-05]\n",
      "   [-4.11916784e-05 -4.33622273e-05 -4.11916784e-05 -4.33622273e-05]\n",
      "   [-4.98738743e-05 -3.90211293e-05 -4.98738743e-05 -3.90211293e-05]\n",
      "   [-4.11916784e-05 -4.33622273e-05 -4.11916784e-05 -4.33622273e-05]]\n",
      "\n",
      "  [[-1.85107056e-03 -1.44827055e-03 -1.85107056e-03 -1.44827055e-03]\n",
      "   [-1.52883056e-03 -1.60939056e-03 -1.52883056e-03 -1.60939056e-03]\n",
      "   [-1.85107056e-03 -1.44827055e-03 -1.85107056e-03 -1.44827055e-03]\n",
      "   [-1.52883056e-03 -1.60939056e-03 -1.52883056e-03 -1.60939056e-03]]\n",
      "\n",
      "  [[-8.03977663e-04 -6.29029061e-04 -8.03977663e-04 -6.29029061e-04]\n",
      "   [-6.64018783e-04 -6.99008503e-04 -6.64018783e-04 -6.99008503e-04]\n",
      "   [-8.03977663e-04 -6.29029061e-04 -8.03977663e-04 -6.29029061e-04]\n",
      "   [-6.64018783e-04 -6.99008503e-04 -6.64018783e-04 -6.99008503e-04]]\n",
      "\n",
      "  [[-4.55694724e-04 -3.56533817e-04 -4.55694724e-04 -3.56533817e-04]\n",
      "   [-3.76365999e-04 -3.96198180e-04 -3.76365999e-04 -3.96198180e-04]\n",
      "   [-4.55694724e-04 -3.56533817e-04 -4.55694724e-04 -3.56533817e-04]\n",
      "   [-3.76365999e-04 -3.96198180e-04 -3.76365999e-04 -3.96198180e-04]]]\n",
      "\n",
      "\n",
      " [[[-6.96700947e-03 -5.14426429e-03 -6.96700947e-03 -5.14426429e-03]\n",
      "   [-6.51132207e-03 -4.68857984e-03 -6.51132207e-03 -4.68857984e-03]\n",
      "   [-6.96700947e-03 -5.14426429e-03 -6.96700947e-03 -5.14426429e-03]\n",
      "   [-6.51132207e-03 -4.68857984e-03 -6.51132207e-03 -4.68857984e-03]]\n",
      "\n",
      "  [[-1.12901732e-02 -8.33637951e-03 -1.12901732e-02 -8.33637951e-03]\n",
      "   [-1.05517230e-02 -7.59793406e-03 -1.05517230e-02 -7.59793406e-03]\n",
      "   [-1.12901732e-02 -8.33637951e-03 -1.12901732e-02 -8.33637951e-03]\n",
      "   [-1.05517230e-02 -7.59793406e-03 -1.05517230e-02 -7.59793406e-03]]\n",
      "\n",
      "  [[-1.21908304e-02 -9.00140208e-03 -1.21908304e-02 -9.00140208e-03]\n",
      "   [-1.13934714e-02 -8.20404821e-03 -1.13934714e-02 -8.20404821e-03]\n",
      "   [-1.21908304e-02 -9.00140208e-03 -1.21908304e-02 -9.00140208e-03]\n",
      "   [-1.13934714e-02 -8.20404821e-03 -1.13934714e-02 -8.20404821e-03]]\n",
      "\n",
      "  [[-1.73667976e-02 -1.28232059e-02 -1.73667976e-02 -1.28232059e-02]\n",
      "   [-1.62308969e-02 -1.16873125e-02 -1.62308969e-02 -1.16873125e-02]\n",
      "   [-1.73667976e-02 -1.28232059e-02 -1.73667976e-02 -1.28232059e-02]\n",
      "   [-1.62308969e-02 -1.16873125e-02 -1.62308969e-02 -1.16873125e-02]]\n",
      "\n",
      "  [[-4.47404899e-04 -3.30352508e-04 -4.47404899e-04 -3.30352508e-04]\n",
      "   [-4.18141731e-04 -3.01089528e-04 -4.18141731e-04 -3.01089528e-04]\n",
      "   [-4.47404899e-04 -3.30352508e-04 -4.47404899e-04 -3.30352508e-04]\n",
      "   [-4.18141731e-04 -3.01089528e-04 -4.18141731e-04 -3.01089528e-04]]\n",
      "\n",
      "  [[-1.66054482e-02 -1.22610447e-02 -1.66054482e-02 -1.22610447e-02]\n",
      "   [-1.55193447e-02 -1.11749482e-02 -1.55193447e-02 -1.11749482e-02]\n",
      "   [-1.66054482e-02 -1.22610447e-02 -1.66054482e-02 -1.22610447e-02]\n",
      "   [-1.55193447e-02 -1.11749482e-02 -1.55193447e-02 -1.11749482e-02]]\n",
      "\n",
      "  [[-7.21226394e-03 -5.32535402e-03 -7.21226394e-03 -5.32535402e-03]\n",
      "   [-6.74053532e-03 -4.85362844e-03 -6.74053532e-03 -4.85362844e-03]\n",
      "   [-7.21226394e-03 -5.32535402e-03 -7.21226394e-03 -5.32535402e-03]\n",
      "   [-6.74053532e-03 -4.85362844e-03 -6.74053532e-03 -4.85362844e-03]]\n",
      "\n",
      "  [[-4.08791286e-03 -3.01841188e-03 -4.08791286e-03 -3.01841188e-03]\n",
      "   [-3.82053697e-03 -2.75103772e-03 -3.82053697e-03 -2.75103772e-03]\n",
      "   [-4.08791286e-03 -3.01841188e-03 -4.08791286e-03 -3.01841188e-03]\n",
      "   [-3.82053697e-03 -2.75103772e-03 -3.82053697e-03 -2.75103772e-03]]]],\n",
      "bn_f10: [[ 1.25843060e-01  1.45538991e-02  1.96252121e-01]\n",
      " [-2.27376804e+01 -2.28613417e+01 -2.27525721e+01]]\n"
     ]
    }
   ],
   "source": [
    "params = [\n",
    "    ('conv_f1', conv_f1), ('bn_f1', bn_f1),\n",
    "    ('conv_f2', conv_f2), ('bn_f2', bn_f2),\n",
    "    ('deconv_f3', deconv_f3), ('bn_f3', bn_f3),\n",
    "    ('deconv_f4', deconv_f4), ('bn_f4', bn_f4),\n",
    "    ('deconv_f5', deconv_f5), ('bn_f5', bn_f5),\n",
    "    ('conv_f6', conv_f6), ('bn_f6', bn_f6),\n",
    "    ('conv_f7', conv_f7), ('bn_f7', bn_f7),\n",
    "    ('conv_f8', conv_f8), ('bn_f8', bn_f8),\n",
    "    ('deconv_f9', deconv_f9), ('bn_f9', bn_f9),\n",
    "    ('deconv_f10', deconv_f10), ('bn_f10', bn_f10)\n",
    "]\n",
    "\n",
    "print(\",\\n\".join([f\"{name}: {value}\" for name, value in params]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paradise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
